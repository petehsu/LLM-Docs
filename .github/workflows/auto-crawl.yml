name: Auto Crawl & Deploy

on:
  # æ¯å¤© UTC æ—¶é—´ 2:00 è¿è¡Œï¼ˆåŒ—äº¬æ—¶é—´ 10:00ï¼‰
  schedule:
    - cron: '0 2 * * *'
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
  # æ¨é€åˆ° main åˆ†æ”¯æ—¶éƒ¨ç½²
  push:
    branches: [main]

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 markdownify lxml
      
      - name: Run auto crawler
        working-directory: docs-site/scripts
        run: python auto_crawler.py --force
        continue-on-error: true
      
      - name: Commit changes
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add -A
          git diff --staged --quiet || git commit -m "ğŸ¤– Auto crawl: $(date +'%Y-%m-%d %H:%M')"
          git push

  deploy:
    needs: crawl
    if: always()
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: main
      
      - name: Pull latest changes
        run: git pull origin main
      
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./docs-site
          cname: ''  # å¦‚æœæœ‰è‡ªå®šä¹‰åŸŸåï¼Œå¡«åœ¨è¿™é‡Œ
