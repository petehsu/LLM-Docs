# DeepSeek V3.2 正式版：强化 Agent 能力，融入思考推理

两个月前，我们发布了实验性的 DeepSeek-V3.2-Exp，并收到了众多热心用户反馈的对比测试结果。目前未发现 V3.2-Exp 在任何特定场景中显著差于 V3.1-Terminus，这验证了 DSA 稀疏注意力机制的有效性。也感谢广大用户一直以来的积极反馈与支持，为我们的持续创新注入了更多信心与动力。

今天，我们同时发布两个正式版模型：**DeepSeek-V3.2 和 DeepSeek-V3.2-Speciale** 。官方网页端、App 和 API 均已更新为正式版 DeepSeek-V3.2，欢迎使用。Speciale 版本目前仅以临时 API 服务形式开放，以供社区评测与研究。

新模型技术报告已同步发布：<https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.2/resolve/master/assets/paper.pdf>

![](/zh-cn/img/v3.2_251201_benchmark.webp)

* * *

# 推理能力全球领先

  * DeepSeek-V3.2 的目标是平衡推理能力与输出长度，适合日常使用，例如问答场景和通用 Agent 任务场景。在公开的推理类 Benchmark 测试中，DeepSeek-V3.2 达到了 GPT-5 的水平，仅略低于 Gemini-3.0-Pro；相比 Kimi-K2-Thinking，V3.2 的输出长度大幅降低，显著减少了计算开销与用户等待时间。

  * DeepSeek-V3.2-Speciale 的目标是将开源模型的推理能力推向极致，探索模型能力的边界。V3.2-Speciale 是 DeepSeek-V3.2 的长思考增强版，同时结合了 DeepSeek-Math-V2 的定理证明能力。该模型具备出色的指令跟随、严谨的数学证明与逻辑验证能力，在主流推理基准测试上的性能表现媲美 Gemini-3.0-Pro（见下表）。更令人瞩目的是，V3.2-Speciale 模型成功斩获 IMO 2025（国际数学奥林匹克）、CMO 2025（中国数学奥林匹克）、ICPC World Finals 2025（国际大学生程序设计竞赛全球总决赛）及 IOI 2025（国际信息学奥林匹克）金牌。其中，ICPC 与 IOI 成绩分别达到了人类选手第二名与第十名的水平。

Tips：在高度复杂任务上，Speciale 模型大幅优于标准版本，但消耗的 Tokens 也显著更多，成本更高。目前，DeepSeek-V3.2-Speciale 仅供研究使用，不支持工具调用，暂未针对日常对话与写作任务进行专项优化。

![](/zh-cn/img/v3.2_251201_benchmark_table_cn.webp)  
表1：DeepSeek-V3.2 与其他模型在各类数学、代码与通用领域评测集上的得分（括号内为消耗 Tokens 总量约数）

* * *

# 思考融入工具调用

  * 不同于过往版本在思考模式下无法调用工具的局限，DeepSeek-V3.2 是我们推出的首个将思考融入工具使用的模型，并且同时支持思考模式与非思考模式的工具调用。我们提出了一种大规模 Agent 训练数据合成方法，构造了大量「难解答，易验证」的强化学习任务（1800+ 环境，85,000+ 复杂指令），大幅提高了模型的泛化能力。

![](/zh-cn/img/v3.2_251201_agent_benchmark.webp)  
表2：DeepSeek-V3.2 与其他模型在各类智能体工具调用评测集上的得分

  

  * 如上表所示，DeepSeek-V3.2 模型在智能体评测中达到了当前开源模型的最高水平，大幅缩小了开源模型与闭源模型的差距。值得说明的是，V3.2 并没有针对这些测试集的工具进行特殊训练，所以我们相信，V3.2 在真实应用场景中能够展现出较强的泛化性。

  

![](/zh-cn/img/v3.2_251201_thinking_with_tools_demo.gif)  
示例为通过 LobeChat 使用 DeepSeek-V3.2 的深度思考+工具调用能力得到更加详细准确的回复

* * *

# 开源

  * DeepSeek-V3.2

** HuggingFace: <https://huggingface.co/deepseek-ai/DeepSeek-V3.2>

** ModelScope: <https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.2>

  * DeepSeek-V3.2-Speciale

** HuggingFace: <https://huggingface.co/deepseek-ai/DeepSeek-V3.2-Speciale>

** ModelScope: <https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.2-Speciale>

* * *

# 网页端、APP 与 API 更新

DeepSeek-V3.2 是我们当前正式提供服务的模型，官网网页、APP、API 模型均已由 DeepSeek-V3.2-Exp 升级为正式版 DeepSeek-V3.2，使用方式不变。

同时，为了方便社区评测与研究，我们非正式部署了 DeepSeek-V3.2-Speciale 的 API 服务，API 用户可以通过设置 `base_url="https://api.deepseek.com/v3.2_speciale_expires_on_20251215"` 访问该模型。该模型 API 价格不变，只支持思考模式下的对话功能，不支持工具调用等功能，最大输出长度默认为 128K，支持时间截止至北京时间 2025-12-15 23:59。

* * *

# 思考模式下的工具调用

本次 API 更新支持了 DeepSeek-V3.2 思考模式下的工具调用能力。当前在思考模式下，模型能够经过多轮的思考 + 工具调用，最终给出更详尽准确的回答。下图为思考模式下进行工具调用的 API 请求示意图：

![](/zh-cn/img/v3.2_thinking_with_tools.jpeg)

  * 在回答问题 1 过程中（请求 1.1 - 1.3），模型进行了多次思考 + 工具调用后给出答案。在这个过程中，用户需回传思维链内容（reasoning_content）给 API，以让模型继续思考。

  * 在下一个用户问题开始时（请求 2.1），需删除之前的思维链，并保留其它内容发送给 API。

  * 更详细的使用方法请参考 API 文档：<https://api-docs.deepseek.com/zh-cn/guides/thinking_mode>

DeepSeek-V3.2 的思考模式也增加了对 Claude Code 的支持，用户可以通过将模型名改为 deepseek-reasoner，或在 Claude Code CLI 中按 Tab 键开启思考模式进行使用。但需要注意的是，思考模式未充分适配 Cline、RooCode 等使用非标准工具调用的组件，我们建议用户在使用此类组件时继续使用非思考模式。