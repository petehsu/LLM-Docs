# DeepSeek API Upgrade

On this page

# DeepSeek API Upgrade

## Now Supporting Chat Prefix Completion, FIM, Function Calling and JSON Output​

Today, the DeepSeek API releases a major update, equipped with new interface features to unlock more potential of the model:

  * **Update API`/chat/completions`**
    * JSON Output
    * Function Calling
    * Chat Prefix Completion (Beta)
    * 8K `max_tokens` (Beta)
  * **New API`/completions`**
    * FIM Completion (Beta)

All new features above are open to the two models: `deepseek-chat` and `deepseek-coder`.

* * *

### Update API `/chat/completions`​

#### 1\. JSON Output, Strengthen Formatted Output​

DeepSeek API now supports JSON Output，compatible with OpenAI API，enforces the model to output valid JSON format string.

When performing tasks such as data processing, this feature allows the model to return JSON in a predefined format, facilitating the subsequent parsing of the model's output and enhancing the automation capabilities of the program flow.

To use JSON Output，users need to：

  1. Set `response_format` to `{'type': 'json_object'}`
  2. Guide the model to output JSON format in the prompt to ensure that the output format meets your expectations
  3. Set max_tokens appropriately to prevent the JSON string from being truncated midway

The following is an example of JSON Output.In this example, the user provides a piece of text, and the model formats the questions and answers within the text into JSON.

![](https://cdn.deepseek.com/api-docs/json_mode_en.jpeg)

For detailed guide, please refer to [JSON Output Guide](</guides/json_mode>).

#### 2\. Function Calling, Connecting The Physical World​

DeepSeek API now supports Function Calling, compatible with OpenAI API, allows the model to interact with the physical world via externel tools.

Function Calling supports multiple functions in one call (up to 128). It supports parallel function calls.

The image below demonstrates the integration of `deepseek-coder` into the open-source large model frontend [LobeChat](<https://github.com/lobehub/lobe-chat>). In this example, we enabled the "Website Crawler" plugin to perform website crawling and summarization.

![](https://cdn.deepseek.com/api-docs/fc_demo_en.gif)

The image below illustrates the interaction process using the Function Calling feature:

![](https://cdn.deepseek.com/api-docs/fc_demo_2_en.jpeg)

For detailed guide, please refer to [Tool Calls Guide](</guides/tool_calls>).

#### 3\. Chat Prefix Completion (Beta), More Flexible Output Control​

Chat Prefix Completion follows the API format of [Chat Completion](</api/create-chat-completion>), allowing users to specify the prefix of the last `assistant` message for the model to complete. This feature can also be used to concatenate messages that were truncated due to reaching the `max_tokens` limit and resend the request to continue the truncated content.

To use Chat Prefix Completion, user needs to：

  1. Set `base_url` to `https://api.deepseek.com/beta` to enable the Beta features
  2. Ensure that the role of the last message in the `messages` list is `assistant`, and set the `prefix` parameter of the last message to `True`, for example: `{"role": "assistant", "content": "Once upon a time,", "prefix": True}`

The following is an example of using Chat Prefix Completion. In this example, the beginning of the `assistant` message is set to `'```python\n'` to enforce the output to start with a code block, and the stop parameter is set to `'```'` to prevent the model from outputting extra content.

![](https://cdn.deepseek.com/api-docs/chat_prefix_completion_en.jpeg)

For detailed guide, please refer to [Chat Prefix Completion Guide](</guides/chat_prefix_completion>).

#### 4\. 8K `max_tokens` (Beta)，Release Longer Possibilities​

To accommodate scenarios requiring longer text output, we have adjusted the upper limit of the `max_tokens` parameter to 8K in the Beta API.

To use 8K `max_tokens`, user needs to:

  1. Set `base_url` to `https://api.deepseek.com/beta` to enable the Beta features
  2. `max_tokens` is default to 4096. By enabling the Beta API，`max_tokens` can be set up to 8192

* * *

### New API `/completions`​

#### 1\. FIM Completion (Beta), Enabling More Completion Scenarios​

DeepSeek API now supports FIM (Fill-In-the-Middle) Completion，compatible with OpenAI FIM Completion API，allowing users to provide custom prefixes/suffixes (optional) for the model to complete the content. This feature is commonly used in scenarios such as story completion and code completion. The FIM Completion API is charged the same as the Chat Completion API.

To use FIM Completion, user needs to set `base_url` to `https://api.deepseek.com/beta` to enable the Beta features.

The following is an example of using the FIM Completion API. In this example, the user provides the beginning and the end of a Fibonacci sequence function, and the model completes the content in the middle.

![](https://cdn.deepseek.com/api-docs/fim_completion.jpeg)

For detailed guide, please refer to [FIM Completion Guide](</guides/fim_completion>).

* * *

### Update Statements​

The Beta API is open for all users. User needs to set `base_url` to `https://api.deepseek.com/beta` to enable the Beta features

Beta API are considered unstable and their subsequent testing and release plans may change flexibly. Thank you for your understanding.

The related model versions will be released to the open-source community once the functionality is stable.