[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fapi%2Frtav%2FGLM-4-Voice)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

API REFERENCE

* SDK Calling

  [+ Installation](/dev/api/devguide/sdk-install)

  [+ Authentication](/dev/api/devguide/sdk-auth)

  [+ sdk\_example](/dev/api/devguide/sdk_example)

* HTTP Request

  [+ API Request](/dev/api/http-call/http-para)

  [+ Authentication](/dev/api/http-call/http-auth)

* More Frameworks

  [+ OpenAI SDK](/dev/api/thirdparty-frame/openai-sdk)

  [+ Langchain SDK](/dev/api/thirdparty-frame/langchain-sdk)

APIs

* Language models

  [+ GLM-4 Models](/dev/api/normal-model/glm-4)

  [+ GLM-4V Models](/dev/api/normal-model/glm-4v)

* Reasoning models

  [+ GLM-Z1](/dev/api/Reasoning-models/glm-z1)

* Video Generation

  [+ CogVideoX](/dev/api/videomodel/cogvideox)

  [+ CogVideoX-3](/dev/api/videomodel/cogvideox-3)

  [+ Vidu Models](/dev/api/videomodel/vidu)

* Audio-Video

  [+ GLM-4-Voice](/dev/api/rtav/GLM-4-Voice)

  [+ GLM-Realtime](/dev/api/rtav/GLM-Realtime)

  [+ GLM-ASR](/dev/api/rtav/glm-asr)

* Reasoning models

  [+ GLM-4.1V-Thinking](/dev/api/visual-reasoning-model/GLM-4.1V-Thinking)

* Agent

  [+ TranslationAgent](/dev/api/agent/general_translation)

  [+ Professional Document Translation](/dev/api/agent/doc_translation_agent)

  [+ Social Science and Literary Translation](/dev/api/agent/social_literature_translation_agent)

  [+ Subtitle Translation for Film and Television](/dev/api/agent/subtitle_translation_agent)

  [+ Social Media Translation](/dev/api/agent/social_translation_agent)

  [+ AI Drawing](/dev/api/agent/ai_drawing_agent)

  [+ AI Comics](/dev/api/agent/cartoon_generator_agent)

  [+ Popular Special Effects Videos](/dev/api/agent/vidu_template_agent)

  [+ Resume and Job Matching Assistant](/dev/api/agent/job_matching_agent)

  [+ Customer Service Script Quality Inspection](/dev/api/agent/service_check_agent)

  [+ Sales Quality Inspection](/dev/api/agent/sales_check_agent)

  [+ Bill Recognition](/dev/api/agent/receipt_recognition_agent)

  [+ Clothes Recognition](/dev/api/agent/clothes_recognition_agent)

  [+ Contract Analysis](/dev/api/agent/contract_parser_agent)

  [+ Tendering Analysis Agent](/dev/api/agent/bidding_parser_agent)

  [+ Winning Bid Analysis Agent](/dev/api/agent/bidwin_parser_agent)

  [+ Intelligent Problem Solving](/dev/api/agent/intelligent_education_solve_agent)

  [+ Homework Grading](/dev/api/agent/intelligent_education_correction_agent)

* search-tool

  [+ Web Search API](/dev/api/search-tool/web-search)

  [+ Web Search in Chat](/dev/api/search-tool/websearch-in-chat)

  [+ Search Agent](/dev/api/search-tool/agent-search)

* Image Generation

  [+ CogView-4](/dev/api/image-model/cogview)

* Agent Model

  [+ GLM-4-AllTools](/dev/api/intelligent-agent-model/glm-4-alltools)

  [+ GLM-4-Assistant](/dev/api/intelligent-agent-model/assistantapi)

* Code Programming

  [+ CodeGeeX-4](/dev/api/code-model/codegeex-4)

* Embedding

  [+ Embedding](/dev/api/vector/embedding)

* Moderations

  [+ moderations](/dev/api/moderations/moderations)

* Role-playing

  [+ CharGLM-4](/dev/api/super-humanoid/charglm-4)

  [+ Emohaa](/dev/api/super-humanoid/emohaa)

* Agent Development Platform

  [+ „ÄêNew„Äëqingliuagent](/dev/api/Agent_Platform/newagent)

  [+ agent](/dev/api/Agent_Platform/agent)

  [+ qingliuSDK](/dev/api/Agent_Platform/agentsdk)

  [+ Knowledge](/dev/api/Agent_Platform/knowledge)

  [+ FinAgent](/dev/api/Agent_Platform/FinAgent)

* Batch

  [+ Batch](/dev/api/batch-api/batch)

* Data Management

  [+ File Management](/dev/api/knowlage-manage/queryfile)

  [+ File content extraction](/dev/api/knowlage-manage/queryextract)

  [+ Rerank](/dev/api/knowlage-manage/rerank)

* Error Codes

  [+ HTTP Status Codes](/dev/api/error-code/error-code-v4)

  [+ Model Error Codes](/dev/api/error-code/service-error)

More

[* Libraries](/dev/api/libraries)

[* API Pricing](/dev/api/product-billing)

[* Tokenizer](/dev/api/tokenizer)

[* Parameter Description](/dev/api/parameter-description)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

# GLM-4-Voice

Model Code: glm-4-voice

GLM-4-Voice is an end-to-end voice model launched by Zhipu AI. GLM-4-Voice can directly understand and generate Chinese and English speech, conduct real-time voice conversations, and can follow user instructions to change the emotion, tone, speed, dialect, and other attributes of the voice.

* Model codes: glm-4-voice;
* Experience the model‚Äôs capabilities at the [Demo Center](https://www.bigmodel.cn/login?redirect=%2Ftrialcenter%2Fmodeltrial%3FmodelCode%3Dglm-4-voice) ;
* Check [Product Pricing](https://www.bigmodel.cn/pricing) ;
* View Model [Rate Limits](https://www.bigmodel.cn/login?redirect=%2Fusercenter%2Fcorporateequity) ;
* Check Your [API Key](https://www.bigmodel.cn/login?redirect=%2Fusercenter%2Fproj-mgmt%2Fapikeys) ;

## Synchronous Call

**Interface Request**

| Transmission Method | https |
| --- | --- |
| Request URL | https://open.bigmodel.cn/api/paas/v4/chat/completions |
| Call Method | Synchronous call, wait for the model to complete execution and return the final result or SSE call |
| Character Encoding | UTF-8 |
| Interface Request Format | JSON |
| Response Format | JSON or Standard Stream Event |
| Interface Request Type | POST |
| Development Language | Any development language that can initiate http requests |

### Request Parameters

| **Parameter Name** | **Type** | **Required** | **Parameter Description** |
| --- | --- | --- | --- |
| model | String | Yes | The model code to call. Model Code: glm-4-voice |
| messages | List<Object> | Yes | When calling the language model, the current conversation information list is used as a prompt input to the model, passed as a json array. For example, voice conversation parameters: `{ "role": "user", "content": [ { "type": "text", "text": "Tell me a cold joke" }, { "type": "input_audio", "input_audio": { "data": "<base64_string>", "format": "wav" } } ] }` |
| request\_id | String | No | Passed by the user side, must be unique; used to distinguish the unique identifier of each request, the platform will generate a default if the user side does not pass it. |
| do\_sample | Boolean | No | When do\_sample is true, the sampling strategy is enabled, when do\_sample is false, the sampling strategy temperature, top\_p will not take effect. The default value is true. |
| stream | Boolean | No | This parameter should be set to false or omitted when using synchronous calls. Indicates that the model returns all content at once after generating all content. The default value is false. If set to true, the model will return the generated content in chunks through the standard Event Stream. When the Event Stream ends, a data: [DONE] message will be returned. |
| temperature | Float | No | Sampling temperature, controls the randomness of the output, must be a positive number. The range is: [0.0,1.0], the default value is 0.8, the larger the value, the more random and creative the output will be; the smaller the value, the output will be more stable or deterministic. It is recommended to adjust the top\_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time. |
| top\_p | Float | No | Another method of sampling with temperature, called nucleus sampling. The range is: [0.0, 1.0], the default value is 0.6. The model considers the results of tokens with top\_p probability mass. For example: 0.1 means the model decoder only considers tokens from the top 10% probability candidate set. It is recommended to adjust the top\_p or temperature parameters according to the application scenario, but do not adjust both parameters at the same time. |
| max\_tokens | Integer | No | The maximum number of tokens output by the model, the maximum output is 4095, the default value is 1024. |
| stop | List | No | The model will stop generating when it encounters the characters specified by stop. Currently, only a single stop word is supported, in the format [‚Äústop\_word1‚Äù]. |
| user\_id | String | No | The unique ID of the end user, assisting the platform in intervening in the end user‚Äôs violations, generating illegal and harmful information, or other abusive behaviors. ID length requirement: minimum 6 characters, maximum 128 characters. [Learn more](https://open.bigmodel.cn/dev/howuse/securityaudit) |

### Message Format

**System Message Format**

| **Parameter Name** | **Type** | **Required** | **Parameter Description** |
| --- | --- | --- | --- |
| role | String | Yes | The role information of the message, should be `system` at this time |
| content | String | Yes | The content of the message |

**User Message Format**

| **Parameter Name** | **Type** | **Required** | **Parameter Description** |
| --- | --- | --- | --- |
| role | String | Yes | The role information of the message, should be `user` at this time |
| content | List<Object> | Yes | The content of the message. |
| type | String | Yes | Text type: text  voice type: input\_audio |
| text | String | Yes | Supplement when type is text |
| input\_audio | String | Yes | Supplement when type is input\_audio, only glm-4-voice supports voice input |
| data | String | Yes | Base64 encoding of the voice file. The audio should not exceed 10 minutes. 1s audio = 12.5 Tokens, rounded up. |
| format | String | Yes | The format of the voice file, supports wav and mp3 |

**Assistant Message Format**

| **Parameter Name** | **Type** | **Required** | **Parameter Description** |
| --- | --- | --- | --- |
| role | String | Yes | The role information of the message, should be `assistant` at this time |
| content | String | Yes | The content of the message |
| audio | Object | Yes | Voice message |
| id | String | Yes | Voice message id, used for multi-turn dialogue |

### Response Parameters

| **Parameter Name** | **Type** | **Parameter Description** |
| --- | --- | --- |
| id | String | Task ID |
| created | Long | Request creation time, Unix timestamp in seconds. |
| model | String | Model name |
| choices | List | The model output content of the current conversation |
| index | Integer | Result index |
| finish\_reason | String | The reason for the model inference termination. `stop` represents natural termination or triggering of stop words. `tool_calls` represents the model hitting a function. `length` represents reaching the token length limit. `sensitive` represents the model inference content being intercepted by the security audit interface. Please note, for such content, users should judge and decide whether to withdraw the published content. `network_error` represents model inference exception. |
| message | Object | The text information returned by the model |
| role | String | The role of the current conversation, currently defaults to assistant (model) |
| content | String | The content of the current conversation. This field is `null` when a function is hit, and returns the model inference result when no function is hit. |
| audio | Object | The audio content of the current conversation |
| id | String | The audio content id of the current conversation, can be used for multi-turn dialogue input |
| data | String | Base64 encoding of the audio content of the current conversation |
| expires\_at | String | The expiration time of the audio content of the current conversation |
| usage | Object | Returns the token count statistics of this model call at the end |
| prompt\_tokens | Integer | The number of tokens input by the user |
| completion\_tokens | Integer | The number of tokens output by the model |
| total\_tokens | Integer | The total number of tokens |
| content\_filter | List | Content security related information |
| role | String | Security effective link, including   `role = assistant` model inference,  `role = user` user input,  `role = history` historical context |
| level | Integer | Severity level 0-3, level 0 indicates the most serious, 3 indicates slight |

### Request Example

```
import wave
import base64

from zhipuai import ZhipuAI

def save_audio_as_wav(audio_data, filepath):
    with wave.open(filepath, 'wb') as wav_file:
        wav_file.setnchannels(1)
        wav_file.setsampwidth(2)
        wav_file.setframerate(44100)
        wav_file.writeframes(audio_data)
    print(f"Audio saved to {filepath}")

client = ZhipuAI(api_key="YOUR API KEY") # Fill in your own APIKey

response = client.chat.completions.create(
    model="glm-4-voice",  # Fill in the model name you want to call
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Hello"
                },
                {
                    "type": "input_audio",
                    "input_audio": {
                        "data": "<base64_string>",
                        "format":"wav"
                    }
                }
            ]
        },
    ],
    max_tokens=1024,
    stream=False
)
print(response)
# Get audio data
audio_data = response.choices[0].message.audio['data']
decoded_data = base64.b64decode(audio_data)
# Write the decoded data to a WAV file
with open("output.wav", 'wb') as wav_file:
    wav_file.write(decoded_data)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37  
38  
39  
40  
41  
42  
43  
44  
45  
46

### Response Example

```
{
    "created": 1703487403,
    "id": "8239375684858666781",
    "model": "glm-4-voice",
    "request_id": "8239375684858666781",
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "Why is the math book always unhappy? Because it has too many problems!",
                "role": "assistant",
                "audio": {
                    "id": "c6d3b522-e6e5-4f90-b215-29ecd2a529d5",
                    "data": "<base64_string>",
                    "expires_at": 1735011068
                }
            }
        }
    ],
    "usage": {
        "completion_tokens": 217,
        "prompt_tokens": 31,
        "total_tokens": 248
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26

## Stream Output

| **Parameter Name** | **Type** | **Parameter Description** |
| --- | --- | --- |
| id | String | The task order number generated by the Zhipu AI open platform, please use this order number when calling the request result interface |
| created | Long | Request creation time, Unix timestamp in seconds. |
| choices | List | The model output content of the current conversation |
| index | Integer | Result index |
| finish\_reason | String | The reason for the model inference termination. `stop` represents natural termination or triggering of stop words. `length` represents reaching the token length limit. `sensitive` represents the model inference content being intercepted by the security audit interface. Please note, for such content, users should judge and decide whether to withdraw the published content. `network_error` represents model inference exception. |
| delta | Object | The incremental text information returned by the model |
| role | String | The role of the current conversation, currently defaults to assistant (model) |
| content | String | The content of the current conversation |
| audio | Object | The audio content of the current conversation |
| id | String | The audio content id of the current conversation, can be used for multi-turn dialogue input |
| data | String | Base64 encoding of the audio content of the current conversation |
| expires\_at | String | The expiration time of the audio content of the current conversation |
| usage | Object | Token count statistics for this model call |
| prompt\_tokens | Integer | The number of tokens input by the user |
| completion\_tokens | Integer | The number of tokens output by the model |
| total\_tokens | Integer | The total number of tokens |

### Request Example

```
import wave
import base64

from zhipuai import ZhipuAI

def save_audio_as_wav(audio_data, filepath):
    with wave.open(filepath, 'wb') as wav_file:
        wav_file.setnchannels(1)
        wav_file.setsampwidth(2)
        wav_file.setframerate(44100)
        wav_file.writeframes(audio_data)
    print(f"Audio saved to {filepath}")

client = ZhipuAI(api_key="YOUR API KEY") # Fill in your own APIKey

response = client.chat.completions.create(
    model="glm-4-voice",  # Fill in the model name you want to call
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "input_audio",
                    "input_audio": {
                        "data": "<base64_string>",
                        "format":"wav"
                }
            }
        ]
        },
    ],
    max_tokens=1024,
    stream=True
)

i = 1
for chunk in response:
    print(chunk.choices[0].delta)
    delta = chunk.choices[0].delta
    audio = chunk.choices[0].delta.audio
    if audio is not None:
        filename = "output" + str(i) + ".wav"
        audio_value_data = audio.data
        if audio_value_data is not None:
            decoded_data = base64.b64decode(audio_value_data)
            # Write the decoded data to a WAV file
            with open(filename, 'wb') as wav_file:
                wav_file.write(decoded_data)
                i = i + 1
    else:
        content = delta.content
        print(content)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37  
38  
39  
40  
41  
42  
43  
44  
45  
46  
47  
48  
49  
50  
51  
52  
53

### Response Example

```
data: {"id":"8313807536837492492","created":1706092316,"model":"glm-4-voice","choices":[{"index":0,"delta":{"role":"assistant","content":"Okay! One day, a little turtle was walking slowly on the road"}}]}

data: {"id":"8313807536837492492","created":1706092316,"model":"glm-4-voice","choices":[{"index":0,"delta":{"role":"assistant","content":"Suddenly, a rabbit ran over quickly and bumped into the little turtle. The little turtle stood up, patted the dirt on its body","audio":{"id":"c6d3b522-e6e5-4f90-b215-29ecd2a529d5","data":"<base64_string>","expires_at":1735011068}}}]}

data: {"id":"8313807536837492492","created":1705476637,"model":"glm-4-voice","choices":[{"index":0,"finish_reason":"stop","delta":{"role":"assistant","content":""}}],"usage":{"prompt_tokens":1037,"completion_tokens":37,"total_tokens":1074}}
```

1  
2  
3  
4  
5  
6

## Multi-turn Dialogue Example

Audio dialogue to achieve multi-turn dialogue, currently only supports concatenation through audio.id format, the format is as follows:

```
import wave
import base64

from zhipuai import ZhipuAI
def save_audio_as_wav(audio_data, filepath):
    with wave.open(filepath, 'wb') as wav_file:
        wav_file.setnchannels(1)
        wav_file.setsampwidth(2)
        wav_file.setframerate(44100)
        wav_file.writeframes(audio_data)
    print(f"Audio saved to {filepath}")

client = ZhipuAI(api_key="YOUR API KEY") # Fill in your own APIKey

response = client.chat.completions.create(
    model="glm-4-voice",  # Fill in the model name you want to call
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "input_audio",
                    "input_audio": {
                        "data": "<base64_string>",
                        "format":"wav"
                    }
                }
            ]
        },
        {
            "role": "assistant",
            "audio": {
                "id": "dc85d58d-b339-488e-ad95-2f45119517ff"
            }
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "Not funny, tell another one"
                }
            ]
        },
    ],
    max_tokens=1024,
    stream=False
)
print(response)
# Get audio data
audio_data = response.choices[0].message.audio['data']
decoded_data = base64.b64decode(audio_data)
# Write the decoded data to a WAV file
with open("output.wav", 'wb') as wav_file:
    wav_file.write(decoded_data)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37  
38  
39  
40  
41  
42  
43  
44  
45  
46  
47  
48  
49  
50  
51  
52  
53  
54  
55  
56

Table of contents

Synchronous Call

Request Parameters

Message Format

Response Parameters

Request Example

Response Example

Stream Output

Request Example

Response Example

Multi-turn Dialogue Example