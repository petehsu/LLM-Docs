[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fhowuse%2Fvisual-reasoning-model%2Fglm-4.1v-thinking)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

GET STARTED

[* Overview](/dev/howuse/introduction)

[* Models](/dev/howuse/model)

[* Scenario Examples](/dev/howuse/openpower)

LEARN ABOUT MODELS

* Language Model

  [+ GLM-4-Plus](/dev/howuse/llm/glm-4-plus)

  [+ GLM-4-Air-250414](/dev/howuse/llm/GLM-4-Air-250414)

  [+ GLM-4-AirX](/dev/howuse/llm/GLM-4-AirX)

  [+ GLM-4-Long](/dev/howuse/llm/GLM-4-Long)

  [+ GLM-4-FlashX-250414](/dev/howuse/llm/GLM-4-FlashX-250414)

* Reasoning Model

  [+ GLM-Z1-Air](/dev/howuse/reasoning_models/GLM-Z1-Air)

  [+ GLM-Z1-AirX](/dev/howuse/reasoning_models/GLM-Z1-AirX)

  [+ GLM-Z1-FlashX](/dev/howuse/reasoning_models/GLM-Z1-FlashX)

* Visual Language Model

  [+ GLM-4V-Plus-0111](/dev/howuse/vlm/GLM-4V-Plus-0111)

* GLM-4.1V-Thinking

  [+ GLM-4.1V-Thinking](/dev/howuse/visual-reasoning-model/glm-4.1v-thinking)

* Image Generation Model

  [+ CogView-4](/dev/howuse/image-generation-model/cogview-4)

* Video Generation Model

  [+ CogVideoX-3](/dev/howuse/video-generation-model/CogVideoX-3)

  [+ CogVideoX-2](/dev/howuse/video-generation-model/CogVideoX-2)

  [+ Vidu Q1](/dev/howuse/video-generation-model/ViduQ1)

  [+ Vidu 2](/dev/howuse/video-generation-model/Vidu2)

* Audio and Video Model

  [+ GLM-Realtime](/dev/howuse/audio-and-video-model/GLM-Realtime)

  [+ GLM-4-Voice](/dev/howuse/audio-and-video-model/GLM-4-Voice)

  [+ GLM-ASR](/dev/howuse/audio-and-video-model/GLM-ASR)

CAPABILITIES

[* Web Search](/dev/howuse/websearch)

[* Function Call](/dev/howuse/functioncall)

[* Retrieval](/dev/howuse/retrieval)

[* Fine-tuning](/dev/howuse/finetuning)

[* FileQA](/dev/howuse/fileqa)

[* evaluator](/dev/howuse/model_evaluator)

[* Batch](/dev/howuse/batchapi)

[* Sandbox](/dev/howuse/glm4-toolkit)

[* JSON Format](/dev/howuse/jsonformat)

Agent Development Platform

[* help\_document](/dev/howuse/help_document)

GUIDES

[* Prompt Engineering](/dev/howuse/prompt)

[* Content security](/dev/howuse/securityaudit)

[* Model Migrate](/dev/howuse/model-migration)

[* User Benefits](/dev/howuse/equity-explain)

[* Model Filing](/dev/howuse/Filing)

POLICIES

[* User Agreement](/dev/howuse/useragreement)

[* Privacy Policy](/dev/howuse/privacypolicy)

[* Platform Agreement](/dev/howuse/serviceagreement)

[* Recharge Agreement](/dev/howuse/rechargeagreement)

[* Termination Agreement](/dev/howuse/termination-agreement)

[* Account Change](/dev/howuse/subjectchanage)

[* University X Plan - Application Instructions](/dev/howuse/application-agreement)

[* AI Principle](/dev/howuse/principle)

[* Security & Risk](/dev/howuse/safetytips)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

# GLM-4.1V-Thinking

The GLM-4.1V-Thinking series is the most powerful visual reasoning model known at the 10B parameter scale. It achieves new state-of-the-art performance in key areas such as chart and video understanding, front-end coding, and GUI tasks. By introducing a chain-of-thought reasoning mechanism, it significantly enhances accuracy and interpretability in complex scenarios.

| **Model version** | **Positioning** | **Price** | **Input Modality** | **Output Modality** | **Context Window** |
| --- | --- | --- | --- | --- | --- |
| GLM-4.1V-Thinking-Flash | Free version | / | Video/Image/Document | Text | 64K |
| GLM-4.1V-Thinking-FlashX | High-concurrency version | 2 RMB per million tokens | Video/Image/Document | Text | 64K |

**Limited-time launch offer: ‚Äã**[Click to claim 100 million tokens of the High-Concurrency Version for free.](https://bigmodel.cn/login?redirect=%2Ftokenspropay%3FproductIds%3Dproduct-e6e499%26utm_source%3DbigModel%26utm_medium%3Dusebook%26utm_content%3Dglm-4.1v%26utm_campaign%3DPlatform_Ops%26_channel_track_key%3Dw4l7aUX1)

## **Recommended Use Cases**

* **Image General:** Accurately recognizes and comprehensively analyzes both visual and textual information.
* **Math & Science:** Supports complex problem solving, multi-step deduction, and formula comprehension.
* **Video:** Capable of temporal analysis and event logic modeling.
* **UI2Code, Agent:** Understands interface structure to assist with automated operations.
* **Grounding:** Precisely aligns language with image regions to enhance controllability in human-computer interaction.

## **Resources**

* [Experience Center](https://www.bigmodel.cn/login?redirect=%2Ftrialcenter%2Fmodeltrial%2Fmultimodal%3FmodelCode%3Dglm-4.1v-thinking-flashx) **:** Quickly test the model‚Äôs performance in business scenarios.
* [API Documentation](https://www.bigmodel.cn/dev/api/visual-reasoning-model/GLM-4.1V-Thinking) : Learn how to call the API.

## **Detailed Description**

1. **Achieves SOTA across multiple vision-language benchmarks**

The GLM-4.1V-Thinking model achieves breakthrough performance while maintaining efficient deployment. **In 28 authoritative benchmarks‚Äîincluding MMStar, MMMU-Pro, ChartQAPro, and ‚Äã**‚Äã**OSWorld‚Äîit**‚Äã‚Äã**‚Äã secured top scores among 10B-scale models in 23 tasks. Remarkably, it matched or outperformed mainstream VLMs with 8 times more parameters in 18 of those benchmarks**‚Äã, demonstrating the extreme performance potential of compact models.  
![Description](https://cdn.bigmodel.cn/markdown/1751371876183image.png?attname=image.png)

Notably, the model demonstrates exceptional adaptability in recommendation-related tasks, with its high generality and robustness standing out in complex business scenarios.

2. **‚Äã Leading reasoning capabilities**

Built upon the GLM-4V architecture, GLM-4.1V-Thinking introduces a **chain-of-thought reasoning mechanism** and adopts a curriculum sampling reinforcement learning strategy, systematically enhancing the model‚Äôs cross-modal causal reasoning capabilities and stability. With its strengthened reasoning abilities, GLM-4.1V-Thinking demonstrates significantly improved problem-solving performance in complex real-world applications such as scientific research, education, autonomous agents, and multimodal assistants.

## Use Cases

### 1.Image Question Answering

| Prompt | Generated result |
| --- | --- |
| DescriptionPlease identify the company with the highest annual profit in this chart, as well as its largest department. | Sony has the highest annual profit at $6.3B. For Sony, the note states, ‚ÄúMedia is Sony‚Äôs second - largest segment after game consoles.‚Äù Thus, the largest segment is game consoles. |

### 2.GUI Agent

| Prompt | Generated result |
| --- | --- |
| DescriptionIn the app, please help me create a meeting with Dr. Smith at 3:00 PM two weeks from now. | Action: {‚Äúaction\_type‚Äù: ‚Äúclick‚Äù, ‚Äúbox\_2d‚Äù: [[27,840,122,885]]} |

### 3.Front-end Web Coding

| Prompt | Generated result |
| --- | --- |
| DescriptionPlease build a web page similar to the input image and convert it into React code. | Screenshot of the web page from the generated React code:Description |

## Example

```
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # Fill in your own APIKey
response = client.chat.completions.create(
    model="glm-4.1v-thinking-flashx",  # Fill in the model name to be called
    messages=[
       {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "Please help me solve this problem and provide a detailed solution along with the final answer."
          },
          {
            "type": "image_url",
            "image_url": {
                "url" : "Input image URL"
            }
          }
        ]
      }
    ]
)
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23

## **User Concurrency Rights**

API calls are subject to rate limits. Currently, we limit the number of concurrent requests (the number of in-flight request tasks). The concurrency guarantees for different user tiers are as follows.

| Model version | V0 | V1 | V2 | V3 |
| --- | --- | --- | --- | --- |
| GLM-4.1V-Thinking-Flash | 5 | 10 | 15 | 20 |
| GLM-4.1V-Thinking-FlashX | 30 | 50 | 80 | 100 |

Table of contents

Recommended Use Cases

Resources

Detailed Description

Use Cases

1.Image Question Answering

2.GUI Agent

3.Front-end Web Coding

Example

User Concurrency Rights