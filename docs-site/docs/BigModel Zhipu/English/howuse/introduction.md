[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fhowuse%2Fintroduction)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

GET STARTED

[* Overview](/dev/howuse/introduction)

[* Models](/dev/howuse/model)

[* Scenario Examples](/dev/howuse/openpower)

LEARN ABOUT MODELS

* Language Model

  [+ GLM-4-Plus](/dev/howuse/llm/glm-4-plus)

  [+ GLM-4-Air-250414](/dev/howuse/llm/GLM-4-Air-250414)

  [+ GLM-4-AirX](/dev/howuse/llm/GLM-4-AirX)

  [+ GLM-4-Long](/dev/howuse/llm/GLM-4-Long)

  [+ GLM-4-FlashX-250414](/dev/howuse/llm/GLM-4-FlashX-250414)

* Reasoning Model

  [+ GLM-Z1-Air](/dev/howuse/reasoning_models/GLM-Z1-Air)

  [+ GLM-Z1-AirX](/dev/howuse/reasoning_models/GLM-Z1-AirX)

  [+ GLM-Z1-FlashX](/dev/howuse/reasoning_models/GLM-Z1-FlashX)

* Visual Language Model

  [+ GLM-4V-Plus-0111](/dev/howuse/vlm/GLM-4V-Plus-0111)

* GLM-4.1V-Thinking

  [+ GLM-4.1V-Thinking](/dev/howuse/visual-reasoning-model/glm-4.1v-thinking)

* Image Generation Model

  [+ CogView-4](/dev/howuse/image-generation-model/cogview-4)

* Video Generation Model

  [+ CogVideoX-3](/dev/howuse/video-generation-model/CogVideoX-3)

  [+ CogVideoX-2](/dev/howuse/video-generation-model/CogVideoX-2)

  [+ Vidu Q1](/dev/howuse/video-generation-model/ViduQ1)

  [+ Vidu 2](/dev/howuse/video-generation-model/Vidu2)

* Audio and Video Model

  [+ GLM-Realtime](/dev/howuse/audio-and-video-model/GLM-Realtime)

  [+ GLM-4-Voice](/dev/howuse/audio-and-video-model/GLM-4-Voice)

  [+ GLM-ASR](/dev/howuse/audio-and-video-model/GLM-ASR)

CAPABILITIES

[* Web Search](/dev/howuse/websearch)

[* Function Call](/dev/howuse/functioncall)

[* Retrieval](/dev/howuse/retrieval)

[* Fine-tuning](/dev/howuse/finetuning)

[* FileQA](/dev/howuse/fileqa)

[* evaluator](/dev/howuse/model_evaluator)

[* Batch](/dev/howuse/batchapi)

[* Sandbox](/dev/howuse/glm4-toolkit)

[* JSON Format](/dev/howuse/jsonformat)

Agent Development Platform

[* help\_document](/dev/howuse/help_document)

GUIDES

[* Prompt Engineering](/dev/howuse/prompt)

[* Content security](/dev/howuse/securityaudit)

[* Model Migrate](/dev/howuse/model-migration)

[* User Benefits](/dev/howuse/equity-explain)

[* Model Filing](/dev/howuse/Filing)

POLICIES

[* User Agreement](/dev/howuse/useragreement)

[* Privacy Policy](/dev/howuse/privacypolicy)

[* Platform Agreement](/dev/howuse/serviceagreement)

[* Recharge Agreement](/dev/howuse/rechargeagreement)

[* Termination Agreement](/dev/howuse/termination-agreement)

[* Account Change](/dev/howuse/subjectchanage)

[* University X Plan - Application Instructions](/dev/howuse/application-agreement)

[* AI Principle](/dev/howuse/principle)

[* Security & Risk](/dev/howuse/safetytips)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

# Introduction

The Zh√¨p«î AI Open Platform offers a variety of large models with different functionalities and pricing, including general-purpose large models, super-humanoid large models, image large models, and vector large models. It also supports fine-tuning these models using your private data.

On January 16, 2024, we launched the new generation of foundational large model, GLM-4, at the ‚ÄòZh√¨p«î AI Technology Open Day (ZHIPU DevDay)‚Äô.  
[](https://cdn.bigmodel.cn/static/platform/videos/usage-guide/GLM4-press-conference.mp4)

## Resources

* View the model [API documentation](https://www.bigmodel.cn/dev/api/normal-model/glm-4)
* Experience model capabilities in the [Trial Center](https://www.bigmodel.cn/console/trialcenter)
* Check your [API Key](https://www.bigmodel.cn/usercenter/apikeys)
* [Create a Knowledge Base](https://www.bigmodel.cn/console/appcenter_v1/knowledge)
* Create applications in the [Application Center](https://www.bigmodel.cn/console/appcenter_v1/application/myapp)

## Key Concepts

#### GLM

GLM, short for General Language Model, is a pre-trained language model based on autoregressive filling. The ChatGLM series models support relatively complex natural language instructions and are capable of solving difficult reasoning problems. Equipped with an easy-to-use API interface, this model allows developers to seamlessly integrate it into various applications. It is widely used in fields such as intelligent customer service, virtual anchors, chatbots, and more.

#### Embedding

Embedding is a method of representing data (such as text) in vector form. This representation ensures that data similar in certain specific aspects are close to each other in vector space, while unrelated data are farther apart. By converting text strings into vectors, the data can be effectively used in applications such as search, clustering, recommendation systems, anomaly detection, and classification.

#### Token

A token is the basic unit used by the model to represent natural language text, which can be intuitively understood as a ‚Äúcharacter‚Äù or ‚Äúword.‚Äù Typically, one Chinese word, one English word, one number, or one symbol is counted as one token.

In general, the conversion ratio of tokens to characters in the ChatGLM series models is about 1:1.6. However, due to different tokenization methods in different models, the conversion ratio may vary. The actual number of tokens processed each time is determined by the model‚Äôs response, which you can view in the usage field of the returned results.

Table of contents

Resources

Key Concepts