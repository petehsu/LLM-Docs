[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fhowuse%2Fllm%2Fglm-4-plus)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

GET STARTED

[* Overview](/dev/howuse/introduction)

[* Models](/dev/howuse/model)

[* Scenario Examples](/dev/howuse/openpower)

LEARN ABOUT MODELS

* Language Model

  [+ GLM-4-Plus](/dev/howuse/llm/glm-4-plus)

  [+ GLM-4-Air-250414](/dev/howuse/llm/GLM-4-Air-250414)

  [+ GLM-4-AirX](/dev/howuse/llm/GLM-4-AirX)

  [+ GLM-4-Long](/dev/howuse/llm/GLM-4-Long)

  [+ GLM-4-FlashX-250414](/dev/howuse/llm/GLM-4-FlashX-250414)

* Reasoning Model

  [+ GLM-Z1-Air](/dev/howuse/reasoning_models/GLM-Z1-Air)

  [+ GLM-Z1-AirX](/dev/howuse/reasoning_models/GLM-Z1-AirX)

  [+ GLM-Z1-FlashX](/dev/howuse/reasoning_models/GLM-Z1-FlashX)

* Visual Language Model

  [+ GLM-4V-Plus-0111](/dev/howuse/vlm/GLM-4V-Plus-0111)

* GLM-4.1V-Thinking

  [+ GLM-4.1V-Thinking](/dev/howuse/visual-reasoning-model/glm-4.1v-thinking)

* Image Generation Model

  [+ CogView-4](/dev/howuse/image-generation-model/cogview-4)

* Video Generation Model

  [+ CogVideoX-3](/dev/howuse/video-generation-model/CogVideoX-3)

  [+ CogVideoX-2](/dev/howuse/video-generation-model/CogVideoX-2)

  [+ Vidu Q1](/dev/howuse/video-generation-model/ViduQ1)

  [+ Vidu 2](/dev/howuse/video-generation-model/Vidu2)

* Audio and Video Model

  [+ GLM-Realtime](/dev/howuse/audio-and-video-model/GLM-Realtime)

  [+ GLM-4-Voice](/dev/howuse/audio-and-video-model/GLM-4-Voice)

  [+ GLM-ASR](/dev/howuse/audio-and-video-model/GLM-ASR)

CAPABILITIES

[* Web Search](/dev/howuse/websearch)

[* Function Call](/dev/howuse/functioncall)

[* Retrieval](/dev/howuse/retrieval)

[* Fine-tuning](/dev/howuse/finetuning)

[* FileQA](/dev/howuse/fileqa)

[* evaluator](/dev/howuse/model_evaluator)

[* Batch](/dev/howuse/batchapi)

[* Sandbox](/dev/howuse/glm4-toolkit)

[* JSON Format](/dev/howuse/jsonformat)

Agent Development Platform

[* help\_document](/dev/howuse/help_document)

GUIDES

[* Prompt Engineering](/dev/howuse/prompt)

[* Content security](/dev/howuse/securityaudit)

[* Model Migrate](/dev/howuse/model-migration)

[* User Benefits](/dev/howuse/equity-explain)

[* Model Filing](/dev/howuse/Filing)

POLICIES

[* User Agreement](/dev/howuse/useragreement)

[* Privacy Policy](/dev/howuse/privacypolicy)

[* Platform Agreement](/dev/howuse/serviceagreement)

[* Recharge Agreement](/dev/howuse/rechargeagreement)

[* Termination Agreement](/dev/howuse/termination-agreement)

[* Account Change](/dev/howuse/subjectchanage)

[* University X Plan - Application Instructions](/dev/howuse/application-agreement)

[* AI Principle](/dev/howuse/principle)

[* Security & Risk](/dev/howuse/safetytips)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

## **GLM-4-Plus**

**GLM-4-Plus is the most advanced and intelligent flagship model available on the Zhipu BigModel open platform to date.** It leads globally in areas such as language understanding, logical reasoning, instruction following, and long-text processing.

| **Price** | **Input Modality** | **Output Modality** | **Context Window** | **Maximum Output Tokens** |
| --- | --- | --- | --- | --- |
| 5 RMB per million tokens | Text | Text | 128K | 4K |

### **Recommended Use Cases**

1. **Translation:** In addition to multilingual translation, it can accurately handle texts with mixed languages, tones, slang, emojis, and technical terms, while also respecting cultural nuances.
2. **Intelligent Data Classification:** Based on semantic understanding, it can automatically classify and label complex heterogeneous data with high precision. It can design multi-dimensional evaluation metrics based on business objectives and use model validation to ensure the reliability of the results.
3. **Document Information Extraction:** Capable of comprehending and analyzing massive amounts of text, it can accurately extract structured fields such as project numbers and amounts, with an average accuracy rate of over 93%. By combining domain-specific expert prompts, it can also semantically infer and classify complex clauses.
4. **Hit Content Creation:** Quickly generates diverse, stylistically consistent, and attractive high-quality copy, covering social media posts, advertising slogans, product detail pages, marketing emails, and key event descriptions. (Recommended to combine with [search tools](https://www.bigmodel.cn/dev/howuse/websearch)  for more real-time, accurate, and high-quality results)
5. **Risk Assessment Reports:** Rapidly analyzes vast amounts of the latest industry data, policy documents, and market trends to identify potential risks, automatically producing risk assessment reports that meet business needs, efficiently completing risk classification and strategy ormulation. (Recommended to combine with [search tools](https://www.bigmodel.cn/dev/howuse/websearch) for more real-time, accurate, and high-quality results)
6. **Smart Itinerary Planning:** Tailors travel plans to user preferences, budget requirements, and time constraints by integrating information such as transportation, weather, and accommodation costs, creating personalized itineraries covering transportation connections, accommodations, and sightseeing. (Recommended to combine with [search tools](https://www.bigmodel.cn/dev/howuse/websearch)  for more real-time, accurate, and high-quality results)

### **Resources**

* [Experience Center](https://bigmodel.cn/login?redirect=%2Ftrialcenter%2Fmodeltrial%2Ftext%3FmodelCode%3Dglm-4-plus) **:** Quickly test the model‚Äôs performance in business scenarios.
* [API Documentation](https://bigmodel.cn/dev/api/normal-model/glm-4) : Learn how to call the API.

### **Detailed Description**

GLM-4-Plus serves as the robust foundation of the entire Zhipu model family, achieving significant performance improvements and cost reductions in areas such as code computation, data analysis, and image/video feature recognition.

1. #### **Language Capabilities**

GLM-4-Plus uses extensive model-assisted high-quality synthetic data to improve performance and employs PPO (Proximal Policy Optimization) to enhance reasoning tasks (math, code, etc.), aligning more closely with human preferences. In comparative testing with OpenAI GPT-4o, GLM-4-Plus achieves near or even better performance on most tasks.

| Models | AlignBench | MMLU | MATH | GPQA | LCB | NCB | IFEval |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Claude 3.5 Sonnet | 80.7 | 88.3 | 71.1 | \*56.4 | 49.8 | 53.1 | 80.6 |
| Llama 3.1 405B | 60.7 | 88.6 | 73.8 | \*50.1 | \*39.4 | 50 | 83.9 |
| Gemini 1.5Pro | 74.7 | 85.9 | 67.7 | 46.2 | 33.6 | 42.3 | 74.4 |
| GPT-4o | 83.8 | 88.7 | 76.6 | \*51.0 | \*45.5 | 52.3 | 81.9 |
| GLM-4-Plus | 83.2 | 86.8 | 74.2 | 50.7 | \*45.8 | 50.4 | 79.5 |
| GLM-4-Plus/GPT-4o | 99% | 98% | 97% | 99% | 101% | 96% | 97% |
| GLM-4-Plus/Claude 3.5 Sonnet | 103% | 98% | 104% | 85% | 92% | 95% | 99% |

During its release period, GLM-4-Plus ranked among the world‚Äôs top three in the SuperBench large model evaluation.

![](https://zhipu-ai.feishu.cn/space/api/box/stream/download/asynccode/?code=ODkxZmZhMDg5NDBmZTZlYmJjMjUyMWIwYTUyNTlkNDlfbFBYRVRxS2IzdkhSdVVRb0RpMnNDOTNvWnp3TWFOMG9fVG9rZW46RHpJV2JmVFhxb1ZaSFR4MzJRSGNZNEdrbnlmXzE3NDk1NDA3NjU6MTc0OTU0NDM2NV9WNA)

2. #### **Long-Text Capabilities**

In long-text processing, GLM-4-Plus uses a more precise mix of long and short text data, significantly enhancing reasoning performance and improving understanding and processing of lengthy texts. This greatly mitigates the performance drop caused by excessive prompts in enterprise deployment scenarios.

| Models | LongBench-Chat | InfiniteBench/EN.MC | Ruler |
| --- | --- | --- | --- |
| Mistral-123B | 8.2 | 38.9 | 80.5 |
| Llama 405B | 8.6 | 83.4 | 91.5 |
| Claude Sonnet 3.5 | 8.6 | 79.5 | - |
| Gemini 1.5 Pro | 8.6 | 80.9 | 95.8 |
| GPT-4o | 9 | 82.5 | - |
| GLM-4-Plus | 8.8 | 85.1 | 93 |
| GLM-4-Plus/GPT-4o | 98% | 103% | - |
| GLM-4-Plus/Claude 3.5 Sonnet | 102% | 107% | - |

### **Features Supported**

* Streaming Output
* Structured Output
* Function Calling

### **Example**

Below is a complete example call to help you get started quickly with the GLM-4-Plus model.

```
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # Fill in your own APIKey
response = client.chat.completions.create(
    model="glm-4-plus",  # Fill in the model name to be called
    messages=[
        {"role": "system", "content": "You are a helpful assistant dedicated to answering a wide range of questions. Your task is to provide users with professional, accurate, and insightful advice."},
        {"role": "user", "content": "A farmer needs to ferry a wolf, a sheep, and a cabbage across a river, but he can only carry one item at a time. The wolf and the sheep cannot be left alone together, and the sheep and the cabbage cannot be left alone together. How can the farmer successfully ferry everything across the river?"}
    ],
)
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10

### **User Concurrency Rights**

API calls are subject to rate limits. Currently, we limit the number of concurrent requests (the number of in-flight request tasks). The concurrency guarantees for different user tiers are as follows.

| V0 | V1 | V2 | V3 |
| --- | --- | --- | --- |
| 50 | 100 | 300 | 500 |

Table of contents

GLM-4-Plus

Recommended Use Cases

Resources

Detailed Description

Features Supported

Example

User Concurrency Rights