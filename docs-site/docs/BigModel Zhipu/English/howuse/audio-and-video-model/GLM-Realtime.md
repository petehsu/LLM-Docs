[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fhowuse%2Faudio-and-video-model%2FGLM-Realtime)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

GET STARTED

[* Overview](/dev/howuse/introduction)

[* Models](/dev/howuse/model)

[* Scenario Examples](/dev/howuse/openpower)

LEARN ABOUT MODELS

* Language Model

  [+ GLM-4-Plus](/dev/howuse/llm/glm-4-plus)

  [+ GLM-4-Air-250414](/dev/howuse/llm/GLM-4-Air-250414)

  [+ GLM-4-AirX](/dev/howuse/llm/GLM-4-AirX)

  [+ GLM-4-Long](/dev/howuse/llm/GLM-4-Long)

  [+ GLM-4-FlashX-250414](/dev/howuse/llm/GLM-4-FlashX-250414)

* Reasoning Model

  [+ GLM-Z1-Air](/dev/howuse/reasoning_models/GLM-Z1-Air)

  [+ GLM-Z1-AirX](/dev/howuse/reasoning_models/GLM-Z1-AirX)

  [+ GLM-Z1-FlashX](/dev/howuse/reasoning_models/GLM-Z1-FlashX)

* Visual Language Model

  [+ GLM-4V-Plus-0111](/dev/howuse/vlm/GLM-4V-Plus-0111)

* GLM-4.1V-Thinking

  [+ GLM-4.1V-Thinking](/dev/howuse/visual-reasoning-model/glm-4.1v-thinking)

* Image Generation Model

  [+ CogView-4](/dev/howuse/image-generation-model/cogview-4)

* Video Generation Model

  [+ CogVideoX-3](/dev/howuse/video-generation-model/CogVideoX-3)

  [+ CogVideoX-2](/dev/howuse/video-generation-model/CogVideoX-2)

  [+ Vidu Q1](/dev/howuse/video-generation-model/ViduQ1)

  [+ Vidu 2](/dev/howuse/video-generation-model/Vidu2)

* Audio and Video Model

  [+ GLM-Realtime](/dev/howuse/audio-and-video-model/GLM-Realtime)

  [+ GLM-4-Voice](/dev/howuse/audio-and-video-model/GLM-4-Voice)

  [+ GLM-ASR](/dev/howuse/audio-and-video-model/GLM-ASR)

CAPABILITIES

[* Web Search](/dev/howuse/websearch)

[* Function Call](/dev/howuse/functioncall)

[* Retrieval](/dev/howuse/retrieval)

[* Fine-tuning](/dev/howuse/finetuning)

[* FileQA](/dev/howuse/fileqa)

[* evaluator](/dev/howuse/model_evaluator)

[* Batch](/dev/howuse/batchapi)

[* Sandbox](/dev/howuse/glm4-toolkit)

[* JSON Format](/dev/howuse/jsonformat)

Agent Development Platform

[* help\_document](/dev/howuse/help_document)

GUIDES

[* Prompt Engineering](/dev/howuse/prompt)

[* Content security](/dev/howuse/securityaudit)

[* Model Migrate](/dev/howuse/model-migration)

[* User Benefits](/dev/howuse/equity-explain)

[* Model Filing](/dev/howuse/Filing)

POLICIES

[* User Agreement](/dev/howuse/useragreement)

[* Privacy Policy](/dev/howuse/privacypolicy)

[* Platform Agreement](/dev/howuse/serviceagreement)

[* Recharge Agreement](/dev/howuse/rechargeagreement)

[* Termination Agreement](/dev/howuse/termination-agreement)

[* Account Change](/dev/howuse/subjectchanage)

[* University X Plan - Application Instructions](/dev/howuse/application-agreement)

[* AI Principle](/dev/howuse/principle)

[* Security & Risk](/dev/howuse/safetytips)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

## GLM-Realtime

GLM-Realtime is an audio-video call model that offers real-time video call functionality with a conversation memory of up to 2 minutes. It is capable of real-time reasoning across text, audio, and video.

| **Price** | **Input Modality** | **Output Modality** | **Context Window** | **Maximum Output Tokens** |
| --- | --- | --- | --- | --- |
| Limited-Time Free | Video/Audio/Text | Audio | -Audio (voice call): 8K; approximately 20 rounds - Video (video call): 32K | 1K |

### **Recommended Use Cases**

* **Speaking Practice:** Through real-time conversation and video feedback, it provides instant pronunciation correction for users, supporting video capture of facial expressions, object recognition, and document browsing.
* **Real-Time Translation:** Supports multilingual real-time conversations, automatically recognizing languages and enabling natural language interaction with instant translation, comparable to a professional interpreter.
* **Interview Simulation:** AI can act as an interviewer to simulate real interview scenarios, intelligently matching interview questions based on different job requirements and candidate profiles.
* **Travel Guide:** Simulates professional tour guide explanations of attractions, history, and culture, supporting video dialogue mode for an immersive experience.

### **Resources**

* [API Documentation](https://bigmodel.cn/dev/api/rtav/GLM-Realtime) : Learn how to call the API.

### **Detailed Description**

GLM-Realtime reduces video call latency through streaming inference, enabling the AI to engage in smooth conversations while allowing human users to interrupt the AI in real time. In addition to real-time audio interaction, GLM-Realtime can also interact with people through smartphone or AIPC cameras, read page information via shared computer screens, and understand the current environment of the conversation through video streaming.

[](https://cdn.bigmodel.cn/static/platform/videos/doc_solutions/Realtime-%E5%94%B1%E6%AD%8C.m4v)  
In terms of voice interaction, GLM-Realtime innovatively introduces the ability to sing a cappella, marking the first time that a large model is capable of singing in dialogue.

At the same time, we have integrated the GLM-Realtime API into smart glasses and companion dolls, allowing users to experience near-real-time intelligent assistant interactions.

It is worth mentioning that GLM-Realtime also supports the Function Call feature. This enables the model not only to rely on its own knowledge and abilities but also to flexibly call external knowledge and tools, thus expanding into a wider range of business scenarios.

[](https://cdn.bigmodel.cn/static/platform/videos/doc_solutions/Realtime-function%20call.m4v)

### **User Concurrency Rights**

API calls are subject to rate limits. Currently, we limit the number of concurrent requests (the number of in-flight request tasks). The concurrency guarantees for different user tiers are as follows.

| V0 | V1 | V2 | V3 |
| --- | --- | --- | --- |
| 5 | 10 | 15 | 20 |

Table of contents

GLM-Realtime

Recommended Use Cases

Resources

Detailed Description

User Concurrency Rights