# API 调用问题

> API 调用常见问题解答

### 如何调用我们的 API?

您可以参考我们平台提供的 [接口文档](/api-reference/%E6%A8%A1%E5%9E%8B-api/%E5%AF%B9%E8%AF%9D%E8%A1%A5%E5%85%A8) 进行调用。

### 同步、异步、SSE 调用方式有什么区别？

同步、异步、SSE 调用是三种不同的 API 响应方式。

* **SSE 调用**：客户发起请求后，可以流式的实时获取到模型生成的内容直到推理结束，类似于智谱清言 APP 上的打字机效果。该调用方式适用于对首响及响应时长要求较高的场景，如和用户直接进行交互的智能客服、对话闲聊等。我们推荐您使用 SSE 调用，用户体验更好。
* **同步调用**：客户发起请求，模型完成推理后一次性返回全量生成结果。
* **异步调用**：客户发起请求后，需要用户调用异步接口结果查询模型处理状态和推理结果，如处理完成，可通过结果查询接口获取到模型生成结果。该调用方式适用于对响应时间不敏感的业务场景，如批量处理数据、批量生成文章等。

### 调用模型时的并发限制是多少？

您可以参考 [速率限制](https://www.bigmodel.cn/usercenter/corporateequity) 了解当前的并发以及如何提升您的并发数。

### temperature 和 top\_p 参数该如何设置？

在大语言模型中，temperature 和 top\_p 参数用于调节生成文本的多样性和质量。

* **temperature** 参数用于控制模型输出结果的随机性，取值范围是: \[0.0,1.0]。值越大，生成的文本越随机，值越小，生成的文本越稳定；
* **top\_p** 参数用于控制模型输出结果中单词或词组的概率分布，取值范围是：\[0.0,1.0]。值越大，模型会在更多单词或词组中进行选择，增加输出结果的随机性，值越小，模型会在更少的单词或词组中进行选择，增加输出结果的稳定性。

要获得更有创意、更多样性的回答，可将 temperature 设为较高值或 top\_p 设为较高值；要获得更稳定、更有确定性的回答，可将 temperature 设为较低值或 top\_p 设为较低值。您可根据实际的应用场景调整 temperature 或 top\_p 参数，但不要同时调整这两个参数。

### 如何使用函数调用能力？

您可参考 [函数调用使用文档](/cn/guide/capabilities/function-calling) 了解调用逻辑。

### tools 列表支持传多个函数吗？

tools 支持传多个函数，但每次调用只能命中一个。

### 函数调用，知识库检索，网络搜索可以全部添加到 tools 参数里吗？

函数调用、知识库检索、网络搜索，3个功能互斥。如果同时使用，按照优先级只会生效一个。优先级顺序为：函数调用>知识库检索>网络搜索。

### 模型微调怎么做？

目前可通过提交 模型微调接口文档 [开发者 Pro 版平台服务权益](https://open.bigmodel.cn/tokenspropay?productIds=product-001)申请 获得 GLM-4-Flash 模型微调权限，其他模型的微调能力会陆续迭代。开通权限后可通过模型微调接口文档了解调用详情。

您也可以购买我们的云端私有化服务，获得私有化部署及模型微调服务，请随时 [ 联系我们](https://open.bigmodel.cn/online-book/modelLocalDeployment?channel_track_key=modelLocalDeployment)，我们的咨询顾问将为您详细介绍。

### 对话模型如何实现联系上下文？或如何实现多轮对话？

对话模型联系上下文（或实现多轮对话），需要您将之前的对话记录作为参数传过来，传参 messages 示例如下：

```json  theme={null}
messages=[

{"role": "user", "content": "作为一名营销专家，请为我的产品创作一个吸引人的slogan"},

{"role": "assistant", "content": "当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息"},

{"role": "user", "content": "智谱AI开放平台"},

{"role": "assistant", "content": "智启未来，谱绘无限一智谱AI，让创新触手可及\!"},

{"role": "user", "content": "创造一个更精准、吸引人的slogan"}

]
```

### 模型上下文、最大输入、最大输出分别有限制吗？

* 模型上下文、最大输出限制请参考文档：[模型概览](/cn/guide/start/model-overview)
* 模型最大输入限制 = 模型上下文 - 最大输出

### glm4v 系列模型支持本地图片吗？

glm4v 系列模型支持传参 base64 格式的本地图片或图片 url 地址

### glm-4v 系列支持传参多张图片吗？

GLM-4V-Plus-0111: 具备卓越的多模态理解能力，可同时处理最多 5 张图像，并支持视频内容理解（视频大小 ＜200M），适用于复杂的多媒体分析场景；

GLM-4V-Flash（免费）：专注于高效的单一图像理解，适用于单张图像解析的场景。

### 异步任务有过期时间吗？

异步任务没有过期时间

### 调用对话 API 接口时，使用了 web\_search，但模型返回结果为什么还是跟没联网一样？

原因可能是：

* 使用 Web\_Search 工具传参时，未传 enable 参数，该参数默认为 false，需要传 true 才能开启联网
* 搜索引擎未搜索到相关内容，可设置 Web\_Search 工具中的 search\_result 参数为 true，看是否有返回的搜索来源确认搜索引擎是否搜索到相关内容
* 如还未解决，可联系人工客服

### 如何创建自己的智能体？

您可以参考下[智能体开发文档](/cn/guide/platform/intelligent-agent)

### 如何用 API 接口调用自己创建的智能体？

您可以参考下清流智能体 API 接口文档：[清流智能体 API](/api-reference/%E6%99%BA%E8%83%BD%E4%BD%93-api%EF%BC%88%E6%97%A7%EF%BC%89/%E8%8E%B7%E5%8F%96%E6%99%BA%E8%83%BD%E4%BD%93%E8%BE%93%E5%85%A5%E5%8F%82%E6%95%B0)

### 模型微调后支持下载吗？

目前微调的模型不支持下载


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.bigmodel.cn/llms.txt