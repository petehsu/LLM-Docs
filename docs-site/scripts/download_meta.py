#!/usr/bin/env python3
"""
Meta Llama API æ–‡æ¡£æ‰¹é‡ä¸‹è½½å·¥å…·

URL: https://llama.developer.meta.com/docs/
è¿™æ˜¯ React SPAï¼Œéœ€è¦ Playwright æ¸²æŸ“é¡µé¢æå–å†…å®¹
"""

import sys
import time
import re
import asyncio
from pathlib import Path
from playwright.async_api import async_playwright
from markdownify import markdownify as md

sys.stdout.reconfigure(line_buffering=True)

OUTPUT_BASE = "Meta Llama/docs"

# å…¥å£é¡µé¢
ENTRY_URL = "https://llama.developer.meta.com/docs/overview"


async def get_all_links(page):
    """ä»ä¾§è¾¹æ è·å–æ‰€æœ‰æ–‡æ¡£é“¾æ¥"""
    print("  ç­‰å¾…é¡µé¢åŠ è½½...")
    await page.goto(ENTRY_URL, wait_until="networkidle", timeout=60000)
    await page.wait_for_timeout(3000)
    
    # æå–ä¾§è¾¹æ é“¾æ¥
    links = await page.evaluate('''() => {
        const links = [];
        document.querySelectorAll('a[href^="/docs/"]').forEach(a => {
            const href = a.getAttribute('href');
            if (href && !href.includes('#')) {
                links.push(href);
            }
        });
        return [...new Set(links)];
    }''')
    
    return sorted(set(links))


async def download_page(page, path):
    """ä¸‹è½½å•ä¸ªé¡µé¢"""
    url = f"https://llama.developer.meta.com{path}"
    
    # è¾“å‡ºè·¯å¾„
    rel_path = path.replace('/docs/', '', 1)
    if not rel_path:
        rel_path = 'index'
    output = f"{OUTPUT_BASE}/{rel_path}.md"
    
    # è·³è¿‡å·²å­˜åœ¨
    if Path(output).exists():
        return True, "è·³è¿‡"
    
    try:
        await page.goto(url, wait_until="networkidle", timeout=60000)
        await page.wait_for_timeout(2000)
        
        # æå–ä¸»å†…å®¹åŒºåŸŸ
        content_html = await page.evaluate('''() => {
            // å°è¯•å¤šç§é€‰æ‹©å™¨æ‰¾åˆ°ä¸»å†…å®¹
            const selectors = [
                'article',
                '[role="main"]',
                'main',
                '.markdown-body',
                '.doc-content',
            ];
            
            for (const sel of selectors) {
                const el = document.querySelector(sel);
                if (el && el.innerText.length > 100) {
                    return el.innerHTML;
                }
            }
            
            // å›é€€ï¼šå°è¯•æ‰¾æœ€å¤§çš„å†…å®¹åŒºåŸŸ
            const divs = document.querySelectorAll('div');
            let maxDiv = null;
            let maxLen = 0;
            divs.forEach(div => {
                const text = div.innerText || '';
                if (text.length > maxLen && text.length < 50000) {
                    maxLen = text.length;
                    maxDiv = div;
                }
            });
            
            return maxDiv ? maxDiv.innerHTML : document.body.innerHTML;
        }''')
        
        if not content_html or len(content_html) < 100:
            return False, "å†…å®¹ä¸ºç©º"
        
        # è½¬æ¢ä¸º Markdown
        markdown = md(content_html, heading_style="ATX", strip=['script', 'style', 'nav', 'header', 'footer'])
        
        # æ¸…ç†
        markdown = re.sub(r'\n{3,}', '\n\n', markdown)
        markdown = markdown.strip()
        
        if len(markdown) < 50:
            return False, "è½¬æ¢åå†…å®¹å¤ªçŸ­"
        
        Path(output).parent.mkdir(parents=True, exist_ok=True)
        with open(output, 'w', encoding='utf-8') as f:
            f.write(markdown)
        
        return True, "OK"
    except Exception as e:
        return False, str(e)[:50]


async def main():
    print("=" * 50)
    print("Meta Llama API æ–‡æ¡£ä¸‹è½½å·¥å…·")
    print("=" * 50)
    
    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=True,
            proxy={"server": "http://127.0.0.1:10808"}
        )
        page = await browser.new_page()
        
        # è·å–æ‰€æœ‰é“¾æ¥
        print("\nğŸ“‹ çˆ¬å–æ–‡æ¡£é“¾æ¥...")
        docs = await get_all_links(page)
        
        if not docs:
            print("æœªæ‰¾åˆ°æ–‡æ¡£é“¾æ¥")
            await browser.close()
            return
        
        print(f"   å‘ç° {len(docs)} ä¸ªé“¾æ¥")
        
        # ä¿å­˜é“¾æ¥
        with open('meta_links.txt', 'w') as f:
            f.write('\n'.join(docs))
        
        # æ˜¾ç¤ºé“¾æ¥é¢„è§ˆ
        print("\nğŸ“„ é“¾æ¥é¢„è§ˆ:")
        for link in docs[:10]:
            print(f"   {link}")
        if len(docs) > 10:
            print(f"   ... è¿˜æœ‰ {len(docs) - 10} ä¸ª")
        
        # ä¸‹è½½
        print(f"\nğŸ“š å¼€å§‹ä¸‹è½½...")
        success, skipped, fail = 0, 0, 0
        failed_docs = []
        
        for path in docs:
            name = path.split('/')[-1] or 'index'
            ok, status = await download_page(page, path)
            
            if ok:
                if status == "è·³è¿‡":
                    skipped += 1
                else:
                    success += 1
                    print(f"    âœ“ {name}")
            else:
                fail += 1
                failed_docs.append((path, status))
                print(f"    âœ— {name} ({status})")
            
            if status != "è·³è¿‡":
                await page.wait_for_timeout(500)
        
        await browser.close()
        
        print(f"\nâœ… å®Œæˆ: {success} æ–°ä¸‹è½½, {skipped} è·³è¿‡, {fail} å¤±è´¥")
        
        if failed_docs:
            print("\nâŒ å¤±è´¥åˆ—è¡¨:")
            for path, status in failed_docs[:10]:
                print(f"    {path} - {status}")


if __name__ == "__main__":
    asyncio.run(main())
