[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fhowuse%2Fhelp_document)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

GET STARTED

[* Overview](/dev/howuse/introduction)

[* Models](/dev/howuse/model)

[* Scenario Examples](/dev/howuse/openpower)

LEARN ABOUT MODELS

* Language Model

  [+ GLM-4-Plus](/dev/howuse/llm/glm-4-plus)

  [+ GLM-4-Air-250414](/dev/howuse/llm/GLM-4-Air-250414)

  [+ GLM-4-AirX](/dev/howuse/llm/GLM-4-AirX)

  [+ GLM-4-Long](/dev/howuse/llm/GLM-4-Long)

  [+ GLM-4-FlashX-250414](/dev/howuse/llm/GLM-4-FlashX-250414)

* Reasoning Model

  [+ GLM-Z1-Air](/dev/howuse/reasoning_models/GLM-Z1-Air)

  [+ GLM-Z1-AirX](/dev/howuse/reasoning_models/GLM-Z1-AirX)

  [+ GLM-Z1-FlashX](/dev/howuse/reasoning_models/GLM-Z1-FlashX)

* Visual Language Model

  [+ GLM-4V-Plus-0111](/dev/howuse/vlm/GLM-4V-Plus-0111)

* GLM-4.1V-Thinking

  [+ GLM-4.1V-Thinking](/dev/howuse/visual-reasoning-model/glm-4.1v-thinking)

* Image Generation Model

  [+ CogView-4](/dev/howuse/image-generation-model/cogview-4)

* Video Generation Model

  [+ CogVideoX-3](/dev/howuse/video-generation-model/CogVideoX-3)

  [+ CogVideoX-2](/dev/howuse/video-generation-model/CogVideoX-2)

  [+ Vidu Q1](/dev/howuse/video-generation-model/ViduQ1)

  [+ Vidu 2](/dev/howuse/video-generation-model/Vidu2)

* Audio and Video Model

  [+ GLM-Realtime](/dev/howuse/audio-and-video-model/GLM-Realtime)

  [+ GLM-4-Voice](/dev/howuse/audio-and-video-model/GLM-4-Voice)

  [+ GLM-ASR](/dev/howuse/audio-and-video-model/GLM-ASR)

CAPABILITIES

[* Web Search](/dev/howuse/websearch)

[* Function Call](/dev/howuse/functioncall)

[* Retrieval](/dev/howuse/retrieval)

[* Fine-tuning](/dev/howuse/finetuning)

[* FileQA](/dev/howuse/fileqa)

[* evaluator](/dev/howuse/model_evaluator)

[* Batch](/dev/howuse/batchapi)

[* Sandbox](/dev/howuse/glm4-toolkit)

[* JSON Format](/dev/howuse/jsonformat)

Agent Development Platform

[* help\_document](/dev/howuse/help_document)

GUIDES

[* Prompt Engineering](/dev/howuse/prompt)

[* Content security](/dev/howuse/securityaudit)

[* Model Migrate](/dev/howuse/model-migration)

[* User Benefits](/dev/howuse/equity-explain)

[* Model Filing](/dev/howuse/Filing)

POLICIES

[* User Agreement](/dev/howuse/useragreement)

[* Privacy Policy](/dev/howuse/privacypolicy)

[* Platform Agreement](/dev/howuse/serviceagreement)

[* Recharge Agreement](/dev/howuse/rechargeagreement)

[* Termination Agreement](/dev/howuse/termination-agreement)

[* Account Change](/dev/howuse/subjectchanage)

[* University X Plan - Application Instructions](/dev/howuse/application-agreement)

[* AI Principle](/dev/howuse/principle)

[* Security & Risk](/dev/howuse/safetytips)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

# [Help Document] Zhipu Qingliu

## Update Log

| **Update time** | **Update content** | **Corresponding version** |
| --- | --- | --- |
| 2024.10.09 | V 1.2.5 system upgrade | V1.2.5 |
| 2024.10.15 | Plugin Center Upgrade and User Instructions | V1.2.5 |
| 2024.10.16 | Memory - Variables, Introduction to Initial Variables | V1.2.5 |

## 1. Product Introduction

### 1.1 Introduction

**Intelligent Agent Development Platform**

* Zero code, Out Of The Box
* Diversified integration
* Real landing-level effect guarantee
* Quickly assist enterprises in intelligent transformation
* Make AI applications no longer stay in imagination

The new generation intelligent agent development platform integrates commonly used nodes and tools. Users can drag and drop operations on the canvas to build their own task flow and complete the agent construction of large models. With batch debugging capabilities, the effect of the intelligent agent can be previewed quickly and at a low cost. Finally, the built intelligent agent can be integrated into the user‚Äôs business process through page embedding, API calls, and other forms.

### 1.2 Applicable Population

* **Non-technical**: Front-line business/product/operation, with the help of templates and plug-in services provided by the platform, you only need to make requirements to build your own intelligent body without any development.
* **Technical**: By using code nodes and self-built plugins, more complex intelligent agents can be implemented to adapt to more scenarios.

## 2. Quickly Start

### 2.1 Quickly Experience

![Description](https://cdn.bigmodel.cn/markdown/1731046621871image.png?attname=image.png)

#### 2.1.1 Conversational-agent

The conversational type is generally used in scenarios such as role-playing, intelligent customer service, and business assistants to interact with users in the form of conversation.

**Experience link**: [Conversational-agent](https://appcenter.bigmodel.cn/appcenter_v2/chat?share_code=mSBrkrJBKdyKPeeyLHLFi)

#### 2.1.2 Text-type agent

Text-based general user text writing, information extraction, copywriting, and other scenarios are interacted with in the form of single-round and multi-field input.

**Experience link**: [Text-type agent](https://appcenter.bigmodel.cn/console/appcenter_v2/chat?share_code=zOro1s77lj-W4zqop8vMS)

### 2.2 Teaching Case

#### 2.2.1 Case 1: Intelligent Customer Service Q&A

![Description](https://cdn.bigmodel.cn/markdown/1731046657730image.png?attname=image.png)

**Steps**:

1. Click ‚ÄúCreate Agent‚Äù, select ‚ÄúDialogue Type‚Äù, enter the name of the agent, input or generate an agent introduction with one click, upload or generate an agent logo, and click ‚ÄúCreate‚Äù to enter the canvas editing page.
2. Click the ‚ÄúAdd Section‚Äù button at the bottom of the page, add two ‚ÄúAgent nodes‚Äù, and connect the ‚ÄúStart‚Äù node with any ‚ÄúAgent node‚Äù.
3. Click on the ‚ÄúAgent Node‚Äù tool and add the corresponding Knowledge Base.
4. Write Prompt.
5. Evaluate the effectiveness of the intelligent agent.
6. Click ‚ÄúRelease Management‚Äù - ‚ÄúNew Version‚Äù, enter the version number, and click ‚ÄúRelease‚Äù.
7. After the release is successful, the version details page will pop up.

#### 2.2.2 Case 2: Market Report Assistant

![Description](https://cdn.bigmodel.cn/markdown/1730972118818image.png?attname=image.png)

**Steps**:

1. Click ‚ÄúCreate Agent‚Äù, select ‚ÄúText Type‚Äù, enter the name of the agent, input or one-click generate agent introduction, upload or generate agent logo, and click ‚ÄúCreate‚Äù to enter the canvas editing page.
2. Click ‚ÄúPage Settings‚Äù to configure input items, add a single input item, and configure the type, field name, and prompt of the input item according to requirements.
3. Click the ‚ÄúAdd Section‚Äù button at the bottom of the page, add the required ‚Äúnode‚Äù, and connect the ‚ÄúStart‚Äù node with the first ‚Äúnode‚Äù.
4. Write Prompt.
5. Evaluate the intelligent agent.
6. Click ‚ÄúRelease Management‚Äù - ‚ÄúNew Version‚Äù, enter the version number, and click ‚ÄúRelease‚Äù.
7. After the release is successful, the version details page will pop up.

## 3. Agent Square

### 3.1 Introduction

Intelligent Agent Square is a template library carefully prepared by Zhipu Qingliu for customers, which collects intelligent agent templates selected by Zhipu. These intelligent agent templates involve a wide range of scenarios, have strong versatility, and have high reusability. You can find intelligent agents similar to your scenario in the intelligent agent center, experience their effects, view their canvas and Prompts, and copy the intelligent agents you are satisfied with to your account with one click, reducing a lot of your development time.

![Description](https://cdn.bigmodel.cn/markdown/1730972133900image.png?attname=image.png)

### 3.2 Entry Method

You can access it directly by visiting the link: [Agent Square](https://open.bigmodel.cn/console/appcenter_v2/intelligent/center)

You can also access it by visiting Zhipu Open Platform, clicking ‚ÄúConsole‚Äù, and then clicking ‚ÄúIntelligent Agent Center‚Äù - ‚ÄúIntelligent Agent Square‚Äù in the menu bar on the right side of the page.

### 3.3 Recommended Usage Process

1. According to your scenario, look for similar agents in the Agent Center, such as intelligent customer service, tutoring, and TuShengWen (using ‚ÄúTeacher Assistant‚Äù as an example here).
2. Click ‚ÄúView Details‚Äù to enter the intelligent agent canvas.

![Description](https://cdn.bigmodel.cn/markdown/1730972150370image.png?attname=image.png)

3. Check the canvas node and Prompt to confirm whether the template can be reused in your own scene, and experience the template effect in the ‚ÄúPreview Debugging‚Äù on the right.

![Description](https://cdn.bigmodel.cn/markdown/1730972161914image.png?attname=image.png)

4. ‚ÄúReturn to Agent Center‚Äù, click ‚ÄúCopy Template‚Äù, and you will jump to the editable canvas interface. At this point, the template has been copied to your account. If you go to ‚ÄúMy Agents‚Äù at this time, you will see it become the agent you rank first.

![Description](https://cdn.bigmodel.cn/markdown/1730972175229image.png?attname=image.png)  
![Description](https://cdn.bigmodel.cn/markdown/1730972187043image.png?attname=image.png)  
![Description](https://cdn.bigmodel.cn/markdown/1730972195682image.png?attname=image.png)

### 3.4 Notes

* To ensure user privacy, you cannot copy the private Knowledge Base and plugin configurations in the template.
* When you experience the template, you will consume the tokens of your own account. If you owe or do not have the corresponding model permissions, the system will prompt you for arrears.

## 4. Features and Nodes Introduction

### 4.1 Introduction & Recommendation - Automatic Configuration

**Function Introduction**: Automatically configure the opening remarks and recommended questions of the dialogue page for you through AIGC.

**Effect**:

![Description](https://cdn.bigmodel.cn/markdown/1730972209119image.png?attname=image.png)  
![Description](https://cdn.bigmodel.cn/markdown/1730972218127image.png?attname=image.png)

**Configuration Method**:

1. Click Create Agent

![Description](https://cdn.bigmodel.cn/markdown/1730972300335image.png?attname=image.png)

2. Select the appropriate agent type in ‚ÄúCreate from Blank‚Äù, hover the mouse over it, and click the button ‚ÄúCreate Agent‚Äù.

![Description](https://cdn.bigmodel.cn/markdown/1730972314041image.png?attname=image.png)

3. In the pop-up box, you can choose to turn it on or off at the ‚ÄúAuto Configuration‚Äù in the upper right corner, and the default state is on.

![Description](https://cdn.bigmodel.cn/markdown/1730972323673image.png?attname=image.png)

### 4.2 Fundamental Variable

The agent you create usually has four initial variables, which are `{{conversation record}}`, `{{user-conversation}}`, `{{LLM}}/{{Agent}}`, and `{{current time}}`.

![Description](https://cdn.bigmodel.cn/markdown/1732005247733image.png?attname=image.png)

* **Conversation record**: This variable refers to the historical conversation record between you and the agent.
* **{{User-Dialogue}}**: This variable refers to the input of the user‚Äôs current round.
* **{{LLM}}/{{Agent}}**: This variable refers to the output of the LLM node or Agent node you added.
* **{{Current time}}**: The current Beijing time automatically obtained by the system, is used to inform the large model of the current time.

### 4.3 Start Node

Click the button next to the ‚ÄúStart‚Äù node to enter the dialogue settings, as shown in the figure.

![Description](https://cdn.bigmodel.cn/markdown/1730972345485image.png?attname=image.png)  
![Description](https://cdn.bigmodel.cn/markdown/1730972353292image.png?attname=image.png)

* **The start node is the start node**: Every time the user enters something, it is executed from the start node of the process canvas.
* **The starting node is the last conversation node**: Each time the user enters content, the conversation continues with the user from the node in the last conversation (Agent node only).
* **Dialogue history strategy (carrying the number of rounds of context)**: Controls the variable `{dialogue record}`, the LLM node‚Äôs ‚Äúhistorical dialogue splicing‚Äù function, and the Agent node‚Äôs ‚Äúhistorical dialogue‚Äù round.

### 4.4 Agent Node

![Description](https://cdn.bigmodel.cn/markdown/1730972363360image.png?attname=image.png)

**Function Introduction**: You can use Agent nodes to enrich your own intelligent agent functions.

* **Prompt text box**: Edit the Prompt area, the default is system prompt. Advanced mode after full screen supports entering System Prompt and User Prompt separately. Click the lower right corner of the Prompt text box to enter full-screen mode, and enter advanced mode in the upper left corner.

![Description](https://cdn.bigmodel.cn/markdown/1730972382280image.png?attname=image.png)  
![Description](https://cdn.bigmodel.cn/markdown/1730972391496image.png?attname=image.png)

* **System Prompt**: In large models, System Prompt usually refers to instructions or context designed by model developers or users to guide model behavior.
* **User Prompt**: User Prompt refers to the text input by the user, which is the direct input for the user request model to generate responses.
* **Prompt optimization**: After you have preliminarily written your Prompt, you can click on the star symbol on the right side of Advanced and use the Prompt optimization function to optimize your Prompt to save time on Prompt writing and achieve better results.

![Description](https://cdn.bigmodel.cn/markdown/1730972401904image.png?attname=image.png)

**Model settings**: The model setup page supports replacing large models with a single set of nodes. You can debug the optimal solution for cost and effect in your business scenario by configuring large models with different parameters.  
The model settings page supports adjusting temperature, top\_p, and max\_token three parameters.

* **Temperature:** The Temperature parameter mainly controls the randomness of the text generated by the model. When the Temperature value is high, the model tends to generate more diverse and innovative text, but this may also introduce grammatical errors or irrelevant content. Conversely, when the Temperature value is low, the text generated by the model will be more conservative and stable, but may lack diversity and creativity.
* **Top\_P:** The Top-p (kernel sampling) parameter is different from the Temperature parameter in that it affects diversity by limiting the range of candidate words for the generated text. The Top-p parameter indicates that only the highest probability p% of candidate words are considered when generating each word. Therefore, when the p-value is high, the model-generated text will be more diverse and innovative, but may also contain some unrelated words. When the p-value is low, the generated text will be more focused and coherent, but may lack novelty.
* **Max\_token:** Control model maximum output token, the range is 1-8192.  
  ![Description](https://cdn.bigmodel.cn/markdown/1730972570523image.png?attname=image.png)  
  Support glm-4-alltools model, now glm-4-alltools model can generate and run code locally (code interpreter)  
  ![Description](https://cdn.bigmodel.cn/markdown/1730972585629image.png?attname=image.png)
* **Tools**: unique features of Agent nodes that help your agent create richer features.

  + **Plugin**: By calling functions, Agent nodes can interact with other systems and support calling external interfaces.

![Description](https://cdn.bigmodel.cn/markdown/1730972624887image.png?attname=image.png)

* **Use plugins**: You can add plugins built into the Agent Center by clicking ‚ÄúTools - Add Plugins‚Äù.
* **Create plugins**: You can configure your own plugins through ‚ÄúTools - Add Plugins - Custom Plugins‚Äù.

![Description](https://cdn.bigmodel.cn/markdown/1730972615049image.png?attname=image.png)

**Steps**:

1. Configure your authentication (if any).
2. Configure the schema according to the given example (input the corresponding API schema that conforms to the OpenAPI 3.0 specification), and synchronize support for YAMA and JSON formats.
3. Verify if the analysis result on the right is correct.
4. Save the plugin.

![Description](https://cdn.bigmodel.cn/markdown/1730972671675image.png?attname=image.png)

* **Plugins - Variables/Memory**: A tool to assist large models in achieving long-term memory. The function of this tool is to record data in Key-value format and convert it into variables, which can be used for global reference.

![Description](https://cdn.bigmodel.cn/markdown/1730972697905image.png?attname=image.png)  
**How to use**:

* Agent node usage: Like other plug-in tools, it is called by the Agent itself. For debugging and optimization steps, in addition to Prompt, you can pay attention to the field description of the plug-in function itself.

**Use tips:**

If you need to implement reading variables:

```
Â∑≤ÊúâÂèòÈáèÔºö
ÂüéÂ∏ÇÔºöÂåó‰∫¨

ÈúÄÊ±ÇÔºö
Â§ßÊ®°ÂûãËØªÂèñÁé∞Âú®Â∑≤ÊúâÂüéÂ∏Ç

Á§∫‰æãÊåá‰ª§Ôºö
ÂΩìÂâçÂ∑≤ÊúâÂüéÂ∏ÇÔºö{ÂüéÂ∏Ç}}
```

1  
2  
3  
4  
5  
6  
7  
8

If you need to store multiple values in a variable:

* First, introduce the variable into the instruction so that the large model can see the existing value in the variable.
* Then adjust the instructions so that when the large model is written, it will include not only the newly added value, but also the existing value.

```
Â∑≤ÊúâÂèòÈáèÔºö
ÂüéÂ∏ÇÔºöÂåó‰∫¨

ÈúÄÊ±ÇÔºö
Â¢ûÂä†‰∏äÊµ∑

Á§∫‰æãÊåá‰ª§Ôºö
Èô§‰∫ÜÂΩìÂâçÂ∑≤ÊúâÁöÑÂüéÂ∏ÇÔºåÊàëËøòÊÉ≥Âéª‰∏äÊµ∑
ÂΩìÂâçÂ∑≤ÊúâÂüéÂ∏ÇÔºö{ÂüéÂ∏Ç}}ÔºåÂ§ö‰∏™ÂÄº‰πãÈó¥ÈááÁî®ÈÄóÂè∑ÈöîÂºÄ

ÁªìÊûúÔºö
ÂüéÂ∏ÇÔºöÂåó‰∫¨Ôºå‰∏äÊµ∑
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12

**Knowledge Base:** Agent nodes can access your Knowledge Base on the development platform by calling functions, and have the ability to recognize user intentions on their own. Agents can independently ‚Äúrewrite user input‚Äù and use questions that are more in line with user intentions to find corresponding answers in the Knowledge Base.

1. Since the Agent node calls Knowledge Base through a function call, the name and description of Knowledge Base will be input to the model as the name and description of the function, which affects the final effect of the large model calling the function. Please configure the name and description carefully.
2. You can add your Knowledge Base on Open Platform by clicking ‚ÄúTools - Add Knowledge Base‚Äù.
3. After adding Knowledge Base, you will find a settings button next to the add button. After clicking it, you can make advanced settings to the Knowledge Base function. In the manual settings, you can adjust the recall strategy of Knowledge Base.  
   a. Currently supports three methods: Search Deep Retrieval, keyword recall, and mixed recall.  
   b. Support the Rerank model to improve the relevance and accuracy of search results by reordering the results.  
   c. Support manual setting for recalling slices.  
   d. Support manually setting search terms for knowledge.  
   ![Description](https://cdn.bigmodel.cn/markdown/1730972719805image.png?attname=image.png)  
   ![Description](https://cdn.bigmodel.cn/markdown/1730972731510image.png?attname=image.png)  
   ![Description](https://cdn.bigmodel.cn/markdown/1730972738607image.png?attname=image.png)

* **Auxiliary Capability - Network Search**: The Agent node supports network search capability and supports configuring search terms. This function is not implemented through function calls.  
  1. Internet Settings: With Internet Search enabled, you can click the Settings button on the right side of the ‚ÄúInternet Search Switch‚Äù to open the Internet Settings box and configure search terms.  
  2. When the search term is not empty, the Agent node will force a search in each round of dialogue.  
  ![Description](https://cdn.bigmodel.cn/markdown/1730972748194image.png?attname=image.png)
* **Jump-in condition**: The agent node can automatically recognize the user‚Äôs intention for node jump. You can fill in the scenarios or tasks applicable to the agent in the ‚ÄúJump-in condition‚Äù.

  1. You can describe in detail the types of questions the agent is responsible for answering, the tasks it performs, or just the scenarios you want it to be used in.
  2. The influence range of the jump condition is global, which means that the agent can freely jump throughout the entire canvas.
* **Jump-out condition**: When the control agent node meets the condition, it jumps to the next node. There are currently two judgment conditions: model autonomous judgment and rule judgment.

  1. Model autonomous judgment: The model subjectively judges whether the current node can jump to the next node based on the intention of the dialogue.
  2. Rule judgment: Determine whether to jump to the next node based on objective conditions such as the number of dialogue rounds and time. This applies to general user training, dialogue practice, and other scenarios.

### 4.5 LLM Node

![Description](https://cdn.bigmodel.cn/markdown/1730972760476image.png?attname=image.png)

**Function Introduction**: LLM nodes are used to execute specific user tasks, and the execution order is completely executed according to the canvas connection. The Agent Center supports parallel multiple LLM nodes.

* **Prompt text box**: Edit the Prompt area, the default is user prompt. Advanced mode after full screen supports entering System Prompt and User Prompt separately.
* **Prompt optimization**: After you have preliminarily written your Prompt, you can click on the star symbol on the right side of Advanced and use the Prompt optimization function to optimize your Prompt to save time on Prompt writing and achieve better results.
* **Model Settings**: The model setup page supports replacing large models with a single set of nodes. You can debug the optimal solution for cost and effect in your business scenario by configuring large models with different parameters.

  The model setup page supports replacing large models with a single set of nodes. You can debug the optimal solution for cost and effect in your business scenario by configuring large models with different parameters.

  The model settings page supports adjusting temperature, top\_p, and max\_token three parameters:

  + **Temperature:** The Temperature parameter mainly controls the randomness of the text generated by the model. When the Temperature value is high, the model tends to generate more diverse and innovative text. Conversely, when the Temperature value is low, the text generated by the model will be more conservative and stable.
  + **Top\_P:** The Top-p (kernel sampling) parameter is different from the Temperature parameter in that it affects diversity by limiting the range of candidate words for the generated text. The Top-p parameter indicates that only the highest probability p% of candidate words are considered when generating each word. Therefore, when the p-value is high, the model-generated text will be more diverse and innovative, but may also contain some unrelated words. When the p-value is low, the generated text will be more focused and coherent, but may lack novelty.
  + **Max\_token:** Control model maximum output token, the range is 1-8192.

Support the ‚Äúhistorical dialogue splicing‚Äù function. After enabling it, the LLM node will splice historical dialogue content. The specific dialogue round can be set in the start node.

![Description](https://cdn.bigmodel.cn/markdown/1730972785065image.png?attname=image.png)

Support glm-4-alltools model, now glm-4-alltools model can generate and run code locally (code interpreter)

![Description](https://cdn.bigmodel.cn/markdown/1730972826927image.png?attname=image.png)

**Tools**: LLM nodes can use two general abilities, Knowledge Base and Network Search. Unlike Agent nodes, the Knowledge Base of LLM nodes is not implemented through function calls. (PS: Currently, LLM nodes of text-based agents do not support Knowledge Base).

* **Knowledge Base:** LLM nodes support access to your Knowledge Base on the development platform. When you configure the Knowledge Base tool, the LLM node will definitely call the Knowledge Base tool when executed.
  + You can add your Knowledge Base in Open Platform by clicking ‚ÄúTools - Add Knowledge Base‚Äù.
  + After adding Knowledge Base, you will find a settings button next to the add button. After clicking it, you can make advanced settings to the Knowledge Base function. In the manual settings, you can adjust the recall strategy of Knowledge Base. Currently, there are two ways to recall: index recall, original text recall, and mixed recall.
* Assistive Capability - Network Search: LLM nodes support network search capability and support configuring search terms. This function is not achieved through function calls.
  1. Internet Settings: With Internet Search enabled, you can click the Settings button on the right side of the ‚ÄúInternet Search Switch‚Äù to open the Internet Settings box and configure search terms.
  2. When the search term is not empty, the LLM node will force a search in each round of dialogue.  
     g.Jump condition : Agent can jump into the corresponding LLM node according to the intention.

#### 4.5.1 [Important] MultiModal Model

**Function introduction**: At present, LLM nodes support access to MultiModal Machine Learning large models GLM-4V (graphic text), GLM-4V-Plus (graphic or video text), CogVideoX (graphic video) support input images (or videos) and prompt words for text or video generation.

![Description](https://cdn.bigmodel.cn/markdown/1730972846231image.png?attname=image.png)  
![Description](https://cdn.bigmodel.cn/markdown/1730972856773image.png?attname=image.png)  
**How to use**:

* **Conversational Agent**:  
  1. Select GLM-4V, GLM-4V-Plus, and CogVideoX in the model list, and the interface will automatically switch to an interface compatible with MultiModal Machine Learning. You can see the position of the image variable at the node and the icon for uploading images in the preview debugging text box.  
  ![Description](https://cdn.bigmodel.cn/markdown/1730972871120image.png?attname=image.png)  
  2. Click on the ‚ÄúSelect Image Variable‚Äù text box and check User-Image (or User-Video).  
  ![Description](https://cdn.bigmodel.cn/markdown/1730972882750image.png?attname=image.png)  
  3. Upload a picture (or video) and enter a question or prompt word to run.
* **Text-based agent**: Select GLM-4V, GLM-4V-Plus, and CogVideoX in the model list, and the interface will automatically switch to an interface compatible with MultiModal Machine Learning.

1.Select GLM-4V, GLM-4V-Plus, and CogVideoX in the model list, and the interface will automatically switch to an interface compatible with MultiModal Machine Learning.  
2.Click on the input item configuration, in the type, select Image Upload (Video Upload);  
![Description](https://cdn.bigmodel.cn/markdown/1731050434939image.png?attname=image.png)  
3.Enter the defined field name, click Finish, and then select the corresponding field in the ‚ÄúInput Image‚Äù drop-down box of the LLM node. Entering multiple images (or videos) at once can be achieved by configuring multiple input items.  
![Description](https://cdn.bigmodel.cn/markdown/1731050451358image.png?attname=image.png)  
![Description](https://cdn.bigmodel.cn/markdown/1731050459266image.png?attname=image.png)

### 4.6 Branch Judgment Node

**Or" conditional judgment function**: The branch judgment node can determine the branch direction based on the content and variable values output by the previous node. You can increase the branch judgment by using the ‚Äú+‚Äù in the upper right corner. Currently, six branch judgment logics are supported: ‚Äúequal to‚Äù, ‚Äúnot equal to‚Äù, ‚Äúword count greater than‚Äù, ‚Äúword count less than‚Äù, ‚Äúempty‚Äù, ‚Äúnot empty‚Äù, ‚Äúcontain‚Äù, ‚Äúdo not contain‚Äù, ‚Äúgreater than‚Äù, ‚Äúless than‚Äù. The conditional content can choose to reference variables or fixed values.

**And" conditional judgment function**:

1. When users need to determine the direction of a branch through multiple conditions (i.e. scenarios with ‚Äúand‚Äù condition requirements), they can click ‚Äú+ Add‚Äù in the condition to add judgment conditions under the same condition.

![Description](https://cdn.bigmodel.cn/markdown/1731050647564image.png?attname=image.png)

2. When multiple branches in the canvas need to go to the same ‚Äúbranch judgment node‚Äù, you can connect multiple previous nodes to the ‚Äúbranch judgment node‚Äù.  
   ![Description](https://cdn.bigmodel.cn/markdown/1731050701182image.png?attname=image.png)
3. ‚ÄúOtherwise‚Äù function: The ‚ÄúOtherwise‚Äù function of the branch judgment node can help you deal with unconventional situations encountered in the scene, such as the unstable output of the previous node.  
   ![Description](https://cdn.bigmodel.cn/markdown/1731050743323image.png?attname=image.png)
4. Parallel execution function : The branch judgment node supports executing multiple branches at the same time. Under this function, if the judgment result meets the conditions of multiple branches at the same time, it is allowed to execute multiple subsequent branches at the same time  
   ![Description](https://cdn.bigmodel.cn/markdown/1731050786840image.png?attname=image.png)

### 4.7 Data Extraction Node

**Function Introduction**: The data extraction node supports converting the output of your previous node into a variable for reference in subsequent nodes. It does not support being the last node of the process.

* Currently only supports converting the output content of JSON or key: value structures.

**Key-valueÔºö**

```
Â≠óÊÆµÂêç:Â≠óÊÆµÂÄº
‰æãÂ¶ÇÔºöÂüéÂ∏Ç:Âåó‰∫¨
```

1  
2

* Support extracting multiple fields at once. When you fill in the content in the input box, the node will automatically add a text box.  
  ![Description](https://cdn.bigmodel.cn/markdown/1730972970157image.png?attname=image.png)

### 4.8 Data Merge Node

**Function introduction**: The data merge node supports you to merge the data output by the previous node. In the text box of data merge, you can freely edit the text, reference variables, and arrange them according to your expected structure. Commonly used in long document generation scenarios, you can take steps to generate different parts of the article, and finally use this node to merge the output according to your expected structure.

![Description](https://cdn.bigmodel.cn/markdown/1730972981627image.png?attname=image.png)

### 4.9 Code Node

**Function Introduction**: Support entering code in this node, so that users can more flexibly implement requirements, such as structured data processing, mathematical operations, data splicing, and other scenarios. Currently supports Python and JavaScript languages. The content of the code node runs in the local sandbox environment and cannot interact with external systems. If you need to link external systems, please use the ‚Äúself-built plugin‚Äù function.

![Description](https://cdn.bigmodel.cn/markdown/1731051537754image.png?attname=image.png)  
**Text box:** Click the plus sign in the upper right corner to add parameters. Parameters can input fixed values and reference variables generated by large models.

**Debugging method:** Click IDE Edit, enter the written code, click the test code in the upper right corner, and click Run. After running successfully, click Sync Output to run normally. Note that the input parameters here need to return to the canvas. Click the ‚Äú+‚Äù sign in the input of the component to generate

![Description](https://cdn.bigmodel.cn/markdown/1731051552023image.png?attname=image.png)

### 4.10 Tool Node

![Description](https://cdn.bigmodel.cn/markdown/1731051592059image.png?attname=image.png)

* **Function IntroductionÔºö** Stably call the node of the third-party interface through the project. Now, by combining tool nodes, LLM nodes can also call tools. Currently, only the third-party tools provided by the platform are supported. The tool node cannot be used alone as the last node of the agent. It is necessary to add an LLM node after the tool receives the data returned by the tool and outputs it according to the user‚Äôs expectations.
* **How to use**:

  1. Select Add tool node.  
     ![Description](https://cdn.bigmodel.cn/markdown/1731051675060image.png?attname=image.png)
  2. Select the required tool, add the corresponding action, and save it. See Agent node - Tools - Plugins for details.  
     ![Description](https://cdn.bigmodel.cn/markdown/1731051695709image.png?attname=image.png)
  3. After adding, you can see the specific tool node, expand ‚Äúinput‚Äù to see the necessary imported parameters of the tool, you can choose to fill in fixed values or reference variables in the canvas;  
     ![Description](https://cdn.bigmodel.cn/markdown/1731051735721image.png?attname=image.png)
  4. Click the Run icon in the upper right corner to bring up the tool debugging interface, where you can debug the tool on a single node.  
     ![Description](https://cdn.bigmodel.cn/markdown/1731051761500image.png?attname=image.png)
  5. Expand ‚ÄúOutput‚Äù to see the output paradigm of the tool node. The output paradigm of different tools is different.  
     ![Description](https://cdn.bigmodel.cn/markdown/1731051793453image.png?attname=image.png)

**Plugins - Variables/Memory**:  
![Description](https://cdn.bigmodel.cn/markdown/1731051915652image.png?attname=image.png)

* Function Introduction : A tool to assist large models in achieving long-term memory. See ‚ÄúAgent Node-Tools-Plugins-Plugins-Variables/Memory‚Äù for details.
* Usage : When using the tool node to add this function, the function is called in the form of a project. ‚ÄúInput-Body‚Äù is a pre-set variable name that can be selected as a fixed value or reference to variables in the agent. ‚ÄúOutput‚Äù is the output paradigm of the tool. By clicking on ‚ÄúVariable Management‚Äù in the right area of ‚ÄúInput‚Äù, the variable interface can be called up to manage variables such as increase, decrease, and description.
  + Since the ‚Äútool-variable‚Äù node requires the input to be a structured data structure, it is necessary to make requirements for the output format of the preceding LLM node.
  + If there are multiple fields in the previous LLM node that need to be stored in multiple variables separately, ‚Äúdata extraction‚Äù is required to extract multiple fields from the LLM node first, and then reference them in order in the ‚Äúinput-body‚Äù section of ‚Äútool-variable‚Äù.
  + Since the ‚Äútool - variable‚Äù node is still the essence of the tool, so if as the last node of the agent, the execution result of the output tool (a piece of data in JSON format), the LLM node needs to be added after the tool to receive the data returned by the tool, and output according to the user‚Äôs expectations.  
    ![Description](https://cdn.bigmodel.cn/markdown/1731052031807image.png?attname=image.png)  
    ![Description](https://cdn.bigmodel.cn/markdown/1731052048419image.png?attname=image.png)
  + Note: If there are multiple fields in the previous LLM node and they need to be stored in multiple variables separately, ‚ÄúData Extraction‚Äù is required to extract multiple fields from the LLM node first, and then reference them in order in the ‚ÄúInput-Body‚Äù section of ‚ÄúTools-Variables‚Äù, as shown in the following figure.  
    ![Description](https://cdn.bigmodel.cn/markdown/1731052076797image.png?attname=image.png)

## 5. Testing and Batch Debugging

### 5.1 Single Node Test

#### 5.1.1 Single Node Single Evaluation

* **Applicable scenarios**: In order to facilitate your debugging of Prompt and optimize the effect of the agent, LLM nodes and Agent nodes support Prompt evaluation of a single node.
* **Evaluation entrance**: In the Prompt text box of the LLM node and Agent node, click the lower right corner to enter full-screen mode. You can adjust your Prompt in the left column and test and preview the effect of a single node in the right column.

![Description](https://cdn.bigmodel.cn/markdown/1731052165566image.png?attname=image.png)

#### 5.1.2 Single-node batch debugging

* **Applicable scenarios:** Batch debugging can automatically execute agents/nodes based on the dataset you prepare, quickly obtain test results, and improve evaluation efficiency . If you need to evaluate the stability of a single node Prompt or whether the overall effect meets the online standard when building an agent, you can use the batch debugging function of a single node. Currently, both LLM nodes and Agent nodes support one-click batch evaluation.
* **Evaluation entrance**: In the Prompt text box of the LLM node and Agent node, click the lower right corner to enter full-screen mode. Click ‚ÄúBatch Debugging‚Äù in the upper right corner.(See ‚ÄúTesting and Batch Debugging - Full Node Batch Debugging‚Äù for details)

![Description](https://cdn.bigmodel.cn/markdown/1731052234617image.png?attname=image.png)

### 5.2 Full Node Test

#### 5.2.1 Full node single test

**Quick evaluation**: After you have completed the setup of the entire agent, you can evaluate the agent in the dialog bar on the right to verify the effect of the agent output.

**Detailed evaluation**: You can click the icon in the middle of the upper right corner of ‚ÄúPreview Debugging‚Äù to bring up the log page, view the input and output of each node, and make a more detailed evaluation and problem location of the output of the entire agent.

![Description](https://cdn.bigmodel.cn/markdown/1731052264421image.png?attname=image.png)

#### 5.2.2 Full Node Batch Debugging

**Applicable scenarios**: When you want to evaluate the overall effect of the agent, you can use the batch debugging function. Batch debugging can automatically execute agents/nodes based on the dataset you prepare, quickly obtain test results, improve your evaluation efficiency, and facilitate your optimization direction.

**Access method**: You can enter full-screen mode through the full-screen button in the upper right corner, and click the batch debugging in the upper right corner. Enter the interface of batch debugging.

![Description](https://cdn.bigmodel.cn/markdown/1731052293092image.png?attname=image.png)  
![Description](https://cdn.bigmodel.cn/markdown/1731052303799image.png?attname=image.png)

**Debugging method**: Click New Debugging, then upload or select your dataset (Currently only supports Excel format), then select the column where you evaluate the problem as the ‚ÄúUser‚Äù field, and click ‚ÄúExecute Evaluation‚Äù, and your task will automatically start the evaluation.

![Description](https://cdn.bigmodel.cn/markdown/1731052318831image.png?attname=image.png)

* **Additional matters:**
  1. "When you have multiple inputs at the same time, you need to configure the correct field names in the header of the corresponding input.
  2. Knowledge Base batch debugging: After executing the evaluation in a general way, click Download, and the agent involving Knowledge Base will receive an additional sheet to display the recalled slice content. If there are multiple nodes configured with Knowledge Base in the agent, the recalled slice content of each node will be displayed.
  3. During batch debugging of MultiModal Machine Learning large models, the corresponding images can be placed in a column in Excel and matched correctly with the image-user field (or the variable of ‚Äúcorresponding input image‚Äù in other agents). Other operations are the same as batch debugging of text large models.

## 6. Save and Publish Management

### 6.1 Version Saved

* **Auto-save**: Whenever you edit the canvas, the intelligent experience automatically saves the latest edited content for you after the mouse loses focus.
* **Save version (manual save)**: You can save the agent by clicking the icon in the middle of the upper right corner or using the shortcut ctrl + s (using cmd + s on the Mac system).

![Description](https://cdn.bigmodel.cn/markdown/1731052395225image.png?attname=image.png)

* After clicking, you will see a pop-up box to save the version. You can enter the version name and description in the pop-up box. Click ‚ÄúSave‚Äù to save the intelligent agent. You can see the name of the latest historical version in the small print below the version number, which is convenient for you to manage the version.

![Description](https://cdn.bigmodel.cn/markdown/1731052443610image.png?attname=image.png)

* After clicking OK, you will return to the canvas and see the prompt ‚ÄúSaved Successfully‚Äù appear directly above the canvas.  
  ![Description](https://cdn.bigmodel.cn/markdown/1731052470029image.png?attname=image.png)

### 6.2 Release Management

* You can click the ‚ÄúPublish Management‚Äù button in the upper right corner to publish the edited agent.

![Description](https://cdn.bigmodel.cn/markdown/1731052492258image.png?attname=image.png)

* Click ‚ÄúRelease Management‚Äù and you will see a version record interface, which records all the relevant information about your historical versions. You can choose any version to perform the ‚ÄúRelease‚Äù or ‚ÄúBacktrack‚Äù action, or you can choose to take down the currently released version.  
  ![Description](https://cdn.bigmodel.cn/markdown/1731052536182image.png?attname=image.png)
* Click ‚ÄúNew Version‚Äù in the upper right corner, enter the version name, and then click ‚ÄúPublish‚Äù to publish the agent.  
  ![Description](https://cdn.bigmodel.cn/markdown/1731052556974image.png?attname=image.png)
* After the release is successful, you will see ‚ÄúRelease Successful‚Äù displayed at the top of the page, and the ‚ÄúVersion Details‚Äù page will automatically pop up. This page details the version information, access link, integration information, and integration document link of your current agent for later integration or sharing.

![Description](https://cdn.bigmodel.cn/markdown/1731052580049image.png?attname=image.png)

You can view the release status of the agent through the status below the agent.

* When the status shows ‚ÄúUnpublished‚Äù, it means that you have edited content that has not been published. The experience may be different from the effect of your preview test.
* When the status shows ‚ÄúPublished‚Äù, it means that all your edited content has been published, and the experience effect is the same as the effect of your preview test.  
  ![Description](https://cdn.bigmodel.cn/markdown/1731052635801image.png?attname=image.png)
* You can also check if there are any unpublished edits on the canvas page. You can find a prompt in the small print column to the right of the agent name in the upper left corner of the canvas.  
  ![Description](https://cdn.bigmodel.cn/markdown/1731052667324image.png?attname=image.png)

## 7. Plugin Center

### 7.1 Feature Introduction

Plugins are an important part of the implementation of intelligent agents. They act as the hands and feet of large models, extending their capabilities. Rich plugins are a necessary condition for the implementation of intelligent agents. To this end, Qingliu has launched a plugin center.

### 7.2 Plugin Square

The plugin square displays public plugin tools carefully selected by Zhipu officials and private plugins uploaded by other users. These plugins involve various functions, such as web search, tool efficiency, etc. Using plugins, you can use them when building intelligent agents.

![Description](https://cdn.bigmodel.cn/markdown/1731052689094image.png?attname=image.png)

### 7.3 My Plugin

In ‚ÄúMy Plugins‚Äù, your self-built private plugins are displayed. At the same time, you can also create your own plugins for your agents to use in ‚ÄúMy Plugins‚Äù, and you can choose to upload your self-built plugins to the plugin square for all users to use.

![Description](https://cdn.bigmodel.cn/markdown/1731052701771image.png?attname=image.png)

**Steps to create a custom plugin**:  
![Description](https://cdn.bigmodel.cn/markdown/1731052729711image.png?attname=image.png)

1. Click on the custom plugin in the first step, and the above interface will pop up.
2. Enter your plugin name, select category, description, and icon, and configure your authentication (if any).
3. Configure the schema according to the given specifications and examples (input the corresponding API schema that conforms to the OpenAPI 3.0 specification), and synchronize support for YAMA and JSON formats.
4. After waiting for the schema to load, click ‚ÄúDebug‚Äù under ‚ÄúMethod Debugging‚Äù; perform a practice run on the newly pulled-up page on the right.  
   ![Description](https://cdn.bigmodel.cn/markdown/1731052749000image.png?attname=image.png)
5. After waiting for the schema to load, click ‚ÄúDebug‚Äù under ‚ÄúMethod Debugging‚Äù; perform a practice run on the newly pulled-up page on the right.

## 8. Case Library

### 8.1.1 Prompt Writing Tips

Writing prompts is an important step in configuring applications. The clearer and more specific the prompts are, the more expected the response will be. You can iterate the prompts based on the actual performance of the application to optimize the performance of the large model.

In order to achieve a better experience for the application, it is recommended to include and pay attention to the following content in the writing instructions:

**Recommendations**:

1. **Set the Role**: Describe the role or responsibilities of the application, as well as the style of its responses.
2. **Describe Functionality and Workflow**: Explain the application‚Äôs functions and workflow, specifying how it should respond to users in different scenarios. Emphasize in natural language the scenarios in which a particular tool should be invoked to enhance the application‚Äôs constraints and ensure the selection of tools that align with expected outcomes for accurate responses.
3. **Direct the Application to Respond Within a Specified Scope**: If you want to limit the scope of responses, explicitly tell the application what it should and should not answer. For example: Refuse to answer topics unrelated to healthy living. If no nutritional information about a particular food is found, inform the user that it was not found rather than fabricating content.
4. **For Applications with Relatively Complex Functions, It is Recommended to Use Structured Formatting for Prompts**: Structured prompts using Markdown syntax are more readable and impose stronger constraints on the application. You can use the prompt optimization feature, which automatically optimizes prompts into structured content. You can directly use the optimized content or modify it based on the optimized version.

### 8.1.1.1 Information Extraction: Extracting Desired Information from Complex Natural Language or Data

```
You are a text extractor, you need to help the user structure the extracted information.
The user will input colloquial content, you need to structure the extracted information from the user's input content, generate content according to the template.
Output after completion, do not generate new user input, do not add new content
Template as follows:
"""
{
"xx":"xx"
}
"""
If not found, please reply "null", do not explain other content.

Example:
{
User description: I am sick today, help me submit the leave form, my personal information is as follows, my name is xx, my department is xxx, ask for leave tomorrow, from 11 am to 6 pm, my superior leader is xxx, my email is xxx, my job title is xxxx.
Leave applicant: xx
Leave applicant department: xxx
Start date: tomorrow
Start time: 11 am
End date: tomorrow
End time: 6 pm
Leave type: sick leave
Reason: sick
Leave days: 1
Total leave days: 1
Superior leader: xxx
Corresponding salary adjustment: no
Approval: null
}

{User query}
Please output content according to the above text, according to the template.
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31

### 8.1.1.2 Intent Recognition: Using Large Models to Recognize and Classify the Semantics of User Input

```
From the following information original text:
"""
{QA}
"""
Do user intent recognition

Intent types:
"""
xxxx:xxxx
xxxx:xxxx

"""

Select the user's intent from the intent types, output directly using the json format
Must and can only give one intent type

Example format:
{"User intent type": "..."}

Original text:
"""
{input2}
"""
Judge the xxx intent type according to the original text information

Note:
1. xxxx
2. xxxx

"""
Example format:
xxx
"""
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33

### 8.1.1.3 Query Rewriting: When the User‚Äôs Input May Be Incomplete or Ambiguous, Use a Large Model to Rewrite the User‚Äôs Input as Complete or Correct

```
"""
The user has the following input:
{User}
"""
Please refer to the context, complete or correct the user's input under the condition of complete semantics and premise.
Please note that the user's input may have the following problems:
1. Pronouns or references, need to contact the previous text to complete the information referred to.
2. Elliptical sentences, need to contact the previous text to complete the information referred to.
3. Typos, need to contact the previous text to correct the information referred to.
4. Need to contact the previous text to complete the information of attributive and adverbial.

Please output according to the following format:
{"Modified user input":""}
"""
You have the following context content as a supplement:
{Dialogue content}
"""
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17

### 8.1.1.4 Knowledge Base Q&A: Q&A Scenarios for Accessing Knowledge Base

**The big model calls Knowledge Base**:

```
Role: You are a professional software company customer service. You are providing after-sales service to users. Your reply tone needs to be adjusted according to the user's mood.

Background: The company's business is a no-code development platform.

Task: You need to answer user questions based on knowledge. When there is an answer in the knowledge, use the original knowledge to answer; when the knowledge cannot answer the user's question, reply "I don't know".
"""
The user's question is as follows:
{{User}}
"""
"""
You have the following knowledge:
{{Knowledge}}
"""
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13

**Agent calls Knowledge Base**:

```
system prompt
Role: You are a professional software company customer service. You are providing after-sales service to users. Your reply tone needs to be adjusted according to the user's mood.

Background: The company's business is a no-code development platform.

Task: You need to use the knowledge base tool "{{Document Name}}" to answer user questions.

Requirements:
1. You must use the knowledge base tool "{{Document Name}}"
2. When there is an answer in the knowledge, use the original knowledge to answer; when the knowledge cannot answer the user's question, reply "I don't know".
"""
You have a knowledge base tool that can be used "{{Document Name}}", "{{Document Description}}"
"""

user prompt
{{User}}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16

Table of contents

Update Log

1. Product Introduction

1.1 Introduction

1.2 Applicable Population

2. Quickly Start

2.1 Quickly Experience

2.2 Teaching Case

3. Agent Square

3.1 Introduction

3.2 Entry Method

3.3 Recommended Usage Process

3.4 Notes

4. Features and Nodes Introduction

4.1 Introduction & Recommendation - Automatic Configuration

4.2 Fundamental Variable

4.3 Start Node

4.4 Agent Node

4.5 LLM Node

4.6 Branch Judgment Node

4.7 Data Extraction Node

4.8 Data Merge Node

4.9 Code Node

4.10 Tool Node

5. Testing and Batch Debugging

5.1 Single Node Test

5.2 Full Node Test

6. Save and Publish Management

6.1 Version Saved

6.2 Release Management

7. Plugin Center

7.1 Feature Introduction

7.2 Plugin Square

7.3 My Plugin

8. Case Library

8.1.1 Prompt Writing Tips

8.1.1.1 Information Extraction: Extracting Desired Information from Complex Natural Language or Data

8.1.1.2 Intent Recognition: Using Large Models to Recognize and Classify the Semantics of User Input

8.1.1.3 Query Rewriting: When the User‚Äôs Input May Be Incomplete or Ambiguous, Use a Large Model to Rewrite the User‚Äôs Input as Complete or Correct

8.1.1.4 Knowledge Base Q&A: Q&A Scenarios for Accessing Knowledge Base