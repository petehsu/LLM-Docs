[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fapi%2Frtav%2FGLM-Realtime)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

API REFERENCE

* SDK Calling

  [+ Installation](/dev/api/devguide/sdk-install)

  [+ Authentication](/dev/api/devguide/sdk-auth)

  [+ sdk\_example](/dev/api/devguide/sdk_example)

* HTTP Request

  [+ API Request](/dev/api/http-call/http-para)

  [+ Authentication](/dev/api/http-call/http-auth)

* More Frameworks

  [+ OpenAI SDK](/dev/api/thirdparty-frame/openai-sdk)

  [+ Langchain SDK](/dev/api/thirdparty-frame/langchain-sdk)

APIs

* Language models

  [+ GLM-4 Models](/dev/api/normal-model/glm-4)

  [+ GLM-4V Models](/dev/api/normal-model/glm-4v)

* Reasoning models

  [+ GLM-Z1](/dev/api/Reasoning-models/glm-z1)

* Video Generation

  [+ CogVideoX](/dev/api/videomodel/cogvideox)

  [+ CogVideoX-3](/dev/api/videomodel/cogvideox-3)

  [+ Vidu Models](/dev/api/videomodel/vidu)

* Audio-Video

  [+ GLM-4-Voice](/dev/api/rtav/GLM-4-Voice)

  [+ GLM-Realtime](/dev/api/rtav/GLM-Realtime)

  [+ GLM-ASR](/dev/api/rtav/glm-asr)

* Reasoning models

  [+ GLM-4.1V-Thinking](/dev/api/visual-reasoning-model/GLM-4.1V-Thinking)

* Agent

  [+ TranslationAgent](/dev/api/agent/general_translation)

  [+ Professional Document Translation](/dev/api/agent/doc_translation_agent)

  [+ Social Science and Literary Translation](/dev/api/agent/social_literature_translation_agent)

  [+ Subtitle Translation for Film and Television](/dev/api/agent/subtitle_translation_agent)

  [+ Social Media Translation](/dev/api/agent/social_translation_agent)

  [+ AI Drawing](/dev/api/agent/ai_drawing_agent)

  [+ AI Comics](/dev/api/agent/cartoon_generator_agent)

  [+ Popular Special Effects Videos](/dev/api/agent/vidu_template_agent)

  [+ Resume and Job Matching Assistant](/dev/api/agent/job_matching_agent)

  [+ Customer Service Script Quality Inspection](/dev/api/agent/service_check_agent)

  [+ Sales Quality Inspection](/dev/api/agent/sales_check_agent)

  [+ Bill Recognition](/dev/api/agent/receipt_recognition_agent)

  [+ Clothes Recognition](/dev/api/agent/clothes_recognition_agent)

  [+ Contract Analysis](/dev/api/agent/contract_parser_agent)

  [+ Tendering Analysis Agent](/dev/api/agent/bidding_parser_agent)

  [+ Winning Bid Analysis Agent](/dev/api/agent/bidwin_parser_agent)

  [+ Intelligent Problem Solving](/dev/api/agent/intelligent_education_solve_agent)

  [+ Homework Grading](/dev/api/agent/intelligent_education_correction_agent)

* search-tool

  [+ Web Search API](/dev/api/search-tool/web-search)

  [+ Web Search in Chat](/dev/api/search-tool/websearch-in-chat)

  [+ Search Agent](/dev/api/search-tool/agent-search)

* Image Generation

  [+ CogView-4](/dev/api/image-model/cogview)

* Agent Model

  [+ GLM-4-AllTools](/dev/api/intelligent-agent-model/glm-4-alltools)

  [+ GLM-4-Assistant](/dev/api/intelligent-agent-model/assistantapi)

* Code Programming

  [+ CodeGeeX-4](/dev/api/code-model/codegeex-4)

* Embedding

  [+ Embedding](/dev/api/vector/embedding)

* Moderations

  [+ moderations](/dev/api/moderations/moderations)

* Role-playing

  [+ CharGLM-4](/dev/api/super-humanoid/charglm-4)

  [+ Emohaa](/dev/api/super-humanoid/emohaa)

* Agent Development Platform

  [+ „ÄêNew„Äëqingliuagent](/dev/api/Agent_Platform/newagent)

  [+ agent](/dev/api/Agent_Platform/agent)

  [+ qingliuSDK](/dev/api/Agent_Platform/agentsdk)

  [+ Knowledge](/dev/api/Agent_Platform/knowledge)

  [+ FinAgent](/dev/api/Agent_Platform/FinAgent)

* Batch

  [+ Batch](/dev/api/batch-api/batch)

* Data Management

  [+ File Management](/dev/api/knowlage-manage/queryfile)

  [+ File content extraction](/dev/api/knowlage-manage/queryextract)

  [+ Rerank](/dev/api/knowlage-manage/rerank)

* Error Codes

  [+ HTTP Status Codes](/dev/api/error-code/error-code-v4)

  [+ Model Error Codes](/dev/api/error-code/service-error)

More

[* Libraries](/dev/api/libraries)

[* API Pricing](/dev/api/product-billing)

[* Tokenizer](/dev/api/tokenizer)

[* Parameter Description](/dev/api/parameter-description)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

# GLM-Realtime

**GLM-Realtime API** provides real-time video call functionality, with the capability to perform real-time inference across text, audio, and video. AI can conduct smooth conversations, and humans can interrupt the AI in real-time. In addition to real-time audio interaction, Realtime can also interact with humans through the camera of a mobile phone or AIPC, read page information by sharing a computer screen, and understand the current environment through video streams.

* Model Encoding: glm-4-realtime;
* Product Price: Limited-time free;
* View model [Rate Limits](https://www.bigmodel.cn/dev/howuse/rate-limits) ;
* View your [API Key](https://www.bigmodel.cn/usercenter/proj-mgmt/apikeys) ;

The Audio-Video Realtime API (via /realtime) is built on top of the WebSocket API to facilitate completely asynchronous streaming communication between end-users and the model.  
The Realtime API is currently provided free of charge. If you need commercial integration or integration with the WebRTC solution, you can contact us through the [official website](https://bigmodel.cn/online-book/customerService) ;

## Interface Description

| Type | Description |
| --- | --- |
| Request Address | wss://open.bigmodel.cn/api/paas/v4/realtime |
| Transmission Protocol | Uses WebSocket Protocol:  - WebSocket protocol is a protocol for full-duplex communication over a single TCP connection.  - Both the client and server can establish persistent connections and perform bidirectional data transmission.  - The WebSocket protocol is widely used in applications requiring real-time interaction. |
| Message Format | The transmitted data can be in text format or binary format. |
| Request Authentication | Uses JWT for client authentication. The client generates a JWT and transmits it through the Header during WebSocket connection establishment. |
| Interface Features | Multimodal Input: The model supports video frames, images, and audio input, and supports text and audio output.  VAD (Voice Activity Detection): Supports model VAD, and also supports client-side VAD recognition and control.  Dialogue Interruption: Model dialogue supports being interrupted, controlled by the response.cancel message.  Historical Sessions: All session histories are stored in one WebSocket session. |

## Interface Authentication

### Client-Side Authentication

If your application needs to initiate access directly from the client side, to protect the security of your model API Key, you cannot use API Key authentication directly on the client side. Instead, your server needs to encapsulate JWT and distribute it to the client, who will then use JWT for authentication to access the model API. This is done using the standard JWT creation methods provided (for details, refer to: <https://jwt.io/introduction>).

Reference code example:

```
package com.wd.paas.test;

import com.auth0.jwt.JWT;
import com.auth0.jwt.algorithms.Algorithm;
import io.jsonwebtoken.Jwts;
import io.jsonwebtoken.SignatureAlgorithm;

import java.util.Calendar;
import java.util.Date;
import java.util.HashMap;
import java.util.Map;

public class TestToken {

   private static String generateToken(String apiKey, Long expireMillis) {
       String[] apiKeyInfo = apiKey.split("\\.");
       String api_key = apiKeyInfo[0];
       String api_secret = apiKeyInfo[1];

       long exp = (new Date().getTime() / 1000) + expireMillis;
       long timestamp = new Date().getTime();

       Map<String, Object> payload = new HashMap<>();
       payload.put("api_key", api_key);
       payload.put("exp", exp);
       payload.put("timestamp", timestamp);
       Map<String, Object> headerClaims = new HashMap<>();
       headerClaims.put("alg", "HS256");
       headerClaims.put("sign_type", "SIGN");
       String token = null;
       try {
           token =
                   JWT.create()
                           .withPayload(payload)
                           .withHeader(headerClaims)
                           .sign(Algorithm.HMAC256(api_secret.getBytes("utf-8")));
       } catch (Exception e) {
           e.printStackTrace();
       }
       return token;
   }

   public static void main(String[] args) {
       try {
           // Replace with your apikey from bigmodel.cn
           String apiKey = "xxxxxxxxx.xxxxxxxx";
           String token = generateToken(apiKey, 600L);
           System.out.println(token);
       } catch (Exception e) {
           e.printStackTrace();
       }
   }
}
Server-Side Authentication
If your application accesses your server first before calling the model API from the server, the server can directly use the API Key for authentication. Here's how to do it:

Log in to the Zhipu AI Open Platform API Keys Page to obtain the latest generated user API Key.
The API Key issued by the platform includes both the "User ID" and the "Signature Secret", in the format of {id}.{secret}.
The user needs to place the API Key in the HTTP Authorization header.
Reference code example:

import websockets

async def client():
   # Add the token as a query parameter to the WebSocket URI
   uri = f"wss://open.bigmodel.cn/api/paas/v4/realtime"
   # Custom HTTP headers, such as adding an "Authorization" header
   extra_headers = {
       "Authorization": "Bearer {0}".format("YOUR API KEY")
   }

   # Connect to the server
   async with websockets.connect(uri, extra_headers=extra_headers) as websocket:

       response = await websocket.recv()
       print(f"Server response: {response}")
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37  
38  
39  
40  
41  
42  
43  
44  
45  
46  
47  
48  
49  
50  
51  
52  
53  
54  
55  
56  
57  
58  
59  
60  
61  
62  
63  
64  
65  
66  
67  
68  
69  
70  
71  
72  
73  
74  
75  
76

## Interface Parameters

### Header

| Parameter Name | Type | Required | Parameter Description |
| --- | --- | --- | --- |
| Authorization | String | Yes | Authentication information, supports two methods:  ‚Ä¢ Use JWT to initiate and authenticate directly from the client  ‚Ä¢ Use the platform‚Äôs API Key for server-side authentication |

### Common Parameters

| Parameter Name | Type | Parameter Description |
| --- | --- | --- |
| event\_id | string | ID generated by the client to identify the event |
| type | string | Event type |
| client\_timestamp | Integer | Timestamp of the call initiation on the client side, in milliseconds |

### VAD Detection

The Realtime API supports two VAD detection methods: Server VAD mode for intelligent detection by the model, and Client VAD mode; controlled by the parameter `turn.detection.type`

|  | Server VAD Mode | Client VAD Mode |
| --- | --- | --- |
| Corresponding Field | server\_vad | client\_vad |
| Client Logic Complexity | Low, just need to keep uploading audio | High, need to determine the upload timing and trigger model timing |
| Interruption | Fully managed by Realtime Server | Determined by the client itself |
| Speech Detection | Judged by Realtime Server | Judged by the client itself |

## Data Structure

### RealtimeConversationItem

* Purpose: Defines an item in a conversation, which can be a message, function call, or function call response.
* Properties:
  + id (string, optional): Unique ID of the item, can be generated by the client.
  + type (string, required): Type of the item (message, function\_call, function\_call\_output).
  + object (string, required): Always ‚Äúrealtime.item‚Äù.
  + status (string, optional): Status of the item (completed, incomplete).
  + role (string, optional): Role of the message sender (user, assistant, system), only applicable for message type.
  + content (array, optional): Array of message content.
    - type (string, required): Content type (input\_audio, input\_text, text).
    - text (string, optional): Text content.
    - audio (string, optional): Base64 encoded audio data.
    - transcript (string, optional): Transcription text of the audio.
  + name (string, optional): Name of the function call, for function\_call type.

### RealtimeResponse

* Purpose: Defines the structure of the response object returned by the server.
* Properties:
  + id (string, required): Unique ID of the response.
  + object (string, required): Always ‚Äúrealtime.response‚Äù.
  + status (string, required): Status of the response (completed, cancelled, failed, incomplete).
  + status\_details (object, optional): Additional information about the status, such as the reason for cancellation or error information.
    - type (string, required): Status type (cancelled, incomplete, failed).
    - reason (string, optional): Reason why the response was not completed (turn\_detected, client\_cancelled, max\_output\_tokens, content\_filter).
    - error (object, optional): Error information if the status is failed.
      * type (string, required): Error type.
      * code (string, optional): Error code.
  + output (array, optional): List of output items generated by the response.
    - Each item is a RealtimeConversationItem object.
  + usage (object, optional): Usage statistics of the response, corresponding to billing information.
    - total\_tokens (integer, optional): Total number of tokens used.
    - input\_tokens (integer, optional): Number of input tokens used.
    - output\_tokens (integer, optional): Number of output tokens used.
    - input\_token\_details (object, optional): Detailed information about input tokens.
      * cached\_tokens (integer, optional): Number of cached tokens used.
      * text\_tokens (integer, optional): Number of text tokens used.
      * audio\_tokens (integer, optional): Number of audio tokens used.
    - output\_token\_details (object, optional): Detailed information about output tokens.
      * text\_tokens (integer, optional): Number of text tokens output.
      * audio\_tokens (integer, optional): Number of audio tokens output.

## Client Events

| Event | Description |
| --- | --- |
| RealtimeClientEventSessionUpdate | Session configuration, update default session settings through this event |
| RealtimeClientEventInputAudioBufferAppend | Upload audio |
| RealtimeClientEventInputAudioBufferAppendVideoFrame | In video call mode, report video frame |
| RealtimeClientEventInputAudioBufferCommit | Commit audio |
| RealtimeClientEventConversationItemCreate | Used for text input and upload function call results |
| RealtimeClientEventResponseCreate | Create model call, inference response |
| RealtimeClientEventResponseCancel | Cancel model call |

### Session Configuration session.update

Through this event, update the default configuration of the session, which is set to audio call by default and uses the default values of the above parameters, such as `output_audio_format` set to pcm.

* Special Note: When `session.update` switches the `chat_mode` call mode, there is a default conversation history handling policy by the system:
* From `video` to `audio`, the conversation history will be discarded;
* From `audio` to `video`, the conversation history will be retained;

| Parameter Name | Type | Parameter Description |
| --- | --- | --- |
| session | object | Real-time conversation configuration information |
| input\_audio\_format | string | Audio input format, supports wav; |
| output\_audio\_format | string | Audio output format, supports pcm, mp3, default pcm |
| instructions | string | System instructions, used to guide the model to generate the expected response. Default content see below table |
| turn\_detection | object |  |
| type | string | VAD detection type, supports client\_vad (default), server\_vad |
| beta\_fields | object |  |
| chat\_mode | string | Required, call mode: video\_passive, audio (default) |
| tts\_source | string | Method of speech to text conversion, supports: e2e |
| auto\_search | bool | Whether to enable built-in auto search (set to true, the search engine is built-in on the server, no need to pass in). The switch is only valid in audio mode, and in video mode, the model controls auto supplementation of search content. Default is true |
| tools | object | When using ServerVAD, update tools to pass in turn\_detection at the same time to preventËØØsetting back to client VAD |
| type | string | Type of tool, set to function |
| name | string | Function name |
| description | string | Description of the function. The model will decide the function calling method based on this description. |
| parameters | object | The parameters field needs to pass in a Json Schema object to accurately define the parameters accepted by the function. |

```
{
   "event_id": "",
   "type": "session.update",
   "session": {
       "input_audio_format": "wav",
       "output_audio_format": "wav",
       "instructions": "",
       "turn_detection": {
           "type": "server_vad"
       },
       "beta_fields": {
           "chat_mode": "video_passive",
           "tts_source": "e2e",
           "auto_search": true
       },
       "tools": [
           {
               "type": "function",
               "name": "search_engine",
               "description": "Execute general search based on the given query",
               "parameters": {
                   "type": "object",
                   "properties": {
                       "q": {
                           "type": "string",
                           "description": "Search query"
                       }
                   },
                   "required": [
                       "q"
                   ]
               }
           }
       ]
   }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36

## Upload Audio `input_audio_buffer.append`

This event is used to upload audio to the buffer.

* When using Server VAD mode, the model automatically detects speech and decides when to submit.
* When using ClientVAD mode, audio must be manually submitted. You can determine the audio length during upload - shorter audio yields faster response times, with a maximum duration of 30 seconds permitted.
* The maximum audio submission rate is 50 QPS. Exceeding this limit will trigger rate limiting and packet drops. For real-time audio streaming, we recommend dividing the audio into 100ms frames and sending 10 frames per second.

| Parameter Name | Required or Optional | Type | Description |
| --- | --- | --- | --- |
| type | Y | string | Event type, the type for uploading audio is `input_audio_buffer.append` |
| audio | Y | string | The audio (wav or pcm) binary data as a base64-encoded string |

* Example:

```
{"type":"input_audio_buffer.append","audio":"UklGRiQgAABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAAZGF0YQAgAAAAAP7//v8BAAMABQAIAAoACAAKAAUABwAIAAUABQABAAEAA","client_timestamp":1731999464667}
```

1

### Upload video frame: input\_audio\_buffer.append\_video\_frame

This event is used to upload video frames to the buffer. Note that the video model requires at least 2 image frames for perception. We recommend sending images at a rate of 2 FPS (2 frames per second). Sending too quickly may cause backlog.

| Parameter Name | Required or Optional | Type | Description |
| --- | --- | --- | --- |
| type | Y | string | Event type: `input_audio_buffer.append_video_frame` |
| audio | Y | string | Supports .jpg format images with base64 encoding |

* Example:

```
 {
"type":"input_audio_buffer.append_video_frame",
"video_frame":"<base64 encoded (jpg image)>",
"client_timestamp":1731999464667
}}
```

1  
2  
3  
4  
5

### Clear audio in buffer: input\_audio\_buffer.clear

The client sends the `input_audio_buffer.clear` event to clear audio data in the buffer.  
The server responds with the `input_audio_buffer.cleared` event.

| Parameter Name | Required or Optional | Type | Description |
| --- | --- | --- | --- |
| type | Y | string | Event type: The event type for clearing audio is `input_audio_buffer.clear` |

### Submit audio/video: input\_audio\_buffer.commit

Submit uploaded audio files. This event must be preceded by input\_audio\_buffer.append, and at least one valid audio or video file must be uploaded; otherwise, the commit event will report an error. In ServerVAD mode, there is no need to send this event as the model will automatically upload and submit audio.  
When calling input\_audio\_buffer.commit, if video\_frames exist in the buffer, they will be packaged together and submitted for model inference.

| Parameter Name | Required or Optional | Type | Description |
| --- | --- | --- | --- |
| type | Y | string | Event type: The event type for uploading audio is `input_audio_buffer.commit` |

* Example:

```
{"type":"input_audio_buffer.commit","client_timestamp":1732000439437}
```

1

### Fill conversation information: conversation.item.create

Add an item to the conversation context containing messages and function call response results. This content can be incorporated into the conversation history (session context/history). The system will send an error event if either the input text is empty or function.call.item is empty.

| Parameter Name | Required or Optional | Type | Description |
| --- | --- | --- | --- |
| type | Y | string | Event type: The event type for populating conversation information is conversation.item.create |
| item | Y | object |  |
| type | Y | string | Item typesÔºöfunction\_call\_output: The returned result of a function call |
| output | Y | string | Function call result input, applicable to the function\_call\_output type |

* Example:Function call input

```
{
    "event_id": "evt_fakeId",
    "type": "conversation.item.create",
    "item": {
        "type": "function_call_output",
        "output": "{\"queryContext\":{\"original_query\":\"Beijing weather\"},\"rankingResponse\":{\"mainline\":{\"items\":[]}},\"webPages\":{\"totalEstimatedMatches\":10,\"value\":[{\"cached_page_url\":\"\",\"date_last_crawled\":\"\",\"date_published\":\"\",\"date_published_display_text\":\"\",\"display_url\":\"http://weather.com.cn/weather/101010100.shtml\",\"icon_link\":\"\",\"id\":\"\",\"is_family_friendly\":true,\"is_navigational\":false,\"language\":\"zh_chs\",\"media\":\"\",\"name\":\"Beijing Weather\",\"snippet\":\"Current Beijing weather (November 27, 2024): Sunny, 4.6¬∞C, NW wind 3 m/s, humidity: 27%, air quality: 20.\\n7-day forecast:\\n(Nov 27, 2024): Day: Cloudy, High 3¬∞C, NW wind <3 m/s. Night: Cloudy, Low -4¬∞C, NW wind <3 m/s\\n(Nov 28, 2024): Day: Sunny, High 7¬∞C, NW wind <3 m/s. Night: Sunny, Low -2¬∞C, SW wind <3 m/s\\n(Nov 29, 2024): Day: Sunny, High 11¬∞C, NW wind <3 m/s. Night: Sunny, Low 2¬∞C, N wind <3 m/s\\n(Nov 30, 2024): Day: Cloudy, High 12¬∞C, SW wind <3 m/s. Night: Cloudy, Low 0¬∞C, N wind <3 m/s\\n(Dec 1, 2024): Day: Cloudy, High 10¬∞C, N wind <3 m/s. Night: Sunny, Low -2¬∞C, N wind 3-4 m/s\\n(Dec 2, 2024): Day: Sunny, High 5¬∞C, NW wind <3 m/s. Night: Cloudy, Low -4¬∞C, SW wind <3 m/s\\n(Dec 3, 2024): Day: Cloudy, High 5¬∞C, SW wind <3 m/s. Night: Sunny, Low -3¬∞C, SW wind <3 m/s\\n\",\"url\":\"http://weather.com.cn/weather/101010100.shtml\"}],\"webSearchUrl\":\"\"}}"
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8

### Delete a round of conversation from the history: conversation.item.delete

| Parameter Name | Required or Optional | Type | Description |
| --- | --- | --- | --- |
| type | Y | string | Event type: conversation.item.delete |
| item\_id | Y | object | item\_id of the conversation item to be deleted |
| event\_id | Y | string | Event ID generated by the client |

### Create model response: response.create

This event creates a server response and also triggers model inference. In ServerVAD mode, the server automatically creates responses. In ClientVAD mode for video calls, video frames and audio at this time point must be passed to the model.  
When chat\_mode is video, at least one image must be uploaded via the input\_audio\_buffer.append\_video\_frame event before submitting this event. Otherwise, model response creation will fail and return a video\_model\_query\_error event.

| Parameter Name | Required or Optional | Type | Description |
| --- | --- | --- | --- |
| type | Y | string | Event type: The event type for creating model responses is `response.create` |

### Cancel model call: response.cancel

| Parameter Name | Required or Optional | Type | Description |
| --- | --- | --- | --- |
| type | Y | Cancel model call: `response.cancel` |  |

* Example:

```
 {"type":"response.cancel","client_timestamp":1732000444494}
```

1

## Server-Side Events

| Event | Description |
| --- | --- |
| RealtimeServerEventError | Server event triggered when an error occurs. |
| RealtimeServerEventSessionCreated | Server event triggered when a session is created. Immediately emitted after session creation. |
| RealtimeServerEventSessionUpdated | Server event triggered when a session is updated. |
| RealtimeServerEventConversationItemCreated | Server event triggered when a conversation item is created. |
| RealtimeServerEventConversationItemInputAudioTranscriptionCompleted | Server event triggered when input audio transcription is enabled and successfully completed. |
| RealtimeServerEventInputAudioBufferCommitted | Server event triggered when the input audio buffer is committed by the client or automatically in server VAD mode. |
| RealtimeServerEventInputAudioBufferSpeechStarted | Server event triggered when speech is detected in the audio buffer in server VAD mode. |
| RealtimeServerEventInputAudioBufferSpeechStopped | Server event triggered when speech stops in the audio buffer in server VAD mode. |
| RealtimeServerEventResponseAudioDelta | Server event triggered when the model-generated audio is updated. |
| RealtimeServerEventResponseAudioTranscriptDelta | Server event triggered when the model-generated audio output text is updated. |
| RealtimeServerEventResponseCreated | Server event triggered when a new response is created. |
| RealtimeServerEventResponseDone | Server event triggered when response streaming is completed, indicating the end of the reply. |
| RealtimeServerEventResponseFunctionCallArgumentsDone | Server event triggered when the model-generated function call arguments are completed. Multiple calls may be returned if there are multiple function call results. |
| RealtimeServerEventHeartbeat | Server event for heartbeat to keep the session alive. |
| RealtimeServerEventResponseFunctionCallSimpleBrowser | Server event triggered when the video link triggers the built-in search. |

### RealtimeServerEventError

When an error occurs, the system returns a server `error` event (it could be a client issue or a server issue, refer to the error code documentation for specifics). Most errors are recoverable, and the session will remain open.

| Parameter Name | Type | Description |
| --- | --- | --- |
| type | string | The event type must be **error**. |
| error | object | Detailed information about the error. |
| type | string | The type of error. For example, ‚Äúinvalid\_request\_error‚Äù and ‚Äúserver\_error‚Äù are error types. |
| code | string | The error code (if any). |
| message | string | A user-readable error message. |

* Example:

```
 {
    "event_id": "event_890",
    "type": "error",
    "error": {
        "type": "invalid_request_error",
        "code": "invalid_event",
        "message": "The 'type' field is missing.",
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9

### RealtimeServerEventSessionUpdated

The server will immediately return a `session.updated` event after creating/updating a session.

| Parameter Name | Type | Description |
| --- | --- | --- |
| event\_id | string | Unique ID of the server event |
| type | string | Event type must be `session.updated` |
| session | object | Configuration information for the current session |

* Example

```
{
    "event_id": "",
    "type": "session.update",
    "session": {
        "model":"glm-realtime-flash"
        "input_audio_format": "wav",
        "output_audio_format": "pcm",
        "instructions": "",
        "turn_detection": {
            "type": "server_vad"
        },
        "beta_fields": {
            "chat_mode": "audio",
            "tts_source": "e2e",
            "auto_search": "True"
        },
        "tools": [
            {
                "type": "function",
                "name": "search_engine",
                "description": "Perform general search based on the given query",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "q": {
                            "type": "string",
                            "description": "Search query"
                        }
                    },
                    "required": [
                        "q"
                    ]
                }
            }
        ]
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37

### RealtimeServerEventConversationCreated

The server will immediately return a `conversation.created` event after creating a session. Each session creates one conversation.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | Unique ID of the server event |
| **type** | string | Event type must be `conversation.created` |
| **conversation** | object | Current conversation |
| **id** | string | Unique ID of the conversation |
| **object** | string | Object type must be `realtime.conversation` |

* Example

```
{
  "type": "conversation.created",
  "conversation": {
    "id": "<id>",
    "object": "<object>"
  }
}
```

1  
2  
3  
4  
5  
6  
7

### RealtimeServerEventConversationItemCreated

The server will return a `conversation.item.created` event when creating a conversation item.

‰ª•‰∏ãÊòØÊ†πÊçÆ‰Ω†Êèê‰æõÁöÑÂõæÁâáÁîüÊàêÁöÑ HTML Ë°®Ê†º‰ª£Á†ÅÔºå‰øùÊåÅÊ†ºÂºè„ÄÅÂä†Á≤ó„ÄÅÊç¢Ë°å‰∏çÂèòÔºåÂπ∂Â∞Ü‰∏≠ÊñáÁøªËØë‰∏∫Ëã±ÊñáÔºàÁ±ªÂûã‰∏ÄÂàó‰øùÊåÅÂéüÊ†∑ÔºâÔºö

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | Unique ID of the server event |
| **type** | string | Event type must be `conversation.item.created` |
| **item** | object | Created item |
| **id** | string | ID parameter returned |
| **object** | object (RealtimeConversationItem) | Created item |
| **type** | string | The item's type includes `message`, `function_call`, `function_call_output` |
| **output** | string | Function call result output |

```
{"event_id":"event1b6ac5f7417e4c96b3e9ba5ca3bbb902","type":"conversation.item.created","delta":"","item":{"id":"iteme3e2203700cc464e9dc1025c78aa25ff","object":"realtime.item","type":"function_call_output","status":"","role":"","content":null,"output":"success"}}
```

1

### RealtimeServerEventConversationItemInputAudioTranscriptionCompleted

Write speech-to-text results to the audio buffer. Speech-to-text runs asynchronously with response creation, and this event may occur before or after the response event.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | Unique ID of the server event |
| **type** | string | Event type must be `conversation.item.input_audio_transcription.completed` |
| **item\_id** | string | ID of the user message item containing audio |
| **transcript** | string | Text after audio transcription |

* Example

```
{
  "type": "conversation.item.input_audio_transcription.completed",
  "event_id": "event_ASFKtkZnkS1B5zU49KPP8",
  "item_id": "item_ASFKsCEx8iuucKeuJOBvX",
  "transcript": "Tell me a cold joke."
}
```

1  
2  
3  
4  
5  
6

### RealtimeServerEventConversationItemInputAudioTranscriptionFailed

The system returns a server `conversation.item.input_audio_transcription.failed` event when input audio transcription is configured and the user message transcription request fails. This event is separate from other error events to allow client-side identification of the relevant item.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | Unique ID of the server event |
| **type** | string | Event type must be `conversation.item.input_audio_transcription.failed` |
| **item\_id** | string | ID of the user message item containing audio |
| **content\_index** | integer | Index of the audio content part |
| **error** | object | Detailed error information |
| **type** | string | Error type. For example, `"invalid_request_error"` and `"server_error"` are error types |
| **code** | string | Error code (if any) |
| **message** | string | User-readable error message |

* Example

```
{
  "type": "conversation.item.input_audio_transcription.failed",
  "item_id": "<item_id>",
  "content_index": 0,
  "error": {
    "code": "<code>",
    "message": "<message>",
    "param": "<param>"
  }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10

### RealtimeServerEventInputAudioBufferCommitted

The system returns a server `input_audio_buffer.committe` event when the input audio buffer is submitted by the client or automatically submitted in server VAD mode.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event. |
| **type** | string | The event type must be `input_audio_buffer.committed`. |
| **item\_id** | string | The ID of the created user message item. |

* Example:

```
{"event_id":"event19d716550d9f43ac92bfc2aae07e74f7","type":"input_audio_buffer.committed","item_id":"item0f49455339d04574bf62b73beaad0756"}
```

1

### RealtimeServerEventInputAudioBufferCleared

The system returns a server `input_audio_buffer.cleared` event when the client uses the `input_audio_buffer.clear` event to clear the input audio buffer.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| event\_id | string | The unique id of the server event. |
| type | string | The event type must be `input_audio_buffer.cleared`. |

* Example

```
{
  "event_id": "<event_id>",
  "type": "input_audio_buffer.cleared"
}
```

1  
2  
3  
4

### RealtimeServerEventInputAudioBufferSpeechStarted

The system returns a server input\_audio\_buffer.speech\_started event in server\_vad mode when speech is detected in the audio buffer.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event. |
| **type** | string | The event type must be `input_audio_buffer.speech_started`. |
| **item\_id** | string | The ID of the user message item created when speech stops. |

```
{"event_id":"event7e2c218d1f8a4f01bbdc857922e6fe86","type":"input_audio_buffer.speech_started"}
```

1

### RealtimeServerEventInputAudioBufferSpeechStopped

The system returns a server `input_audio_buffer.speech_stopped` event when speech ends in the audio buffer under server\_vad mode.  
The server also sends a `conversation.item.created`S event containing the user message item created from the audio buffer.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event. |
| **type** | string | The event type must be `input_audio_buffer.speech_stopped`. |

```
{"event_id":"evente5587f654b294efd964dd03d8653d65b","type":"input_audio_buffer.speech_stopped"}
```

1

### RealtimeServerEventResponseTextDelta

The system returns a server `response.text.delta` event when updating model-generated text. The text corresponds to the content portion of the assistant message item.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event. |
| **type** | string | The event type must be `response.text.delta`. |
| **response\_id** | string | The unique ID of the response event. |
| **delta** | string | The result of converting the voice output by the model into text. |
| **item\_id** | string | The ID of the Response conversation item. |

* Example

```
{"event_id":"event2dfd64945afc446b8626c131d3b92556","type":"response.text.delta","client_timestamp":1737454110889,"response_id":"resp3840c7f9227f411b95ec55902b5363d6","output_index":0,"content_index":0,"delta":"audience","item_id":"itemxxxxxxx"}
```

1

### RealtimeServerEventResponseTextDone

The system returns a server `response.text.done` event when model-generated text completes streaming. The `text` corresponds to the content portion of the assistant message item.  
This event is also returned when the response is interrupted, incomplete, or canceled.

| **Parameter Name** | **Type** | **PDescription** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event. |
| **type** | string | The event type must be `response.text.done`. |
| **response\_id** | string | The unique ID of the response event. |
| **item\_id** | string | The ID of the item. |
| **output\_index** | integer | The index of the output item in the response. |
| **content\_index** | integer | The index of the content part in the array within the item. |
| **transcript** | string | The final text of the audio. |

* Example

```
{
  "type": "response.text.done",
  "response_id": "<response_id>",
  "item_id": "<item_id>",
  "output_index": 0,
  "content_index": 0,
  "transcript": "<transcript>"
}
```

1  
2  
3  
4  
5  
6  
7  
8

### RealtimeServerEventResponseAudioDelta

The system returns a server `response.audio.delta` event when updating model-generated audio. The delta is a base64-encoded PCM audio chunk in 24kHz mono format.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event. |
| **type** | string | The event type must be `response.audio.delta`. |
| **response\_id** | string | The unique ID of the response event. |
| **delta** | string | Base64-encoded audio data delta. |
| **item\_id** | string | The ID of the Response conversation item. |

* Example

```
{"event_id":"event89a3eb3140b54bd6b89952793d5b2f19","type":"response.audio.delta","client_timestamp":1737454096061,"response_id":"respbc50304acdea479b8bd55efd5346dbdf","output_index":0,"content_index":0,"delta":"+w6hBu39R/US8Mzuo+0A68DpKOw28Cv0ivYU9Pvwn+1t6h7odeca61vzTf76Ci8ViRnwGMUUOhPKEQ0MowMZ/E/3fPak+Bv4c/ci+b35n/jw9l/yb/Cd8brvtOzD7kPvXvBi937+PQPbCIIPXxIWEeENA", "item_id":"itemxxxxxxx"}
```

1

### RealtimeServerEventResponseAudioDone

The system returns a server `response.audio.done` event when model-generated audio is complete.  
This event is also returned when the response is interrupted, incomplete, or canceled.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event. |
| **type** | string | The event type must be response.audio\_transcript.delta |
| **response\_id** | string | The unique ID of the response event. |
| **item\_id** | string | The ID of the item. |
| **output\_index** | integer | The index of the output item in the response. |
| **content\_index** | integer | The index of the content part in the item's content array. |

* Example

```
{
  "type": "response.audio.done",
  "response_id": "<response_id>",
  "item_id": "<item_id>",
  "output_index": 0,
  "content_index": 0
}
```

1  
2  
3  
4  
5  
6  
7

### RealtimeServerEventResponseAudioTranscriptDelta

The system returns a server `response.audio_transcript.delta` event when updating model-generated audio output speech-to-text conversion.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event. |
| **type** | string | The event type must be response.audio.transcript.delta |
| **response\_id** | string | The unique ID of the response event. |
| **delta** | string | The result of converting the voice output by the model into text. |
| **item\_id** | string | The ID of the Response conversation item. |

* Example

```
{"event_id":"event2dfd64945afc446b8626c131d3b92556","type":"response.audio_transcript.delta","client_timestamp":1737454110889,"response_id":"resp3840c7f9227f411b95ec55902b5363d6","output_index":0,"content_index":0,"delta":"audience","item_id":"itemxxxxxxx"}
```

1

### 

RealtimeServerEventResponseAudioTranscriptDone  
The system returns a server `response.audio_transcript.done` event when model-generated audio output transcription completes streaming.  
This event is also returned when the response is interrupted, incomplete, or canceled.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event |
| **type** | string | The event type must be `response.audio_transcript.done` |
| **response\_id** | string | The unique ID of the response event |
| **item\_id** | string | The ID of the item |
| **output\_index** | integer | The index of the output item in the response. |
| **content\_index** | integer | The index of the content part in the item content array. |
| **transcript** | string | The final text of the audio. |

* Example

```
{
  "type": "response.audio_transcript.done",
  "response_id": "<response_id>",
  "item_id": "<item_id>",
  "output_index": 0,
  "content_index": 0,
  "transcript": "<transcript>"
}
```

1  
2  
3  
4  
5  
6  
7  
8

### 

RealtimeServerEventResponseOutputItemAdded  
The system returns a server `response.output_item.added` event when creating new items during response generation.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event |
| **type** | string | The event type must be `response.output_item.added` |
| **response\_id** | string | The unique ID of the response event |
| **output\_index** | integer | The index of the output item in the response. |
| **item** | RealtimeConversationItem | See data structure RealtimeConversationItem. |

* Example

```
{
    "event_id": "event_3334",
    "type": "response.output_item.added",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "in_progress",
        "role": "assistant",
        "content": []
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14

### RealtimeServerEventResponseOutputItemDone

The system returns a server `response.output_item.done` event when item streaming is complete.  
This event is also returned when the response is interrupted, incomplete, or canceled.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event |
| **type** | string | The event type must be response.output\_item.done |
| **response\_id** | string | The unique ID of the response event |
| **output\_index** | integer | The index of the output item in the response. |
| **item** | RealtimeConversationItem | See data structure RealtimeConversationItem. |

* Example

```
{
    "event_id": "event_3536",
    "type": "response.output_item.done",
    "response_id": "resp_001",
    "output_index": 0,
    "item": {
        "id": "msg_007",
        "object": "realtime.item",
        "type": "message",
        "status": "completed",
        "role": "assistant",
        "content": [
            {
                "type": "text",
                "text": "Sure, I can help with that."
            }
        ]
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19

### RealtimeServerEventResponseContentPartAdded

The system returns a server `response.content_part.added` event when new content parts are added to assistant message items during response generation.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **eventid** | string | The unique ID of the server event |
| **type** | string | The event type must be response.outputitem.addeda |
| **responseid** | string | The unique ID of the response event |
| **outputindex** | integer | The index of the output item in the response. |
| **item** | object | See data structure RealtimeConversationItem. |

* Example

```
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12

### RealtimeServerEventResponseContentPartDone

The system returns a server `response.content_part.done` event when content parts complete streaming in assistant message items.  
This event is also returned when the response is interrupted, incomplete, or canceled.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event |
| **type** | string | The event type must be response.content\_part.done |
| **response\_id** | string | The unique ID of the response event |
| **item\_id** | string | The ID of the item |
| **output\_index** | integer | The index of the output item in the response |
| **content\_index** | integer | The index of the content part in the item content array |
| **part** | ContentPart | The added content part |

* Example

```
{
    "event_id": "event_3738",
    "type": "response.content_part.added",
    "response_id": "resp_001",
    "item_id": "msg_007",
    "output_index": 0,
    "content_index": 0,
    "part": {
        "type": "text",
        "text": ""
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12

### RealtimeServerEventResponseCreated

The system returns a server `response.done` event when creating a new response.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event |
| **type** | string | The event type must be `response.created` |
| **response** | object (RealtimeResponse) | See data structure RealtimeResponse |

* Example

```
{
  "event_id": "eventc385dd417574478086bfe80a1a8508d1",
  "type": "response.created",
  "client_timestamp": 1739001414866,
  "response": {
    "object": "realtime.response",
    "id": "respee64945eafb44facac88cea6f9de86f5",
    "status": "in_progress",
    "usage": {
      "total_tokens": 0,
      "input_tokens": 0,
      "output_tokens": 0,
      "input_token_details": {
        "text_tokens": 0,
        "audio_tokens": 0
      },
      "output_token_details": {
        "text_tokens": 0,
        "audio_tokens": 0
      }
    }
  }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23

### 

RealtimeServerEventResponseCancelled  
The system responds to client event `response.cancel` by terminating any in-progress response.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event |
| **type** | string | The event type must be `response.cancelled` |
| **response** | RealtimeResponse | See data structure RealtimeResponse |

* Example

```
{
  "event_id": "eventc385dd417574478086bfe80a1a8508d1",
  "type": "response.cancelled",
  "client_timestamp": 1739001414866,
  "response": {
    "object": "realtime.response",
    "id": "respee64945eafb44facac88cea6f9de86f5",
    "status": "cancelled"
  }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10

### RealtimeServerEventResponseDone

The system returns a server `response.done` event when response streaming completes. This event is always emitted regardless of final status.  
Consumed tokens are returned in the `response.done` event, including complete input and output token information.

| **Parameter Name** | Type | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event |
| **type** | string | The event type must be `response.done` |
| **response** | object (RealtimeResponse) | See data structure RealtimeResponse |

* Example

```
{
    "event_id": "eventb94f1f3b5c7e4ee9b9091a012cfb11bd",
    "type": "response.done",
    "client_timestamp": 1739001415611,
    "response": {
        "id": "respee64945eafb44facac88cea6f9de86f5",
        "status": "completed",
        "usage": {
            "total_tokens": 0,
            "input_tokens": 0,
            "output_tokens": 0,
            "input_token_details": {
                "text_tokens": 0,
                "audio_tokens": 0
            },
            "output_token_details": {
                "text_tokens": 0,
                "audio_tokens": 0
            }
        }
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22

### RealtimeServerEventResponseFunctionCallArgumentsDone

The system returns a server `response.function_call_arguments.done` event for model-generated function calls.  
When a query requires multiple function calls (e.g. ‚ÄúSearch weather for Beijing and Shanghai‚Äù), the model may return multiple calls. The system will then emit multiple `response.function_call_arguments.done` events corresponding to each call. SS  
Currently this event is only returned for successful responses. Support for interrupted/incomplete/canceled cases is under development.

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| **event\_id** | string | The unique ID of the server event |
| **type** | string | The event type must be response.function\_call.arguments.done |
| **client\_timestamp** | Integer | The timestamp (in milliseconds) when the calling end initiates the call |
| **response\_id** | string | The unique ID of the response event |
| **arguments** | string | Function call parameters, in JSON string format, need to be parsed by yourself |
| **name** | string | The name of the function |

```
{"event_id":"event598e94dcf9084afb89b4f093a5c1cd59","type":"response.function_call_arguments.done","client_timestamp":1737454330410,"response_id":"resp15b6021ce20c4d1094fffc0ec3e183c4","output_index":0,"arguments":"{\"name\": \Zhangsan\"}", "name": "phoneCall"}
```

1

### RealtimeServerEventResponseFunctionCallSimpleBrowser

The video model has a built-in search tool. When recognizing that a user‚Äôs query requires external data retrieval through search, it returns this event. The service automatically calls the search interface internally to obtain data. After acquiring search results, it recalls the model and continues streaming the response data upon receiving the model‚Äôs reply.  
This event occurs after the response.created event and before the `response.audio_transcript.delta` event. If the search encounters errors, it returns the error event `video_model_query_error`.  
The current video pipeline doesn‚Äôt yet support toggling the search tool - this functionality will be added in future versions.

```
{
    "event_id": "event4ddadf069e454cb4b75133007c992811",
    "type": "response.function_call.simple_browser",
    "name": "simple_brower",
    "session": {
        "beta_fields": {
            "simple_brower": {
                "description": "Let me check that for you" // Stalling phrase before search, will also be synthesized into voice response
            }
        }
    }
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12

### RealtimeServerEventHeartbeat

The system returns this when a session is created/updated, and subsequently every 30 seconds. The heartbeat indicates the conversation is currently in an active connected state.

* Example

```
{"type": "heartbeat"}
```

1

Table of contents

Interface Description

Interface Authentication

Client-Side Authentication

Interface Parameters

Header

Common Parameters

VAD Detection

Data Structure

RealtimeConversationItem

RealtimeResponse

Client Events

Session Configuration session.update

Upload Audio input\_audio\_buffer.append

Upload video frame: input\_audio\_buffer.append\_video\_frame

Clear audio in buffer: input\_audio\_buffer.clear

Submit audio/video: input\_audio\_buffer.commit

Fill conversation information: conversation.item.create

Delete a round of conversation from the history: conversation.item.delete

Create model response: response.create

Cancel model call: response.cancel

Server-Side Events

RealtimeServerEventError

RealtimeServerEventSessionUpdated

RealtimeServerEventConversationCreated

RealtimeServerEventConversationItemCreated

RealtimeServerEventConversationItemInputAudioTranscriptionCompleted

RealtimeServerEventConversationItemInputAudioTranscriptionFailed

RealtimeServerEventInputAudioBufferCommitted

RealtimeServerEventInputAudioBufferCleared

RealtimeServerEventInputAudioBufferSpeechStarted

RealtimeServerEventInputAudioBufferSpeechStopped

RealtimeServerEventResponseTextDelta

RealtimeServerEventResponseTextDone

RealtimeServerEventResponseAudioDelta

RealtimeServerEventResponseAudioDone

RealtimeServerEventResponseAudioTranscriptDelta

RealtimeServerEventResponseOutputItemDone

RealtimeServerEventResponseContentPartAdded

RealtimeServerEventResponseContentPartDone

RealtimeServerEventResponseCreated

RealtimeServerEventResponseDone

RealtimeServerEventResponseFunctionCallArgumentsDone

RealtimeServerEventResponseFunctionCallSimpleBrowser

RealtimeServerEventHeartbeat