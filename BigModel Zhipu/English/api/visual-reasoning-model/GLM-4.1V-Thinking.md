[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fapi%2Fvisual-reasoning-model%2FGLM-4.1V-Thinking)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

API REFERENCE

* SDK Calling

  [+ Installation](/dev/api/devguide/sdk-install)

  [+ Authentication](/dev/api/devguide/sdk-auth)

  [+ sdk\_example](/dev/api/devguide/sdk_example)

* HTTP Request

  [+ API Request](/dev/api/http-call/http-para)

  [+ Authentication](/dev/api/http-call/http-auth)

* More Frameworks

  [+ OpenAI SDK](/dev/api/thirdparty-frame/openai-sdk)

  [+ Langchain SDK](/dev/api/thirdparty-frame/langchain-sdk)

APIs

* Language models

  [+ GLM-4 Models](/dev/api/normal-model/glm-4)

  [+ GLM-4V Models](/dev/api/normal-model/glm-4v)

* Reasoning models

  [+ GLM-Z1](/dev/api/Reasoning-models/glm-z1)

* Video Generation

  [+ CogVideoX](/dev/api/videomodel/cogvideox)

  [+ CogVideoX-3](/dev/api/videomodel/cogvideox-3)

  [+ Vidu Models](/dev/api/videomodel/vidu)

* Audio-Video

  [+ GLM-4-Voice](/dev/api/rtav/GLM-4-Voice)

  [+ GLM-Realtime](/dev/api/rtav/GLM-Realtime)

  [+ GLM-ASR](/dev/api/rtav/glm-asr)

* Reasoning models

  [+ GLM-4.1V-Thinking](/dev/api/visual-reasoning-model/GLM-4.1V-Thinking)

* Agent

  [+ TranslationAgent](/dev/api/agent/general_translation)

  [+ Professional Document Translation](/dev/api/agent/doc_translation_agent)

  [+ Social Science and Literary Translation](/dev/api/agent/social_literature_translation_agent)

  [+ Subtitle Translation for Film and Television](/dev/api/agent/subtitle_translation_agent)

  [+ Social Media Translation](/dev/api/agent/social_translation_agent)

  [+ AI Drawing](/dev/api/agent/ai_drawing_agent)

  [+ AI Comics](/dev/api/agent/cartoon_generator_agent)

  [+ Popular Special Effects Videos](/dev/api/agent/vidu_template_agent)

  [+ Resume and Job Matching Assistant](/dev/api/agent/job_matching_agent)

  [+ Customer Service Script Quality Inspection](/dev/api/agent/service_check_agent)

  [+ Sales Quality Inspection](/dev/api/agent/sales_check_agent)

  [+ Bill Recognition](/dev/api/agent/receipt_recognition_agent)

  [+ Clothes Recognition](/dev/api/agent/clothes_recognition_agent)

  [+ Contract Analysis](/dev/api/agent/contract_parser_agent)

  [+ Tendering Analysis Agent](/dev/api/agent/bidding_parser_agent)

  [+ Winning Bid Analysis Agent](/dev/api/agent/bidwin_parser_agent)

  [+ Intelligent Problem Solving](/dev/api/agent/intelligent_education_solve_agent)

  [+ Homework Grading](/dev/api/agent/intelligent_education_correction_agent)

* search-tool

  [+ Web Search API](/dev/api/search-tool/web-search)

  [+ Web Search in Chat](/dev/api/search-tool/websearch-in-chat)

  [+ Search Agent](/dev/api/search-tool/agent-search)

* Image Generation

  [+ CogView-4](/dev/api/image-model/cogview)

* Agent Model

  [+ GLM-4-AllTools](/dev/api/intelligent-agent-model/glm-4-alltools)

  [+ GLM-4-Assistant](/dev/api/intelligent-agent-model/assistantapi)

* Code Programming

  [+ CodeGeeX-4](/dev/api/code-model/codegeex-4)

* Embedding

  [+ Embedding](/dev/api/vector/embedding)

* Moderations

  [+ moderations](/dev/api/moderations/moderations)

* Role-playing

  [+ CharGLM-4](/dev/api/super-humanoid/charglm-4)

  [+ Emohaa](/dev/api/super-humanoid/emohaa)

* Agent Development Platform

  [+ „ÄêNew„Äëqingliuagent](/dev/api/Agent_Platform/newagent)

  [+ agent](/dev/api/Agent_Platform/agent)

  [+ qingliuSDK](/dev/api/Agent_Platform/agentsdk)

  [+ Knowledge](/dev/api/Agent_Platform/knowledge)

  [+ FinAgent](/dev/api/Agent_Platform/FinAgent)

* Batch

  [+ Batch](/dev/api/batch-api/batch)

* Data Management

  [+ File Management](/dev/api/knowlage-manage/queryfile)

  [+ File content extraction](/dev/api/knowlage-manage/queryextract)

  [+ Rerank](/dev/api/knowlage-manage/rerank)

* Error Codes

  [+ HTTP Status Codes](/dev/api/error-code/error-code-v4)

  [+ Model Error Codes](/dev/api/error-code/service-error)

More

[* Libraries](/dev/api/libraries)

[* API Pricing](/dev/api/product-billing)

[* Tokenizer](/dev/api/tokenizer)

[* Parameter Description](/dev/api/parameter-description)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

# GLM-4.1V-Thinking

GLM-4.1V-Thinking-Flash is currently the most powerful visual model among known 10B-level VLMs, integrating state-of-the-art (SOTA) capabilities in various vision-language tasks, including video understanding, image Q&A, subject problem-solving, OCR text recognition, document and chart interpretation, GUI Agent, front-end web coding, grounding, and more. Its performance in multiple tasks even surpasses that of the 8x larger parameter model, Qwen2.5-VL-72B. Leveraging advanced reinforcement learning techniques, the model has mastered chain-of-thought reasoning to enhance the accuracy and richness of its responses, significantly outperforming traditional non-thinking models in terms of final results and interpretability.

* Model Codes: GLM-4.1V-Thinking-FlashX, GLM-4.1V-Thinking-Flash
* Context Length: 64K
* Experience the powerful capabilities of the GLM-4.1V-Thinking-Flash model at the [Experience Center](https://www.bigmodel.cn/trialcenter/modeltrial/text?modelCode=glm-4.1v-thinking-flash) ;
* View the model‚Äôs [rate limits](https://www.bigmodel.cn/usercenter/corporateequity) ;
* Check your [API Key](https://www.bigmodel.cn/usercenter/proj-mgmt/apikeys) ;

## Synchronous Calls

### API Request

| Type | Description |
| --- | --- |
| Protocol | HTTPS |
| Request URL | https://open.bigmodel.cn/api/paas/v4/chat/completions |
| Call Method | Synchronous call, waits for the model to complete execution and return the final result or SSE call |
| Character Encoding | UTF-8 |
| Request Format | JSON |
| Response Format | JSON or standard Stream Event |
| Request Type | POST |
| Development Language | Any language capable of initiating HTTP requests |

### Request Parameters

| **Parameter Name** | **Type** | **Required** | **Description** |
| --- | --- | --- | --- |
| model | String | Yes | The model code to call. |
| messages | List<Object> | Yes | When calling the language model, the current conversation message list is input as a prompt to the model, passed as a JSON array. Image type: `{ "type": "image_url", "image_url": { "url": "Image URL" } }` Video type: `{ "type": "video_url", "video_url": { "url": "Video URL" } }` Text type: `{ "type": "text", "text": "Text content" }` Possible message types include User message and Assistant message. See the message field description below. |
| request\_id | String | No | User-provided parameter; must be unique. Used to distinguish each request. If not provided, the platform will generate one by default. |
| do\_sample | Boolean | No | When `do_sample` is true, sampling strategies are enabled. When false, sampling parameters `temperature` and `top_p` will not take effect. |
| stream | Boolean | No | For synchronous calls, this parameter should be set to False or omitted. Indicates that the model returns all content at once after generation. If set to True, the model will return content incrementally via standard Event Stream. A `data: [DONE]` message is sent when the Event Stream ends. |
| temperature | Float | No | Sampling temperature, controls the randomness of output. Must be positive. Range: `[0.0, 1.0]`, default: 0.8. Higher values make output more random and creative; lower values make output more stable or deterministic. Adjust either `top_p` or `temperature` for your use case, but not both simultaneously. |
| top\_p | Float | No | An alternative to temperature sampling, called nucleus sampling. Range: `[0.0, 1.0]`, default: 0.6. The model considers tokens with `top_p` probability mass. For example, 0.1 means the decoder only considers tokens from the top 10% probability mass. Adjust either `top_p` or `temperature` for your use case, but not both simultaneously. |
| max\_tokens | Integer | No | Maximum output tokens from the modelÔºåit is recommended that the input max\_tokens should not be less than 1024. |
| user\_id | String | No | Unique ID for end-users, helping the platform intervene against violations, illegal or harmful content, or other misuse. ID length: minimum 6 characters, maximum 128 characters. [Learn more](https://bigmodel.cn/dev/howuse/securityaudit) |

### Messages Format

The model accepts message types including User message and Assistant message, with different formats for each. Details below:

#### User Message

| **Parameter Name** | **Type** | **Required** | **Description** |
| --- | --- | --- | --- |
| role | String | Yes | Role information for the message; should be `user`. |
| content | List<Object> | Yes | Message content. |
| type | String | Yes | Text type: `text` Image type: `image_url` Video type: `video_url` Video and image types cannot be input simultaneously. |
| text | String | Yes | Required when `type` is `text`. |
| image\_url | Object | Yes | Required when `type` is `image_url`. |
| url | String | Yes | Image URL or base64 encoding. Image size limit: 5MB per image, with pixels not exceeding 6000\*6000. Supported formats: jpg, png, jpeg. |
| video\_url | Object | Yes | Required when `type` is `video_url`. |
| url | String | Yes | Video URL. Maximum size: 200MB. Video format: mp4. |

#### Assistant Message

| **Parameter Name** | **Type** | **Required** | **Description** |
| --- | --- | --- | --- |
| role | String | Yes | Role information; should be `assistant`. |
| content | String | Yes | Message content. |

### Response Parameters

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| id | String | Task ID. |
| created | Long | Request creation time, in Unix timestamp (seconds). |
| model | String | Model name. |
| choices | List | Model output content for the current conversation. |
| index | Integer | Result index. |
| finish\_reason | String | Reason for model inference termination. `stop`: Natural end or triggered stop word. `length`: Reached token limit. `sensitive`: Content blocked by security review. `network_error`: Inference exception. |
| message | Object | Text information returned by the model. |
| role | String | Current conversation role; defaults to `assistant` (model). |
| **reasoning\_content** |  | **Chain-of-thought content.** |
| **content** |  | **Final answer content.** |
| usage | Object | Token count statistics for the model call. |
| prompt\_tokens | Integer | Number of input tokens. |
| completion\_tokens | Integer | Number of output tokens. |
| total\_tokens | Integer | Total tokens. |
| content\_filter | List | Content safety-related information. |
| role | String | Safety enforcement stage:  `assistant`: Model inference, `user`: User input, `history`: Historical context. |
| level | Integer | Severity level 0-3; 0 is most severe, 3 is mild. |

## Request Examples

### Upload Video URL

```
# Video understanding example: Upload video URL  
from zhipuai import ZhipuAI  

client = ZhipuAI(api_key="YOUR API KEY") # Enter your own APIKey  
response = client.chat.completions.create(  
    model="glm-4.1v-thinking-flashx",  # Enter the model name to call  
    messages=[  
      {  
        "role": "user",  
        "content": [  
          {  
            "type": "video_url",  
            "video_url": {  
                "url": "https://sfile.chatglm.cn/testpath/video/xxxxx.mp4"  
            }  
          },  
          {  
            "type": "text",  
            "text": "Please describe this video in detail"  
          }  
        ]  
      }  
    ]  
)  
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25

### Upload Image URL

```
from zhipuai import ZhipuAI  
client = ZhipuAI(api_key="") # Enter your own APIKey  
response = client.chat.completions.create(  
    model="glm-4.1v-thinking-flashx",  # Enter the model name to call  
    messages=[  
       {  
        "role": "user",  
        "content": [  
          {  
            "type": "text",  
            "text": "Please help me solve this problem, providing detailed steps and the answer"  
          },  
          {  
            "type": "image_url",  
            "image_url": {  
                "url": "URL of the image to upload"  
            }  
          }  
        ]  
      }  
    ]  
)  
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23

### Upload Image Base64

```
import base64  
from zhipuai import ZhipuAI  

img_path = "/Users/YourComputer/xxxx.jpeg"  
with open(img_path, 'rb') as img_file:  
    img_base = base64.b64encode(img_file.read()).decode('utf-8')  

client = ZhipuAI(api_key="YOUR API KEY") # Enter your own APIKey  
response = client.chat.completions.create(  
    model="glm-4.1v-thinking-flashx",  # Enter the model name to call  
    messages=[  
      {  
        "role": "user",  
        "content": [  
          {  
            "type": "image_url",  
            "image_url": {  
                "url": img_base
            }  
          },  
          {  
            "type": "text",  
            "text": "Please describe this image"  
          }  
        ]  
      }  
    ]  
)  
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29

## Response Example

```
{  
    "choices": [  
        {  
            "finish_reason": "stop",  
            "index": 0,  
            "message": {  
                "content": "Final output result",  
                "reasoning_content": "Chain-of-thought content",  
                "role": "assistant"  
            }  
        }  
    ],  
    "created": 1751375632,  
    "id": "202507012113214121c0e1a7d4466f",  
    "model": "glm-4.1v-thinking-flash",  
    "request_id": "202507012113214121c0e1a7d4466f",  
    "usage": {  
        "completion_tokens": 3628,  
        "prompt_tokens": 939,  
        "total_tokens": 4567  
    }  
}
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22

## Streaming Output

### Response Parameters

| **Parameter Name** | **Type** | **Description** |
| --- | --- | --- |
| id | String | Task ID. |
| created | Long | Request creation time, in Unix timestamp (seconds). |
| choices | List | Model output content for the current conversation. |
| index | Integer | Result index. |
| finish\_reason | String | Reason for model inference termination. `stop`: Natural end or triggered stop word. `length`: Reached token limit. `sensitive`: Content blocked by security review. `network_error`: Inference exception. |
| delta | Object | Incremental text information returned by the model. |
| role | String | Current conversation role; defaults to `assistant` (model). |
| content | String | Current conversation content. |
| **reasoning\_content** | **String** | **Chain-of-thought content.** |
| usage | Object | Token count statistics for the model call. |
| prompt\_tokens | Integer | Number of input tokens. |
| completion\_tokens | Integer | Number of output tokens. |
| total\_tokens | Integer | Total tokens. |
| content\_filter | List | Content safety-related information. |
| role | String | Safety enforcement stage:  `assistant`: Model inference, `user`: User input, `history`: Historical context. |
| level | Integer | Severity level 0-3; 0 is most severe, 3 is mild. |

### Request Example

```
from zhipuai import ZhipuAI  
client = ZhipuAI(api_key="") # Enter your own APIKey  
response = client.chat.completions.create(  
    model="glm-4.1v-thinking-flashx",  # Enter the model name to call  
    messages=[  
        {  
          "role": "user",   
          "content": [  
            {  
              "type": "image_url",  
              "image_url": {  
                "url": "URL of the image to upload"  
              }  
            },  
            {  
              "type": "text",  
              "text": "Please help me solve this problem, providing detailed steps and the answer"  
            }  
          ]  
        },  
    ],  
    stream=True,  
)  
reasoning_content = ""  # Complete thinking process
answer_content = ""  #  Complete reply
is_answering = False  # Whether to enter the reply stage
print("\n" + "=" * 20 + "Thinking Process" + "=" * 20 + "\n")
for chunk in response:
    if not chunk.choices:
        print("\nUsage:")
        print(chunk.usage)
        continue
    delta = chunk.choices[0].delta
    # Only collect thinking content
    if hasattr(delta, "reasoning_content") and delta.reasoning_content is not None:
        if not is_answering:
            print(delta.reasoning_content, end="", flush=True)
        reasoning_content += delta.reasoning_content
    # Receive content and start replying
    if hasattr(delta, "content") and delta.content:
        if not is_answering:
            print("\n" + "=" * 20 + "Complete Reply" + "=" * 20 + "\n")
            is_answering = True
        print(delta.content, end="", flush=True)
        answer_content += delta.content
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37  
38  
39  
40  
41  
42  
43  
44  
45

### Response Example

```
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', reasoning_content='Áî®Êà∑', tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', reasoning_content='Áé∞Âú®', tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', reasoning_content='ÈúÄË¶Å', tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', reasoning_content='ÂàÜÊûê', tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', reasoning_content='‚Äú', tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content=None, role='assistant', reasoning_content='‰∏ÄÂÆöË¶Å', tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
......
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content='‰∏é', role='assistant', reasoning_content=None, tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content='‰ª∑ÂÄºÁöÑ', role='assistant', reasoning_content=None, tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content='Ê≠£Âêë', role='assistant', reasoning_content=None, tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content='ÂèëÂ±ï', role='assistant', reasoning_content=None, tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content='„ÄÇ', role='assistant', reasoning_content=None, tool_calls=None, audio=None), finish_reason=None, index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=None, extra_json=None)
ChatCompletionChunk(id='202507161648053170fac2ce1f4116', choices=[Choice(delta=ChoiceDelta(content='', role='assistant', reasoning_content=None, tool_calls=None, audio=None), finish_reason='stop', index=0)], created=1752655685, model='glm-4.1v-thinking-flashx', usage=CompletionUsage(prompt_tokens=2615, completion_tokens=1323, total_tokens=3938), extra_json=None)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13

Table of contents

Synchronous Calls

API Request

Request Parameters

Messages Format

Response Parameters

Request Examples

Upload Video URL

Upload Image URL

Upload Image Base64

Response Example

Streaming Output

Response Parameters

Request Example

Response Example