[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fapi%2Fnormal-model%2Fglm-4v)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

API REFERENCE

* SDK Calling

  [+ Installation](/dev/api/devguide/sdk-install)

  [+ Authentication](/dev/api/devguide/sdk-auth)

  [+ sdk\_example](/dev/api/devguide/sdk_example)

* HTTP Request

  [+ API Request](/dev/api/http-call/http-para)

  [+ Authentication](/dev/api/http-call/http-auth)

* More Frameworks

  [+ OpenAI SDK](/dev/api/thirdparty-frame/openai-sdk)

  [+ Langchain SDK](/dev/api/thirdparty-frame/langchain-sdk)

APIs

* Language models

  [+ GLM-4 Models](/dev/api/normal-model/glm-4)

  [+ GLM-4V Models](/dev/api/normal-model/glm-4v)

* Reasoning models

  [+ GLM-Z1](/dev/api/Reasoning-models/glm-z1)

* Video Generation

  [+ CogVideoX](/dev/api/videomodel/cogvideox)

  [+ CogVideoX-3](/dev/api/videomodel/cogvideox-3)

  [+ Vidu Models](/dev/api/videomodel/vidu)

* Audio-Video

  [+ GLM-4-Voice](/dev/api/rtav/GLM-4-Voice)

  [+ GLM-Realtime](/dev/api/rtav/GLM-Realtime)

  [+ GLM-ASR](/dev/api/rtav/glm-asr)

* Reasoning models

  [+ GLM-4.1V-Thinking](/dev/api/visual-reasoning-model/GLM-4.1V-Thinking)

* Agent

  [+ TranslationAgent](/dev/api/agent/general_translation)

  [+ Professional Document Translation](/dev/api/agent/doc_translation_agent)

  [+ Social Science and Literary Translation](/dev/api/agent/social_literature_translation_agent)

  [+ Subtitle Translation for Film and Television](/dev/api/agent/subtitle_translation_agent)

  [+ Social Media Translation](/dev/api/agent/social_translation_agent)

  [+ AI Drawing](/dev/api/agent/ai_drawing_agent)

  [+ AI Comics](/dev/api/agent/cartoon_generator_agent)

  [+ Popular Special Effects Videos](/dev/api/agent/vidu_template_agent)

  [+ Resume and Job Matching Assistant](/dev/api/agent/job_matching_agent)

  [+ Customer Service Script Quality Inspection](/dev/api/agent/service_check_agent)

  [+ Sales Quality Inspection](/dev/api/agent/sales_check_agent)

  [+ Bill Recognition](/dev/api/agent/receipt_recognition_agent)

  [+ Clothes Recognition](/dev/api/agent/clothes_recognition_agent)

  [+ Contract Analysis](/dev/api/agent/contract_parser_agent)

  [+ Tendering Analysis Agent](/dev/api/agent/bidding_parser_agent)

  [+ Winning Bid Analysis Agent](/dev/api/agent/bidwin_parser_agent)

  [+ Intelligent Problem Solving](/dev/api/agent/intelligent_education_solve_agent)

  [+ Homework Grading](/dev/api/agent/intelligent_education_correction_agent)

* search-tool

  [+ Web Search API](/dev/api/search-tool/web-search)

  [+ Web Search in Chat](/dev/api/search-tool/websearch-in-chat)

  [+ Search Agent](/dev/api/search-tool/agent-search)

* Image Generation

  [+ CogView-4](/dev/api/image-model/cogview)

* Agent Model

  [+ GLM-4-AllTools](/dev/api/intelligent-agent-model/glm-4-alltools)

  [+ GLM-4-Assistant](/dev/api/intelligent-agent-model/assistantapi)

* Code Programming

  [+ CodeGeeX-4](/dev/api/code-model/codegeex-4)

* Embedding

  [+ Embedding](/dev/api/vector/embedding)

* Moderations

  [+ moderations](/dev/api/moderations/moderations)

* Role-playing

  [+ CharGLM-4](/dev/api/super-humanoid/charglm-4)

  [+ Emohaa](/dev/api/super-humanoid/emohaa)

* Agent Development Platform

  [+ „ÄêNew„Äëqingliuagent](/dev/api/Agent_Platform/newagent)

  [+ agent](/dev/api/Agent_Platform/agent)

  [+ qingliuSDK](/dev/api/Agent_Platform/agentsdk)

  [+ Knowledge](/dev/api/Agent_Platform/knowledge)

  [+ FinAgent](/dev/api/Agent_Platform/FinAgent)

* Batch

  [+ Batch](/dev/api/batch-api/batch)

* Data Management

  [+ File Management](/dev/api/knowlage-manage/queryfile)

  [+ File content extraction](/dev/api/knowlage-manage/queryextract)

  [+ Rerank](/dev/api/knowlage-manage/rerank)

* Error Codes

  [+ HTTP Status Codes](/dev/api/error-code/error-code-v4)

  [+ Model Error Codes](/dev/api/error-code/service-error)

More

[* Libraries](/dev/api/libraries)

[* API Pricing](/dev/api/product-billing)

[* Tokenizer](/dev/api/tokenizer)

[* Parameter Description](/dev/api/parameter-description)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

# GLM-4V Series

GLM-4V achieves deep integration of visual and linguistic features without compromising performance on any NLP task; supports visual question answering, image captioning, visual grounding, complex object detection, and various image/video understanding tasks.

* Model identifiers: glm-4v-plus-0111, glm-4v-flash;
* Learn about [GLM-4V model differences](https://bigmodel.cn/dev/howuse/model) to choose the model that suits you best;
* Check [pricing](https://www.bigmodel.cn/pricing), for large-scale image data processing we recommend using [Batch API](https://www.bigmodel.cn/dev/howuse/batchapi) with a **50% discount**;
* Visit the [demo center](https://www.bigmodel.cn/login?redirect=%2Ftrialcenter%2Fmodeltrial%3FmodelCode%3Dglm-4v-plus-0111) to experience the powerful capabilities of the GLM-4V-Plus-0111 model;
* View [rate limits](https://www.bigmodel.cn/login?redirect=%2Fusercenter%2Fcorporateequity) of the model;
* View your [API Key](https://www.bigmodel.cn/login?redirect=%2Fusercenter%2Fproj-mgmt%2Fapikeys);

## Synchronous Call

#### Interface Request

| Transfer Method | https |
| --- | --- |
| Request URL | https://open.bigmodel.cn/api/paas/v4/chat/completions |
| Call Method | Synchronous call, wait for the model to complete execution and return the final result or use SSE call |
| Character Encoding | UTF-8 |
| Interface Request Format | JSON |
| Response Format | JSON or Standard Stream Event |
| Interface Request Type | POST |
| Development Language | Any development language that can initiate an HTTP request |

### Request Parameters

| **Parameter Name** | **Type** | **Required** | **Parameter Description** |
| --- | --- | --- | --- |
| model | String | Yes | The model code to be called. |
| messages | List<Object> | Yes | When calling the language model, the current dialogue information list is input as a prompt to the model, passed as a JSON array. For example, video understanding parameters `{ "role": "user", "content": [ { "type": "video_url", "video_url": { "url" : "https://xxx/xx.mp4" } }, { "type": "text", "text": "Please describe this video carefully" } ] }` Image understanding parameters `{ "role": "user", "content": [ { "type": "image_url", "image_url": { "url" : "https://xxx/xx.jpg" } }, { "type": "text", "text": "Explain the phenomenon in the picture" } ] }` Possible message types include User message, Assistant message. See the message field description below. |
| request\_id | String | No | Passed by the user side, must be unique; used to distinguish the unique identifier of each request, the platform will generate one by default if not provided by the user side. |
| do\_sample | Boolean | No | When do\_sample is true, sampling strategy is enabled, when do\_sample is false, the sampling strategy temperature, top\_p will not take effect |
| stream | Boolean | No | When using synchronous call, this parameter should be set to False or omitted. Indicates that the model generates all content at once and returns all content. If set to True, the model will return the generated content in chunks via Standard Event Stream. When the Event Stream ends, a `data: [DONE]` message will be returned. |
| temperature | Float | No | Sampling temperature, controls the randomness of the output, must be a positive number, the range is `[0.0,1.0]`, the default value is 0.8, the larger the value, the more random and creative the output will be; the smaller the value, the more stable or deterministic the output will be. It is recommended to adjust the `top_p` or `temperature` parameters according to the application scenario, but not both. |
| top\_p | Float | No | Another method of temperature sampling, called nucleus sampling, the range is `[0.0, 1.0]`, the default value is 0.6, the model considers the results with `top_p` probability mass tokens, for example: 0.1 means the model decoder only considers the top 10% probability candidate set of tokens. It is recommended to adjust the `top_p` or `temperature` parameters according to the application scenario, but not both. |
| max\_tokens | Integer | No | The maximum output tokens of the model, default is 1024 |
| user\_id | String | No | The unique ID of the end user, helps the platform intervene in the behavior of end users who violate regulations, generate illegal and harmful information, or other abuse. The ID length requirement: at least 6 characters, up to 128 characters. [Learn more](https://bigmodel.cn/dev/howuse/securityaudit) |

### Messages Format

The model can accept message types including User message, Assistant message, with different formats for different message types. Specifically:

#### User message

| **Parameter Name** | **Type** | **Required** | **Parameter Description** |
| --- | --- | --- | --- |
| role | String | Yes | The role information of the message, should be `user` at this time |
| content | List<Object> | Yes | The content of the message. |
| type | String | Yes | Text type: text Image type: image\_url  Video type: video\_url Video and image types are not supported at the same time. |
|  |  |  |  |
| text | String | Yes | Supplemented when type is text |
| image\_url | Object | Yes | Supplemented when type is image\_url,  glm-4v supports single image input, glm-4v-plus supports multi-image input |
| url | String | Yes | Image url or base64 encoding.  Image size upload limit is less than 5M per image, and pixels do not exceed 6000\*6000.  Supports jpg, png, jpeg formats. |
| video\_url | Object | Yes | Supplemented when type is video\_url, only glm-4v-plus supports video input When understanding videos, the `video_url` parameter must be the first. |
|  |  |  |  |
| url | String | Yes | Video url.  Video size only supports within 20M, video duration does not exceed 30s.  Supports video type mp4. |

#### Assistant message

| **Parameter Name** | **Type** | **Required** | **Parameter Description** |
| --- | --- | --- | --- |
| role | String | Yes | The role information of the message, should be `assistant` at this time |
| content | String | Yes | The content of the message |

### Response Content

| **Parameter Name** | **Type** | **Parameter Description** |
| --- | --- | --- |
| id | String | Task ID |
| created | Long | Request creation time, Unix timestamp in seconds. |
| model | String | Model name |
| choices | List | Model output content for the current dialogue |
| index | Integer | Result index |
| finish\_reason | String | Reason for model inference termination.  `stop` represents natural end of inference or trigger stop word.  `length` represents reaching the token length limit.  `sensitive` represents model inference content intercepted by the security audit interface.  `network_error` represents model inference exception. |
| message | Object | Text information returned by the model |
| role | String | The role of the current dialogue, currentlyÈªòËÆ§‰∏∫ assistant (model) |
| content | List | The content of the current dialogue |
| usage | Object | Token count statistics for this model call at the end |
| prompt\_tokens | Integer | Number of tokens input by the user |
| completion\_tokens | Integer | Number of tokens output by the model |
| total\_tokens | Integer | Total tokens |
| content\_filter | List | Content security related information |
| role | String | Security effective link, including   `role = assistant` model inference,  `role = user` user input,  `role = history` historical context |
| level | Integer | Severity level 0-3, level 0 indicates the most serious, 3 indicates slight |

## Request Example

### Upload Video URL

```
# Video understanding example, upload video URL
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="YOUR API KEY") # Fill in your own APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # Fill in the model name you need to call
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "video_url",
            "video_url": {
                "url" : "https://sfile.chatglm.cn/testpath/video/xxxxx.mp4"
            }
          },
          {
            "type": "text",
            "text": "Please describe this video carefully"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25

### Upload Image URL

```
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="") # Fill in your own APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # Fill in the model name you need to call
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
                "url" : "sfile.chatglm.cn/testpath/xxxx.jpg"
            }
          },
          {
            "type": "text",
            "text": "What's in the picture"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24

### Upload Image Base64

```
import base64
from zhipuai import ZhipuAI

img_path = "/Users/YourCompluter/xxxx.jpeg"
with open(img_path, 'rb') as img_file:
    img_base = base64.b64encode(img_file.read()).decode('utf-8')

client = ZhipuAI(api_key="YOUR API KEY") # Fill in your own APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # Fill in the model name you need to call
    messages=[
      {
        "role": "user",
        "content": [
          {
            "type": "image_url",
            "image_url": {
                "url": img_base
            }
          },
          {
            "type": "text",
            "text": "Please describe this picture"
          }
        ]
      }
    ]
)
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29

### Multi-round Image Dialogue

```
```python
from zhipuai import ZhipuAI

client = ZhipuAI(api_key="YOUR API KEY") # Enter your own APIKey
response = client.chat.completions.create(
    model="glm-4v-plus-0111",  # Enter the model name to call
    messages=[
      {
          "content": [
              {
                  "image_url": {
                      "url": "https://cdn.bigmodel.cn/xxxxxx.png"
                  },
                  "type": "image_url"
              },
              {
                  "text": "What is in the picture",
                  "type": "text"
              }
          ],
          "role": "user"
      },
      {
          "content": [
              {
                  "text": "This is a painting depicting a natural landscape, showing a peaceful lake with varying shades of blue-green. On the lake shore, there's a blooming cherry blossom tree with pink-white flowers that look especially vibrant under the sunlight. Under the tree, a person in blue clothing is sitting in a boat, seemingly enjoying the beautiful moment.\n\nIn the background are rolling mountains covered with green vegetation. The mountain tops are shrouded in mist, adding a sense of mystery. In the distance, there's a small pavilion sitting on a rock by the lake, harmoniously blending with the surrounding natural environment.\n\nThe entire scene conveys a feeling of tranquility and harmony, as if stepping into a paradise isolated from the world.",
                  "type": "text"
              }
          ],
          "role": "assistant"
      },
      {
          "content": [
              {
                  "image_url": {
                      "url": "https://cdn.bigmodel.cn/xxxxxxx.jpeg"
                  },
                  "type": "image_url"
              },
              {
                  "text": "What is the difference between this image and the one above",
                  "type": "text"
              }
          ],
          "role": "user"
      },
      {
          "content": [
              {
                  "text": "The first and second images differ greatly in content, composition, and color, forming a stark contrast.\n\n1. The first image is a landscape painting, mainly depicting natural scenery such as cherry blossom trees, lakes, and mountains. It has rich colors and a spring vibe, while the second image is a photo of the Great Wall in winter. The Great Wall winds through snow-covered mountains, and the overall tone is cold, giving a sense of chill and tranquility.\n\n2. In terms of composition, the first image uses symmetrical composition with the cherry blossom tree as the center, and surrounding elements forming a balanced and harmonious effect. The second image uses diagonal composition, with the Great Wall serving as a visual guide that leads the viewer's eye across the frame, enhancing the depth and dynamic of the picture.\n\nOverall, the two images present a strong contrast in terms of content, color, composition, and atmosphere‚Äîone is a vibrant spring landscape painting, the other a quiet and mysterious winter scene of the Great Wall.",
                  "type": "text"
              }
          ],
          "role": "assistant"
      },
      {
          "content": [
              {
                  "image_url": {
                      "url": "https://cdn.bigmodel.cn/xxxxxxx.jpeg"
                  },
                  "type": "image_url"
              },
              {
                  "text": "What is the difference between this image and the previous one",
                  "type": "text"
              }
          ],
          "role": "user"
      }
    ]
)
print(response.choices[0].message)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25  
26  
27  
28  
29  
30  
31  
32  
33  
34  
35  
36  
37  
38  
39  
40  
41  
42  
43  
44  
45  
46  
47  
48  
49  
50  
51  
52  
53  
54  
55  
56  
57  
58  
59  
60  
61  
62  
63  
64  
65  
66  
67  
68  
69  
70  
71  
72  
73

## Response Example

```
{
    "created": 1703487403,
    "id": "8239375684858666781",
    "model": "glm-4v-plus",
    "request_id": "8239375684858666781",
    "choices": [
        {
            "finish_reason": "stop",
            "index": 0,
            "message": {
                "content": "There is a blue sea and blue sky in the picture, with white clouds in the sky. In the lower right corner of the picture, there is a small island or rock, covered with dark green trees.",
                "role": "assistant"
            }
        }
    ],
    "usage": {
        "completion_tokens": 37,
        "prompt_tokens": 1037,
        "total_tokens": 1074
    }
  }
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21

## Streaming Output

### Response Content

| **Parameter Name** | **Type** | **Parameter Description** |
| --- | --- | --- |
| id | String | Task ID |
| created | Long | Request creation time, Unix timestamp in seconds. |
| choices | List | Model output content for the current dialogue |
| index | Integer | Result index |
| finish\_reason | String | Reason for model inference termination.  `stop` represents natural end of inference or trigger stop word.  `length` represents reaching the token length limit.  `sensitive` represents model inference content intercepted by the security audit interface.  `network_error` represents model inference exception. |
| delta | Object | Incremental text information returned by the model |
| role | String | The role of the current dialogue, currentlyÈªòËÆ§‰∏∫ assistant (model) |
| content | String | The content of the current dialogue |
| usage | Object | Token count statistics for this model call |
| prompt\_tokens | Integer | Number of tokens input by the user |
| completion\_tokens | Integer | Number of tokens output by the model |
| total\_tokens | Integer | Total tokens |
| content\_filter | List | Content security related information |
| role | String | Security effective link, including   `role = assistant` model inference,  `role = user` user input,  `role = history` historical context |
| level | Integer | Severity level 0-3, level 0 indicates the most serious, 3 indicates slight |

### Request Example

```
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="") # Please fill in your own APIKey
response = client.chat.completions.create(
    model="glm-4v-plus",  # Fill in the model name you need to call
    messages=[
        {
          "role": "user", 
          "content": [
            {
              "type": "text",
              "text": "What's in the picture"
            },
            {
              "type": "image_url",
              "image_url": {
                "url" : "sfile.chatglm.cn/testpath/xxxx.jpg"
              }
            }
          ]
        },
    ],
    stream=True,
)
for chunk in response:
    print(chunk.choices[0].delta)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19  
20  
21  
22  
23  
24  
25

#### Response Example

```
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"‰∏ã"}}]}
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"Ëßí"}}]}
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"Êúâ‰∏Ä‰∏™"}}]}
... ...
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"Ê†ëÊú®"}}]}
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"delta":{"role":"assistant","content":"„ÄÇ"}}]}
data: {"id":"8305986882425703351","created":1705476637,"model":"glm-4v-plus","choices":[{"index":0,"finish_reason":"stop","delta":{"role":"assistant","content":""}}],"usage":{"prompt_tokens":1037,"completion_tokens":37,"total_tokens":1074}}
```

1  
2  
3  
4  
5  
6  
7

Table of contents

Synchronous Call

Request Parameters

Messages Format

Response Content

Request Example

Upload Video URL

Upload Image URL

Upload Image Base64

Multi-round Image Dialogue

Response Example

Streaming Output

Response Content

Request Example