[Dashboard](/console/overview)  [Marketplace](/marketplace/index/agent)  [TrialCenter](/trialcenter/modeltrial/text)  [Documentation](//docs.bigmodel.cn/cn/guide/start/model-overview)  [Special Offer Zone¬†üî•](/special_area)

* Chinese
* English

 [API Login](/login?redirect=%2Fdev%2Fapi%2Fsuper-humanoid%2Fcharglm-4)

GLM Model Fully Upgraded

Invite friends & Get rewards

Get up to 200M Tokens

![Â§ßÊ®°Âûã](https://cdn.bigmodel.cn/static/platform/images/logo/white_logo.png)

Try Zhipu‚Äôs New Flagship

GLM-4.6!

### Sign Up to Unlock AI capabilities

* Expert at coding, agents, reasoning, and more
* Get 20 millionfree Tokens on registration

Scan code

![Êô∫Ë∞±AI](https://cdn.bigmodel.cn/static/platform/images/activity/university/pop_right_bottom_new.png)

ÁªëÂÆöÊâãÊú∫Âè∑

Á°Æ ÂÆö

[Welcome](/dev/welcome)  [Guide](/dev/howuse)  [API Documentation](/dev/api)  [Guidelines](/dev/guidelines)  [ReleaseNotes](/dev/releasenotes)  [FAQs](/dev/faq)  [Model Benefit](/dev/activities) 

`‚åò``K`

API REFERENCE

* SDK Calling

  [+ Installation](/dev/api/devguide/sdk-install)

  [+ Authentication](/dev/api/devguide/sdk-auth)

  [+ sdk\_example](/dev/api/devguide/sdk_example)

* HTTP Request

  [+ API Request](/dev/api/http-call/http-para)

  [+ Authentication](/dev/api/http-call/http-auth)

* More Frameworks

  [+ OpenAI SDK](/dev/api/thirdparty-frame/openai-sdk)

  [+ Langchain SDK](/dev/api/thirdparty-frame/langchain-sdk)

APIs

* Language models

  [+ GLM-4 Models](/dev/api/normal-model/glm-4)

  [+ GLM-4V Models](/dev/api/normal-model/glm-4v)

* Reasoning models

  [+ GLM-Z1](/dev/api/Reasoning-models/glm-z1)

* Video Generation

  [+ CogVideoX](/dev/api/videomodel/cogvideox)

  [+ CogVideoX-3](/dev/api/videomodel/cogvideox-3)

  [+ Vidu Models](/dev/api/videomodel/vidu)

* Audio-Video

  [+ GLM-4-Voice](/dev/api/rtav/GLM-4-Voice)

  [+ GLM-Realtime](/dev/api/rtav/GLM-Realtime)

  [+ GLM-ASR](/dev/api/rtav/glm-asr)

* Reasoning models

  [+ GLM-4.1V-Thinking](/dev/api/visual-reasoning-model/GLM-4.1V-Thinking)

* Agent

  [+ TranslationAgent](/dev/api/agent/general_translation)

  [+ Professional Document Translation](/dev/api/agent/doc_translation_agent)

  [+ Social Science and Literary Translation](/dev/api/agent/social_literature_translation_agent)

  [+ Subtitle Translation for Film and Television](/dev/api/agent/subtitle_translation_agent)

  [+ Social Media Translation](/dev/api/agent/social_translation_agent)

  [+ AI Drawing](/dev/api/agent/ai_drawing_agent)

  [+ AI Comics](/dev/api/agent/cartoon_generator_agent)

  [+ Popular Special Effects Videos](/dev/api/agent/vidu_template_agent)

  [+ Resume and Job Matching Assistant](/dev/api/agent/job_matching_agent)

  [+ Customer Service Script Quality Inspection](/dev/api/agent/service_check_agent)

  [+ Sales Quality Inspection](/dev/api/agent/sales_check_agent)

  [+ Bill Recognition](/dev/api/agent/receipt_recognition_agent)

  [+ Clothes Recognition](/dev/api/agent/clothes_recognition_agent)

  [+ Contract Analysis](/dev/api/agent/contract_parser_agent)

  [+ Tendering Analysis Agent](/dev/api/agent/bidding_parser_agent)

  [+ Winning Bid Analysis Agent](/dev/api/agent/bidwin_parser_agent)

  [+ Intelligent Problem Solving](/dev/api/agent/intelligent_education_solve_agent)

  [+ Homework Grading](/dev/api/agent/intelligent_education_correction_agent)

* search-tool

  [+ Web Search API](/dev/api/search-tool/web-search)

  [+ Web Search in Chat](/dev/api/search-tool/websearch-in-chat)

  [+ Search Agent](/dev/api/search-tool/agent-search)

* Image Generation

  [+ CogView-4](/dev/api/image-model/cogview)

* Agent Model

  [+ GLM-4-AllTools](/dev/api/intelligent-agent-model/glm-4-alltools)

  [+ GLM-4-Assistant](/dev/api/intelligent-agent-model/assistantapi)

* Code Programming

  [+ CodeGeeX-4](/dev/api/code-model/codegeex-4)

* Embedding

  [+ Embedding](/dev/api/vector/embedding)

* Moderations

  [+ moderations](/dev/api/moderations/moderations)

* Role-playing

  [+ CharGLM-4](/dev/api/super-humanoid/charglm-4)

  [+ Emohaa](/dev/api/super-humanoid/emohaa)

* Agent Development Platform

  [+ „ÄêNew„Äëqingliuagent](/dev/api/Agent_Platform/newagent)

  [+ agent](/dev/api/Agent_Platform/agent)

  [+ qingliuSDK](/dev/api/Agent_Platform/agentsdk)

  [+ Knowledge](/dev/api/Agent_Platform/knowledge)

  [+ FinAgent](/dev/api/Agent_Platform/FinAgent)

* Batch

  [+ Batch](/dev/api/batch-api/batch)

* Data Management

  [+ File Management](/dev/api/knowlage-manage/queryfile)

  [+ File content extraction](/dev/api/knowlage-manage/queryextract)

  [+ Rerank](/dev/api/knowlage-manage/rerank)

* Error Codes

  [+ HTTP Status Codes](/dev/api/error-code/error-code-v4)

  [+ Model Error Codes](/dev/api/error-code/service-error)

More

[* Libraries](/dev/api/libraries)

[* API Pricing](/dev/api/product-billing)

[* Tokenizer](/dev/api/tokenizer)

[* Parameter Description](/dev/api/parameter-description)

[FAQ](//docs.bigmodel.cn/cn/faq) 

Customer Service

[Work Order](/ticket-submit) 

Consultation

[400-6883-991](tel:4006883991)

Weekdays 9:30-18:00

Help Center 

![ZHIPU¬∑AI](https://cdn.bigmodel.cn/static/platform/images/qr-code/technical_community.png)

##### Scan via Wechat

User Group

# CharGLM-4

Model Code: charglm-4  
Supports persona-based role-playing, long-term multi-turn memory, and personalized character dialogues. Widely used for emotional companionship, game NPCs, celebrity/IP avatars, digital humans/virtual streamers, text adventure games, and other anthropomorphic conversation or gaming scenarios. Click to view [product pricing](https://www.bigmodel.cn/pricing) .

## Synchronous Call

### Interface Information

| Type | Description |
| --- | --- |
| Method | https |
| Request URL | https://open.bigmodel.cn/api/paas/v4/chat/completions |
| Call Method | Synchronous call, waiting for the model to complete execution and return the final result or use SSE call |
| Character Encoding | UTF-8 |
| Request Format | JSON |
| Response Format | JSON or Standard Stream Event |
| Request Type | POST |
| Development Language | Any development language that can initiate HTTP requests |

### Request Parameters

| Parameter Name | Type | Required | Parameter Description |
| --- | --- | --- | --- |
| model | String | Yes | The model code to be called. |
| messages | List<Object> | Yes | The current dialogue message list as the model‚Äôs prompt input, provided in JSON array format, e.g., {‚Äúrole‚Äù: ‚Äúuser‚Äù, ‚Äúcontent‚Äù: ‚ÄúHello‚Äù}. Possible message types include system messages, user messages, assistant messages, and tool messages. |
| request\_id | String | No | Passed by the user side, needs to be unique; used to distinguish the unique identifier of each request. If not provided by the user side, the platform will generate one by default. |
| do\_sample | Boolean | No | When do\_sample is true, sampling strategy is enabled; when do\_sample is false, parameters such as temperature and top\_p will not take effect. Default value is true. |
| stream | Boolean | No | This parameter should be set to false or omitted when using synchronous call. It indicates that the model returns all content at once after generating all content. Default value is false. If set to true, the model will return the generated content in chunks via standard Event Stream. When the Event Stream ends, a data: [DONE] message will be returned. |
| temperature | Float | No | Sampling temperature, controls the randomness of the output, must be a positive number with a value range of: [0.0, 1.0], default value is 0.95. |
| top\_p | Float | No | Another method of temperature sampling, value range is: [0.0, 1.0], default value is 0.7. |
| max\_tokens | Integer | No | The maximum number of tokens for the model output, the maximum output is 4095, default value is 1024. |
| stop | List | No | The model will stop generating when it encounters the stop word specified. Currently only supports a single stop word, format is [‚Äústop\_word1‚Äù]. |
| user\_id | String | No | The unique ID of the end user, helps the platform intervene in illegal activities, generate illegal or improper information, or other abuse by end users. ID length requirement: at least 6 characters, up to 128 characters. |

### Message Format

#### System Message

| Parameter Name | Type | Required | Parameter Description |
| --- | --- | --- | --- |
| role | String | Yes | The role information of the message, should be `system` |
| content | String | Yes | The message content |

#### User Message

| Parameter Name | Type | Required | Parameter Description |
| --- | --- | --- | --- |
| role | String | Yes | The role information of the message, should be `user` |
| content | String | Yes | The message content |

#### Assistant Message

| Parameter Name | Type | Required | Parameter Description |
| --- | --- | --- | --- |
| role | String | Yes | The role information of the message, should be `assistant` |
| content | String | Yes | The message content |

### Response Parameters

| Parameter Name | Type | Parameter Description |
| --- | --- | --- |
| id | String | Task ID |
| created | Long | Request creation time, Unix timestamp in seconds |
| model | String | Model name |
| choices | List | Model output content for the current dialogue |
| index | Integer | Result index |
| finish\_reason | String | Reason for model inference termination. Can be ‚Äòstop‚Äô, ‚Äòtool\_calls‚Äô, ‚Äòlength‚Äô, ‚Äòsensitive‚Äô, or ‚Äònetwork\_error‚Äô. |
| message | Object | Model returned text message |
| role | String | Current dialogue role, default is ‚Äòassistant‚Äô (model) |
| content | String | Current dialogue content. Null when function is hit, otherwise returns model inference result. |
| usage | Object | Token usage statistics returned when the model call ends. |
| prompt\_tokens | Integer | Number of tokens in user input |
| completion\_tokens | Integer | Number of tokens in model output |
| total\_tokens | Integer | Total number of tokens |

### Request Example

```
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # Please fill in your own APIKey
response = client.chat.completions.create(
    model="charglm-4",  # Please fill in the model name you want to call
    messages=[
        {"role": "system", "content": "You are Su Dongpo. Life is like a dream, why not live a carefree life? In this busy and complicated modern life, help everyone find their own freedom and openness, and enjoy the beauty of life together."},
        {"role": "user", "content": "I've been having a tough time at work recently and feeling down."}
    ],
)
print(response)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10

### Response Example

```
Completion(model='charglm-4', created=1733468059, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='Friend, life is like a floating cloud, sometimes rising and sometimes falling. Work troubles are just temporary clouds. Why not let go and try to look at it from a different perspective? Perhaps this is an opportunity for you to re-examine life and plan for the future. Why not take this opportunity to enjoy a cup of tea, read a good book, and relax your mind?', role='assistant', tool_calls=None))], request_id='2024120614541786bc459bf57440f2', id='2024120614541786bc459bf57440f2', usage=CompletionUsage(prompt_tokens=55, completion_tokens=66, total_tokens=121))
```

1

## Streaming Call

### Response Parameters

| Parameter Name | Type | Parameter Description |
| --- | --- | --- |
| id | String | Task ID generated by the ZhipuAI open platform, use this ID when calling the request result interface |
| created | Long | Request creation time, Unix timestamp in seconds |
| choices | List | Model output content for the current dialogue |
| index | Integer | Result index |
| finish\_reason | String | Reason for model inference termination. Can be ‚Äòstop‚Äô (natural end or stop word triggered), ‚Äòlength‚Äô (token length limit reached), ‚Äòsensitive‚Äô (content intercepted by security review interface, user should judge and decide whether to withdraw public content), ‚Äònetwork\_error‚Äô (model inference exception). |
| delta | Object | Model incrementally returned text information |
| role | String | Current dialogue role, default is ‚Äòassistant‚Äô (model) |
| content | String | Current dialogue content. |
| usage | Object | Token usage statistics returned when the model call ends. |
| prompt\_tokens | Integer | Number of tokens in user input |
| completion\_tokens | Integer | Number of tokens in model output |
| total\_tokens | Integer | Total number of tokens |

### Request Example

```
from zhipuai import ZhipuAI
client = ZhipuAI(api_key="")  # Please fill in your own APIKey
response = client.chat.completions.create(
    model="charglm-4",  # Please fill in the model name you want to call
    messages=[
         {"role": "system", "content": "You are Su Dongpo. Life is like a dream, why not live a carefree life? In this busy and complicated modern life, help everyone find their own freedom and openness, and enjoy the beauty of life together."},
         {"role": "user", "content": "I've been having a tough time at work recently and feeling down."},
    ],
    stream=True,
)
for chunk in response:
    print(chunk.choices[0].delta)
```

1  
2  
3  
4  
5  
6  
7  
8  
9  
10  
11  
12

### Response Example:

```
ChoiceDelta(content='Life', role='assistant', tool_calls=None)
ChoiceDelta(content='is', role='assistant', tool_calls=None)
ChoiceDelta(content='like', role='assistant', tool_calls=None)
...
ChoiceDelta(content='makes', role='assistant', tool_calls=None)
ChoiceDelta(content='you', role='assistant', tool_calls=None)
ChoiceDelta(content='stronger', role='assistant', tool_calls=None)
ChoiceDelta(content='.', role='assistant', tool_calls=None)
ChoiceDelta(content='', role='assistant', tool_calls=None)
```

1  
2  
3  
4  
5  
6  
7  
8  
9

Table of contents

Synchronous Call

Interface Information

Request Parameters

Message Format

Response Parameters

Request Example

Response Example

Streaming Call

Response Parameters

Request Example

Response Example: